<!DOCTYPE html>


  <html class="light page-post">


<head>
  <meta charset="utf-8">
  
  <title>sparkCore源码解析之partition | sustcoder</title>

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
    <meta name="keywords" content="spark,源码解析," />
  

  <meta name="description" content="水塘抽样">
<meta name="keywords" content="spark,core,源码,partition">
<meta property="og:type" content="article">
<meta property="og:title" content="sparkCore源码解析之partition">
<meta property="og:url" content="https://sustcoder.github.io/2019/01/14/2018-12-01-sparkCore-sorceCodeAnalysis-partition/index.html">
<meta property="og:site_name" content="sustcoder">
<meta property="og:description" content="水塘抽样">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/sparkcore/Partition.png">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/sparkcore/wpsC537.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/sparkcore/wpsC557.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/sparkcore/wpsC559.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/sparkcore/wpsC55A.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/sparkcore/wpsC56B.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/sparkcore/wpsC56C.tmp.jpg">
<meta property="og:updated_time" content="2019-01-14T11:15:54.068Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="sparkCore源码解析之partition">
<meta name="twitter:description" content="水塘抽样">
<meta name="twitter:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/sparkcore/Partition.png">

  

  
    <link rel="icon" href="/favicon.ico">
  

  <link href="/css/styles.css?v=c114cben" rel="stylesheet">


  

  

  
  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?f1cc8b0edce213e23b90ab65ff3c30ff";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>


  
  <script type="text/javascript">
	(function(){
	    var bp = document.createElement('script');
	    var curProtocol = window.location.protocol.split(':')[0];
	    if (curProtocol === 'https') {
	        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
	    }
	    else {
	        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
	    }
	    var s = document.getElementsByTagName("script")[0];
	    s.parentNode.insertBefore(bp, s);
	})();
  </script>



  
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.3.0/css/font-awesome.min.css">
  

</head>

<body>


  
    <span id="toolbox-mobile" class="toolbox-mobile">盒子</span>
  

  <div class="post-header CENTER">
   
  <div class="toolbox">
    <a class="toolbox-entry" href="/">
      <span class="toolbox-entry-text">盒子</span>
      <i class="icon-angle-down"></i>
      <i class="icon-home"></i>
    </a>
    <ul class="list-toolbox">
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/blog/"
            rel="noopener noreferrer"
            target="_self"
            >
            博客
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/category/"
            rel="noopener noreferrer"
            target="_self"
            >
            分类
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/tag/"
            rel="noopener noreferrer"
            target="_self"
            >
            标签
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/link/"
            rel="noopener noreferrer"
            target="_self"
            >
            友链
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/about/"
            rel="noopener noreferrer"
            target="_self"
            >
            关于
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/search/"
            rel="noopener noreferrer"
            target="_self"
            >
            搜索
          </a>
        </li>
      
    </ul>
  </div>


</div>


  <div id="toc" class="toc-article">
    <strong class="toc-title">文章目录</strong>
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-概念"><span class="toc-text">1. 概念</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-获取分区"><span class="toc-text">2. 获取分区</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-接口"><span class="toc-text">2.1. 接口</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-实现"><span class="toc-text">2.2. 实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-1-KafkaRDD"><span class="toc-text">2.2.1. KafkaRDD</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-2-HadoopRDD"><span class="toc-text">2.2.2. HadoopRDD</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-3-JdbcRDD"><span class="toc-text">2.2.3. JdbcRDD</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-4-MapPartitionsRDD"><span class="toc-text">2.2.4. MapPartitionsRDD</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-分区数量"><span class="toc-text">3. 分区数量</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-RDD初始化相关"><span class="toc-text">3.1. RDD初始化相关</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2-通用transformation"><span class="toc-text">3.2. 通用transformation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-3-Key-based-Transformations"><span class="toc-text">3.3. Key-based Transformations</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-分区器"><span class="toc-text">4. 分区器</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1-作用"><span class="toc-text">4.1. 作用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-2-种类"><span class="toc-text">4.2. 种类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-1-HashPartitioner"><span class="toc-text">4.2.1. HashPartitioner</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-2-RangePartitioner"><span class="toc-text">4.2.2. RangePartitioner</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-2-1-获取区间数组"><span class="toc-text">4.2.2.1. 获取区间数组</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#4-2-2-1-1-给定样本总数"><span class="toc-text">4.2.2.1.1. 给定样本总数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-2-2-1-2-计算样本最大值"><span class="toc-text">4.2.2.1.2. 计算样本最大值</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-2-2-1-3-水塘抽样"><span class="toc-text">4.2.2.1.3. 水塘抽样</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-2-2-1-4-是否需要二次采样"><span class="toc-text">4.2.2.1.4. 是否需要二次采样</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-2-2-1-5-计算样本权重"><span class="toc-text">4.2.2.1.5. 计算样本权重</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-2-2-1-6-二次抽样"><span class="toc-text">4.2.2.1.6. 二次抽样</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-2-2-1-7-生成边界数组"><span class="toc-text">4.2.2.1.7. 生成边界数组</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-2-2-水塘抽样算法"><span class="toc-text">4.2.2.2. 水塘抽样算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-2-3-定位分区ID"><span class="toc-text">4.2.2.3. 定位分区ID</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#4-2-2-3-1-数组直接获取"><span class="toc-text">4.2.2.3.1. 数组直接获取</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-2-2-3-2-二分法查找"><span class="toc-text">4.2.2.3.2. 二分法查找</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#5-自定义分区器"><span class="toc-text">5. 自定义分区器</span></a></li></ol>
  </div>



<div class="content content-post CENTER">
   <article id="post-2018-12-01-sparkCore-sorceCodeAnalysis-partition" class="article article-type-post" itemprop="blogPost">
  <header class="article-header">
    <h1 class="post-title">sparkCore源码解析之partition</h1>

    <div class="article-meta">
      <span>
        <i class="icon-calendar"></i>
        <span>2019.01.14</span>
      </span>

      
        <span class="article-author">
          <i class="icon-user"></i>
          <span>freeli</span>
        </span>
      

      
  <span class="article-category">
    <i class="icon-list"></i>
    <a class="article-category-link" href="/categories/spark/">spark</a>
  </span>



      
        <span>
          <i class="icon-comment"></i>
          <a href="https://sustcoder.github.io//2019/01/14/2018-12-01-sparkCore-sorceCodeAnalysis-partition/#disqus_thread"></a>
        </span>
      

      
      <i class="fa fa-eye"></i> 
        <span id="busuanzi_container_page_pv">
           &nbsp热度 <span id="busuanzi_value_page_pv">
           <i class="fa fa-spinner fa-spin"></i></span>℃
        </span>
      
      
    </div>
  </header>

  <div class="article-content">
    
      <p> <img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/sparkcore/Partition.png" alt="job"></p>
<h1 id="1-概念"><a href="#1-概念" class="headerlink" title="1. 概念"></a>1. <strong>概念</strong></h1><p>表示并行计算的一个计算单元</p>
<p>RDD 内部的数据集合在逻辑上和物理上被划分成多个小子集合，这样的每一个子集合我们将其称为分区，分区的个数会决定并行计算的粒度，而每一个分区数值的计算都是在一个单独的任务中进行，因此并行任务的个数，也是由 RDD（实际上是一个阶段的末 RDD，调度章节会介绍）分区的个数决定的</p>
<h1 id="2-获取分区"><a href="#2-获取分区" class="headerlink" title="2. 获取分区"></a>2. <strong>获取分区</strong></h1><p>RDD的分区数量可通过rdd.getPartitions获取。<br>getPartitions方法是在RDD类中定义的，由不同的子类进行具体的实现</p>
<h2 id="2-1-接口"><a href="#2-1-接口" class="headerlink" title="2.1. 接口"></a>2.1. <strong>接口</strong></h2><p><strong>获取分区的定义</strong></p>
<p>在RDD类中定义了getPartition方法，返回一个Partition列表，Partition对象只含有一个编码index字段，不同RDD的partition会继承Partition类，例如JdbcPartition、KafkaRDDPartition，HadoopPartition等。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RDD</span></span>&#123;</span><br><span class="line">	<span class="comment">// 获取分区定义</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">getPartitions</span></span>:<span class="type">Array</span>[<span class="type">Partition</span>]</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// Partition类定义</span></span><br><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">Partition</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">index</span></span>:<span class="type">Int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="2-2-实现"><a href="#2-2-实现" class="headerlink" title="2.2. 实现"></a>2.2. <strong>实现</strong></h2><p><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/sparkcore/wpsC537.tmp.jpg" alt="img"> </p>
<p>transformation类型的RDD分区数量和父RDD的保持一致，Action类型的RDD分区数量，不同的数据源默认值不一样，获取的方式也不同</p>
<h3 id="2-2-1-KafkaRDD"><a href="#2-2-1-KafkaRDD" class="headerlink" title="2.2.1. KafkaRDD"></a>2.2.1. <strong>KafkaRDD</strong></h3><p>kafkaRDD的partition数量等于compute方法中生成OffsetRange的数量。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// DirectKafkaInputDStream类在接收到消息后通过compute方法计算得到OffsetRange</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OffsetRange</span>(<span class="params"> </span></span></span><br><span class="line"><span class="class"><span class="params">	val topic:<span class="type">String</span>, // <span class="type">Kafka</span> topic name</span></span></span><br><span class="line"><span class="class"><span class="params">	val partition:<span class="type">Int</span>, // <span class="type">Kafka</span> partition id</span></span></span><br><span class="line"><span class="class"><span class="params">	val fromOffset:<span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">	val untilOffset:<span class="type">Long</span></span></span></span><br><span class="line"><span class="class"><span class="params"></span>)</span>&#123;...&#125;</span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KafkaRDD</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">		val offsetRages:<span class="type">Array</span>[<span class="type">OffsetRange</span>]</span></span></span><br><span class="line"><span class="class"><span class="params">	</span>) <span class="keyword">extends</span> <span class="title">RDD</span></span>&#123;</span><br><span class="line">	<span class="comment">// 遍历OffsetRange数组，得到数组下标和偏移量等信息生成KafkaRDDPartition</span></span><br><span class="line">	offsetRanges.zipWithIndex.map&#123;</span><br><span class="line">		<span class="keyword">case</span>(o,i)=&gt;</span><br><span class="line">			<span class="keyword">new</span> <span class="type">KafkaRDDPartition</span>(</span><br><span class="line">				i,o.topic,o.partition,</span><br><span class="line">				o.fromOffset,o.untilOffset</span><br><span class="line">			)</span><br><span class="line">	&#125;.toArray</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="2-2-2-HadoopRDD"><a href="#2-2-2-HadoopRDD" class="headerlink" title="2.2.2. HadoopRDD"></a>2.2.2. <strong>HadoopRDD</strong></h3><p>HadoopRDD的分区是基于hadoop的splits方法进行的。每个partition的大小默认等于hdfs的block的大小</p>
<p>例如：一个txt文件12800M,则<br><code>val rdd1=sc.textFile(&quot;/data.txt&quot;);</code><br>rdd1默认会有12800/128=10个分区。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HadoopRDD</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 生成一个RDD的唯一ID</span></span><br><span class="line">	<span class="keyword">val</span> id=<span class="type">Int</span>=sc.newRddId()</span><br><span class="line"> </span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">getPartitions</span></span>:<span class="type">Array</span>[<span class="type">Partition</span>]=&#123;</span><br><span class="line">		<span class="comment">// 调用hadoop的splits方法进行切割</span></span><br><span class="line">		<span class="keyword">val</span> inputSplits=inputFormat.getSplits(</span><br><span class="line">			jobConf,minPartitions</span><br><span class="line">		)</span><br><span class="line">		<span class="comment">// 组成spark的partition</span></span><br><span class="line">		<span class="keyword">val</span> array=<span class="keyword">new</span> <span class="type">Array</span>[<span class="type">Partition</span>](inputSplits.size)</span><br><span class="line">		<span class="keyword">for</span>(i &lt;- <span class="number">0</span> until inputSplits.size)&#123;</span><br><span class="line">			array(i)=<span class="keyword">new</span> <span class="type">HadoopPartition</span>(id,i,</span><br><span class="line">				inputSplits(i))</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>hadoop的FileInputFormat类：<br>texfile的分区大小时指定的分区数和block树中取较大值，所以当指定numPartitions，小于block数时无效，大于则生效</p>
<h3 id="2-2-3-JdbcRDD"><a href="#2-2-3-JdbcRDD" class="headerlink" title="2.2.3. JdbcRDD"></a>2.2.3. <strong>JdbcRDD</strong></h3><p>JDBC的partition划分是指定开始行和结束行，然后将查询到的结果分为3个（默认值）partition。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JdbcRDD</span>(<span class="params">numPartitions:<span class="type">Int</span></span>)</span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">getPartitions</span></span>:<span class="type">Array</span>[<span class="type">Partition</span>]=&#123;</span><br><span class="line">		(<span class="number">0</span> until numPartitions).map&#123;</span><br><span class="line">			<span class="keyword">new</span> <span class="type">JdbcPartition</span>(i,start,end)</span><br><span class="line">		&#125;.toArray</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="2-2-4-MapPartitionsRDD"><a href="#2-2-4-MapPartitionsRDD" class="headerlink" title="2.2.4. MapPartitionsRDD"></a>2.2.4. <strong>MapPartitionsRDD</strong></h3><p>转换类的RDD分区数量是由其父类的分区数决定的</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取父RDD列表的第一个RDD</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RDD</span></span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">firstParent</span></span>:<span class="type">RDD</span>=&#123;</span><br><span class="line">		dependencies.head.rdd.asInstanceOf[<span class="type">RDD</span>]</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MapPartitionsRDD</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">	<span class="comment">// 获取父RDD的partitions数量</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">getPartitions</span></span>: <span class="type">Array</span>[<span class="type">Partition</span>] = 			firstParent[<span class="type">T</span>].partitions</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="3-分区数量"><a href="#3-分区数量" class="headerlink" title="3. 分区数量"></a>3. <strong>分区数量</strong></h1><p><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/sparkcore/wpsC557.tmp.jpg" alt="img"> </p>
<p>分区数量的原则：尽可能的选择大的分区值</p>
<h2 id="3-1-RDD初始化相关"><a href="#3-1-RDD初始化相关" class="headerlink" title="3.1. RDD初始化相关"></a>3.1. <strong>RDD初始化相关</strong></h2><table>
<thead>
<tr>
<th>Spark API</th>
<th>partition数量</th>
</tr>
</thead>
<tbody>
<tr>
<td>sc.parallelize(…)</td>
<td>sc.defaultParallelism</td>
</tr>
<tr>
<td>sc.textFile(…)</td>
<td>max(传参, block数)</td>
</tr>
<tr>
<td>sc.newAPIHadoopRDD(…)</td>
<td>max(传参, block数)</td>
</tr>
<tr>
<td>new JdbcRDD(…)</td>
<td>传参</td>
</tr>
</tbody>
</table>
<h2 id="3-2-通用transformation"><a href="#3-2-通用transformation" class="headerlink" title="3.2. 通用transformation"></a>3.2. <strong>通用transformation</strong></h2><ul>
<li>filter(),map(),flatMap(),distinct()：和父RDD相同</li>
<li>union： 两个RDD的和rdd.union(otherRDD)：rdd.partitions.size + otherRDD. partitions.size</li>
<li>intersection：取较大的rdd.intersection(otherRDD)：max(rdd.partitions.size, otherRDD. partitions.size)</li>
<li>rdd.subtract(otherRDD)    ：rdd.partitions.size</li>
<li>cartesian：两个RDD数量的乘积rdd.cartesian(otherRDD)：<br>rdd.partitions.size * otherRDD. partitions.size</li>
</ul>
<h2 id="3-3-Key-based-Transformations"><a href="#3-3-Key-based-Transformations" class="headerlink" title="3.3. Key-based Transformations"></a>3.3. <strong>Key-based Transformations</strong></h2><p>reduceByKey(),foldByKey(),combineByKey(), groupByKey(),sortByKey(),mapValues(),flatMapValues()    和父RDD相同</p>
<p>cogroup(), join(), ,leftOuterJoin(), rightOuterJoin():<br>所有父RDD按照其partition数降序排列，从partition数最大的RDD开始查找是否存在partitioner，存在则partition数由此partitioner确定，否则，所有RDD不存在partitioner，由spark.default.parallelism确定，若还没设置，最后partition数为所有RDD中partition数的最大值</p>
<h1 id="4-分区器"><a href="#4-分区器" class="headerlink" title="4. 分区器"></a>4. <strong>分区器</strong></h1><p><strong>注意：只有Key-Value类型的RDD才有分区的，非Key-Value类型的RDD分区的值是None的</strong></p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Partitioner</span> <span class="keyword">extends</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">numPartitions</span></span>: <span class="type">Int</span> <span class="comment">// 分区数量</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getPartition</span></span>(key: <span class="type">Any</span>): <span class="type">Int</span> <span class="comment">// 分区编号</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="4-1-作用"><a href="#4-1-作用" class="headerlink" title="4.1. 作用"></a>4.1. <strong>作用</strong></h2><p>partitioner分区器作用：</p>
<ol>
<li>决定Shuffle过程中Reducer个数（实际上是子RDD的分区个数）以及Map端一条数据记录应该分配给那几个Reducer</li>
<li>决定RDD的分区数量，例如执行groupByKey(new HashPartitioner(2))所生成的ShuffledRDD中，分区数目等于2</li>
<li>决定CoGroupedRDD与父RDD之间的依赖关系</li>
</ol>
<h2 id="4-2-种类"><a href="#4-2-种类" class="headerlink" title="4.2. 种类"></a>4.2. <strong>种类</strong></h2><p><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/sparkcore/wpsC559.tmp.jpg" alt="img"> </p>
<p>分区器的选择：</p>
<ol>
<li>如果RDD已经有了分区器，则在已有分区器里面挑选分区数量最多的一个分区器。</li>
<li>如果RDD没有指定分区器，则默认使用HashPartitioner分区器。</li>
<li>用户可以自己声明RangePartitioner分区器</li>
</ol>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Partitioner</span></span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">defaultPartitioner</span></span>(rdd):<span class="type">Partitioner</span>=&#123;</span><br><span class="line">		<span class="keyword">val</span> hasPartitioner=</span><br><span class="line">			rdds.filter(</span><br><span class="line">				_.partitioner.exists(_numPartitions&gt;<span class="number">0</span>))</span><br><span class="line">			&#125;</span><br><span class="line">		<span class="comment">// 如果RDD已经有分区则选取其分区数最多的</span></span><br><span class="line">		<span class="keyword">if</span>(hasPartitioner.nonEmpty)&#123;</span><br><span class="line">			hasPartitioner.maxBy(_.partitions.length).</span><br><span class="line">				partitioner.get</span><br><span class="line">		&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">			<span class="keyword">if</span>(rdd.context.conf.contains(</span><br><span class="line">				<span class="string">"spark.default.parallelism"</span></span><br><span class="line">			))&#123;</span><br><span class="line">				<span class="comment">// 如果在conf中配置了分区数则用之</span></span><br><span class="line">				<span class="keyword">new</span> <span class="type">HashPartitioner</span>(</span><br><span class="line">					rdd.context.defaultParallelism</span><br><span class="line">				)</span><br><span class="line">			&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">				<span class="comment">// 如果没有配置parallelism则和父RDD中最大的保持一致</span></span><br><span class="line">				<span class="keyword">new</span> <span class="type">HashPartitioner</span>(rdds.map(</span><br><span class="line">					_.partitions.length</span><br><span class="line">				).max)</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="4-2-1-HashPartitioner"><a href="#4-2-1-HashPartitioner" class="headerlink" title="4.2.1. HashPartitioner"></a>4.2.1. <strong>HashPartitioner</strong></h3><p>HashPartitioner分区的原理很简单，对于给定的key，计算其hashCode，并除于分区的个数取余，<strong>如果余数小于0，则用余数+分区的个数，最后返回的值就是这个key所属的分区ID</strong></p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HashPartitioner</span>(<span class="params">partitions:<span class="type">Int</span></span>) </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">getPartition</span></span>(key:<span class="type">Any</span>):<span class="type">Int</span>=key <span class="keyword">match</span>&#123;</span><br><span class="line">		<span class="keyword">case</span> <span class="literal">null</span>=&gt; <span class="number">0</span></span><br><span class="line">		<span class="keyword">case</span> _=&gt; nonNegativeMod(key.hashCode, numPartitions)</span><br><span class="line">	&#125;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">nonNegativeMod</span></span>(x: <span class="type">Int</span>, mod: <span class="type">Int</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> rawMod = x % mod</span><br><span class="line">    rawMod + (<span class="keyword">if</span> (rawMod &lt; <span class="number">0</span>) mod <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line">  &#125;	</span><br><span class="line">	<span class="comment">// 判断两个RDD分区方式是否一样</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">equals</span></span>(other:<span class="type">Any</span>):<span class="type">Boolean</span>= other <span class="keyword">match</span>&#123;</span><br><span class="line">		<span class="keyword">case</span> h:<span class="type">HashPartitioner</span> =&gt; </span><br><span class="line">			h.numPartitions==numPartitions</span><br><span class="line">		<span class="keyword">case</span>  _ =&gt; <span class="literal">false</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="4-2-2-RangePartitioner"><a href="#4-2-2-RangePartitioner" class="headerlink" title="4.2.2. RangePartitioner"></a>4.2.2. <strong>RangePartitioner</strong></h3><p><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/sparkcore/wpsC55A.tmp.jpg" alt="img"> </p>
<p>HashPartitioner分区可能导致每个分区中数据量的不均匀。而RangePartitioner分区则尽量保证每个分区中数据量的均匀，将一定范围内的数映射到某一个分区内。分区与分区之间数据是有序的，但分区内的元素是不能保证顺序的。</p>
<p>  RangePartitioner分区执行原理：</p>
<ol>
<li>计算总体的数据抽样大小sampleSize，计算规则是：至少每个分区抽取20个数据或者最多1M的数据量。</li>
<li>根据sampleSize和分区数量计算每个分区的数据抽样样本数量最大值sampleSizePrePartition</li>
<li>根据以上两个值进行水塘抽样，返回RDD的总数据量，分区ID和每个分区的采样数据。</li>
<li>计算出数据量较大的分区通过RDD.sample进行重新抽样。</li>
<li>通过抽样数组 candidates: ArrayBuffer[(K, wiegth)]计算出分区边界的数组BoundsArray</li>
<li>在取数据时，如果分区数小于128则直接获取，如果大于128则通过二分法，获取当前Key属于那个区间，返回对应的BoundsArray下标即为partitionsID</li>
</ol>
<p>一句话概括：<strong>就是遍历每个paritiion，对里面的数据进行抽样，把抽样的数据进行排序，并按照对应的权重确定边界</strong></p>
<h4 id="4-2-2-1-获取区间数组"><a href="#4-2-2-1-获取区间数组" class="headerlink" title="4.2.2.1. 获取区间数组"></a>4.2.2.1. <strong>获取区间数组</strong></h4><p><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/sparkcore/wpsC56B.tmp.jpg" alt="img"> </p>
<h5 id="4-2-2-1-1-给定样本总数"><a href="#4-2-2-1-1-给定样本总数" class="headerlink" title="4.2.2.1.1. 给定样本总数"></a>4.2.2.1.1. <strong>给定样本总数</strong></h5><p>给定总的数据抽样大小，最多1M的数据量(10^6)，最少20倍的RDD分区数量，也就是每个RDD分区至少抽取20条数据<br>​<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RangePartitioner</span>(<span class="params">partitions,rdd</span>) </span>&#123;</span><br><span class="line"><span class="comment">// 1. 计算样本大小</span></span><br><span class="line"> <span class="keyword">val</span> sampleSize =math.min(<span class="number">20.0</span> * partitions, <span class="number">1e6</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h5 id="4-2-2-1-2-计算样本最大值"><a href="#4-2-2-1-2-计算样本最大值" class="headerlink" title="4.2.2.1.2. 计算样本最大值"></a>4.2.2.1.2. <strong>计算样本最大值</strong></h5><p>RDD各分区中的数据量可能会出现倾斜的情况，乘于3的目的就是保证数据量小的分区能够采样到足够的数据，而对于数据量大的分区会进行第二次采样</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RangePartitioner</span>(<span class="params">partitions,rdd</span>) </span>&#123;</span><br><span class="line">​	</span><br><span class="line"><span class="comment">// 1. 计算样本大小</span></span><br><span class="line"> <span class="keyword">val</span> sampleSize = </span><br><span class="line">​			math.min(<span class="number">20.0</span> * partitions, <span class="number">1e6</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 2. 计算样本最大值</span></span><br><span class="line"><span class="keyword">val</span> sampleSizePerPartition = </span><br><span class="line">​	math.ceil(</span><br><span class="line">​		<span class="number">3.0</span> * sampleSize / rdd.partitions.length</span><br><span class="line">​	).toInt</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="4-2-2-1-3-水塘抽样"><a href="#4-2-2-1-3-水塘抽样" class="headerlink" title="4.2.2.1.3. 水塘抽样"></a>4.2.2.1.3. <strong>水塘抽样</strong></h5><p>根据以上两个值进行水塘抽样，返回RDD的总数据量，分区ID和每个分区的采样数据。其中总数据量通过遍历RDD所有partition的key累加得到的，不是通过rdd.count计算得到的</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RangePartitioner</span>(<span class="params">partitions,rdd</span>) </span>&#123;</span><br><span class="line">	</span><br><span class="line"><span class="comment">// 1. 计算样本大小</span></span><br><span class="line"> <span class="keyword">val</span> sampleSize =math.min(<span class="number">20.0</span> * partitions, <span class="number">1e6</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 2. 计算样本最大值</span></span><br><span class="line"><span class="keyword">val</span> sampleSizePerPartition = </span><br><span class="line">	math.ceil(</span><br><span class="line">		<span class="number">3.0</span> * sampleSize / rdd.partitions.length</span><br><span class="line">	).toInt</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 3. 进行抽样，返回总数据量，分区ID和样本数据</span></span><br><span class="line"><span class="keyword">val</span> (numItems, sketched) = <span class="type">RangePartitioner</span>.sketch(</span><br><span class="line">		rdd.map(_._1), sampleSizePerPartition)</span><br></pre></td></tr></table></figure>
<h5 id="4-2-2-1-4-是否需要二次采样"><a href="#4-2-2-1-4-是否需要二次采样" class="headerlink" title="4.2.2.1.4. 是否需要二次采样"></a>4.2.2.1.4. <strong>是否需要二次采样</strong></h5><p>如果有较大RDD存在，则按照平均值去采样的话数据量太少，容易造成数据倾斜，所以需要进行二次采样</p>
<p>判断是否需要重新采样方法：<br>样本数量占比乘以当前RDD的总行数大于预设的每个RDD最大抽取数量，说明这个RDD的数据量比较大，需要采样更多的数据：eg: 0.2<em>100=20&lt;60;0.2</em>20000=2000&gt;60</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RangePartitioner</span>(<span class="params">partitions,rdd</span>) </span>&#123;</span><br><span class="line">	</span><br><span class="line"><span class="comment">// 1. 计算样本大小</span></span><br><span class="line"> <span class="keyword">val</span> sampleSize =math.min(<span class="number">20.0</span> * partitions, <span class="number">1e6</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 2. 计算样本最大值</span></span><br><span class="line"><span class="keyword">val</span> sampleSizePerPartition = </span><br><span class="line">	math.ceil(</span><br><span class="line">		<span class="number">3.0</span> * sampleSize / rdd.partitions.length</span><br><span class="line">	).toInt</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 3. 进行抽样，返回总数据量，分区ID和样本数据</span></span><br><span class="line"><span class="keyword">val</span> (numItems, sketched) = <span class="type">RangePartitioner</span>.sketch(</span><br><span class="line">		rdd.map(_._1), sampleSizePerPartition)</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 4. 是否需要二次采样</span></span><br><span class="line"><span class="keyword">val</span> imbalancedPartitions = 	mutable.<span class="type">Set</span>.empty[<span class="type">Int</span>]</span><br><span class="line"> <span class="keyword">if</span> (fraction * n &gt; sampleSizePerPartition) &#123;</span><br><span class="line">	<span class="comment">// 记录需要重新采样的RDD的ID</span></span><br><span class="line">	imbalancedPartitions += idx </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="4-2-2-1-5-计算样本权重"><a href="#4-2-2-1-5-计算样本权重" class="headerlink" title="4.2.2.1.5. 计算样本权重"></a>4.2.2.1.5. <strong>计算样本权重</strong></h5><p>计算每个采样数据的权重占比，根据采样数据的ID和权重生成出RDD分区边界数组</p>
<p>权重计算方法：总数据量/当前RDD的采样数据量</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RangePartitioner</span>(<span class="params">partitions,rdd</span>) </span>&#123;</span><br><span class="line">​	</span><br><span class="line"><span class="comment">// 1. 计算样本大小</span></span><br><span class="line"> <span class="keyword">val</span> sampleSize = </span><br><span class="line">​			math.min(<span class="number">20.0</span> * partitions, <span class="number">1e6</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 2. 计算样本最大值</span></span><br><span class="line"><span class="keyword">val</span> sampleSizePerPartition = </span><br><span class="line">​	math.ceil(</span><br><span class="line">​		<span class="number">3.0</span> * sampleSize / rdd.partitions.length</span><br><span class="line">​	).toInt</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 3. 进行抽样，返回总数据量，分区ID和样本数据</span></span><br><span class="line"><span class="keyword">val</span> (numItems, sketched) = 		<span class="type">RangePartitioner</span>.sketch(</span><br><span class="line">​		rdd.map(_._1), sampleSizePerPartition)</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 4. 是否需要二次采样</span></span><br><span class="line"><span class="keyword">val</span> imbalancedPartitions = 	mutable.<span class="type">Set</span>.empty[<span class="type">Int</span>]</span><br><span class="line"> </span><br><span class="line"><span class="comment">//  5. 保存样本数据的集合buffer:包含数据和权重</span></span><br><span class="line"><span class="keyword">val</span> candidates = <span class="type">ArrayBuffer</span>.empty[(<span class="type">K</span>, <span class="type">Float</span>)]</span><br><span class="line"> </span><br><span class="line"> <span class="keyword">if</span> (fraction * n &gt; sampleSizePerPartition) &#123;</span><br><span class="line">​	<span class="comment">// 记录需要重新采样的RDD的ID</span></span><br><span class="line">​	imbalancedPartitions += idx </span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line"><span class="comment">// 5. 计算样本权重</span></span><br><span class="line">​	<span class="keyword">val</span> weight = (</span><br><span class="line">​	  <span class="comment">// 采样数据的占比</span></span><br><span class="line">​		n.toDouble / sample.length).toFloat </span><br><span class="line">​            <span class="keyword">for</span> (key &lt;- sample) &#123;</span><br><span class="line">​			<span class="comment">// 记录采样数据key和权重</span></span><br><span class="line">​              candidates += ((key, weight))</span><br><span class="line">​            &#125;</span><br><span class="line">​	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="4-2-2-1-6-二次抽样"><a href="#4-2-2-1-6-二次抽样" class="headerlink" title="4.2.2.1.6. 二次抽样"></a>4.2.2.1.6. <strong>二次抽样</strong></h5><p> 对于数据分布不均衡的RDD分区，重新进行二次抽样。<br>二次抽样采用的是RDD的采样方法：RDD.sample</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RangePartitioner</span>(<span class="params">partitions,rdd</span>) </span>&#123;</span><br><span class="line">​	</span><br><span class="line"><span class="comment">// 1. 计算样本大小</span></span><br><span class="line"> <span class="keyword">val</span> sampleSize = </span><br><span class="line">​			math.min(<span class="number">20.0</span> * partitions, <span class="number">1e6</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 2. 计算样本最大值</span></span><br><span class="line"><span class="keyword">val</span> sampleSizePerPartition = </span><br><span class="line">​	math.ceil(</span><br><span class="line">​		<span class="number">3.0</span> * sampleSize / rdd.partitions.length</span><br><span class="line">​	).toInt</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 3. 进行抽样，返回总数据量，分区ID和样本数据</span></span><br><span class="line"><span class="keyword">val</span> (numItems, sketched) = 		<span class="type">RangePartitioner</span>.sketch(</span><br><span class="line">​		rdd.map(_._1), sampleSizePerPartition)</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 4. 是否需要二次采样</span></span><br><span class="line"><span class="keyword">val</span> imbalancedPartitions = 	mutable.<span class="type">Set</span>.empty[<span class="type">Int</span>]</span><br><span class="line"> </span><br><span class="line"><span class="comment">//  5. 保存样本数据的集合buffer:包含数据和权重</span></span><br><span class="line"><span class="keyword">val</span> candidates = <span class="type">ArrayBuffer</span>.empty[(<span class="type">K</span>, <span class="type">Float</span>)]</span><br><span class="line"> </span><br><span class="line"> <span class="keyword">if</span> (fraction * n &gt; sampleSizePerPartition) &#123;</span><br><span class="line">​	<span class="comment">// 记录需要重新采样的RDD的ID</span></span><br><span class="line">​	imbalancedPartitions += idx </span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line"><span class="comment">// 5. 计算样本权重</span></span><br><span class="line">​	<span class="keyword">val</span> weight = (</span><br><span class="line">​	  <span class="comment">// 采样数据的占比</span></span><br><span class="line">​		n.toDouble / sample.length).toFloat </span><br><span class="line">​            <span class="keyword">for</span> (key &lt;- sample) &#123;</span><br><span class="line">​			<span class="comment">// 记录采样数据key和权重</span></span><br><span class="line">​              candidates += ((key, weight))</span><br><span class="line">​            &#125;</span><br><span class="line">​	&#125;</span><br><span class="line"><span class="comment">// 6. 对于数据分布不均衡的RDD分区，重新数据抽样</span></span><br><span class="line"><span class="keyword">if</span> (imbalancedPartitions.nonEmpty) &#123;</span><br><span class="line">​	<span class="comment">// 利用rdd的sample抽样函数API进行数据抽样</span></span><br><span class="line">​          <span class="keyword">val</span> reSampled = imbalanced.sample(</span><br><span class="line">​				withReplacement = </span><br><span class="line">​					<span class="literal">false</span>, fraction, seed).collect()</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="4-2-2-1-7-生成边界数组"><a href="#4-2-2-1-7-生成边界数组" class="headerlink" title="4.2.2.1.7. 生成边界数组"></a>4.2.2.1.7. <strong>生成边界数组</strong></h5><p>将最终的抽样数据计算出分区边界数组返回，边界数组里面存放的是RDD里面数据的key值，<br>比如最终返回的数组是：array[0,10,20,30..]<br>其中0,10,20,30是采样数据中的key值，对于每一条数据都会判断其在此数组的那个区间中间，例如有一条数据key值是3则其在0到10之间，属于第一个分区，同理Key值为15的数据在第二个分区</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RangePartitioner</span>(<span class="params">partitions,rdd</span>) </span>&#123;</span><br><span class="line">​	</span><br><span class="line"><span class="comment">// 1. 计算样本大小</span></span><br><span class="line"> <span class="keyword">val</span> sampleSize = </span><br><span class="line">​			math.min(<span class="number">20.0</span> * partitions, <span class="number">1e6</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 2. 计算样本最大值</span></span><br><span class="line"><span class="keyword">val</span> sampleSizePerPartition = </span><br><span class="line">​	math.ceil(</span><br><span class="line">​		<span class="number">3.0</span> * sampleSize / rdd.partitions.length</span><br><span class="line">​	).toInt</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 3. 进行抽样，返回总数据量，分区ID和样本数据</span></span><br><span class="line"><span class="keyword">val</span> (numItems, sketched) = 		<span class="type">RangePartitioner</span>.sketch(</span><br><span class="line">​		rdd.map(_._1), sampleSizePerPartition)</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 4. 是否需要二次采样</span></span><br><span class="line"><span class="keyword">val</span> imbalancedPartitions = 	mutable.<span class="type">Set</span>.empty[<span class="type">Int</span>]</span><br><span class="line"> </span><br><span class="line"><span class="comment">//  5. 保存样本数据的集合buffer:包含数据和权重</span></span><br><span class="line"><span class="keyword">val</span> candidates = <span class="type">ArrayBuffer</span>.empty[(<span class="type">K</span>, <span class="type">Float</span>)]</span><br><span class="line"> </span><br><span class="line"> <span class="keyword">if</span> (fraction * n &gt; sampleSizePerPartition) &#123;</span><br><span class="line">​	<span class="comment">// 记录需要重新采样的RDD的ID</span></span><br><span class="line">​	imbalancedPartitions += idx </span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line"><span class="comment">// 5. 计算样本权重</span></span><br><span class="line">​	<span class="keyword">val</span> weight = (</span><br><span class="line">​	  <span class="comment">// 采样数据的占比</span></span><br><span class="line">​		n.toDouble / sample.length).toFloat </span><br><span class="line">​            <span class="keyword">for</span> (key &lt;- sample) &#123;</span><br><span class="line">​			<span class="comment">// 记录采样数据key和权重</span></span><br><span class="line">​              candidates += ((key, weight))</span><br><span class="line">​            &#125;</span><br><span class="line">​	&#125;</span><br><span class="line"><span class="comment">// 6. 对于数据分布不均衡的RDD分区，重新数据抽样</span></span><br><span class="line"><span class="keyword">if</span> (imbalancedPartitions.nonEmpty) &#123;</span><br><span class="line">​	<span class="comment">// 利用rdd的sample抽样函数API进行数据抽样</span></span><br><span class="line">​          <span class="keyword">val</span> reSampled = imbalanced.sample(</span><br><span class="line">​				withReplacement = </span><br><span class="line">​					<span class="literal">false</span>, fraction, seed).collect()</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 7. 生成边界数组</span></span><br><span class="line"><span class="type">RangePartitioner</span>.determineBounds(</span><br><span class="line">​	candidates, partitions)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="4-2-2-2-水塘抽样算法"><a href="#4-2-2-2-水塘抽样算法" class="headerlink" title="4.2.2.2. 水塘抽样算法"></a>4.2.2.2. <strong>水塘抽样算法</strong></h4><p>水塘抽样概念：<br>它是一系列的随机算法，其目的在于从包含n个项目的集合S中选取k个样本，使得每条数据抽中的概率是k/n。其中n为一很大或未知的数量，尤其适用于不能把所有n个项目都存放到主内存的情况</p>
<p>我们可以：定义取出的行号为choice，第一次直接以第一行作为取出行 choice ，而后第二次以二分之一概率决定是否用第二行替换 choice ，第三次以三分之一的概率决定是否以第三行替换 choice ……，以此类推。由上面的分析我们可以得出结论，在取第n个数据的时候，我们生成一个0到1的随机数p，如果p小于1/n，保留第n个数。大于1/n，继续保留前面的数。直到数据流结束，返回此数，算法结束。</p>
<p>详见：<br><a href="https://www.iteblog.com/archives/1525.html" target="_blank" rel="noopener">https://www.iteblog.com/archives/1525.html</a><br><a href="https://my.oschina.net/freelili/blog/2987667" target="_blank" rel="noopener">https://my.oschina.net/freelili/blog/2987667</a></p>
<p> 实现：</p>
<ol>
<li>获取到需要抽样RDD分区的样本大小k和分区的所有KEY数组input</li>
<li>初始化抽样结果集reservoir为分区前K个KEY值</li>
<li>如果分区的总数小于预计样本大小k,则将当前分区的所有数据作为样本数据，否则到第四步</li>
<li>遍历分区里所有Key组成的数组input</li>
<li>生成随机需要替换input数组的下标，如果下标小于K则替换</li>
<li>返回抽取的key值数组和当前分区的总数据量： (reservoir, l)</li>
</ol>
<p>难点：<br><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"> <span class="comment">// 计算出需要替换的数组下标</span></span><br><span class="line"><span class="comment">// 选取第n个数的概率是：n/l; 如果随机替换数组值的概率是p=rand.nextDouble，</span></span><br><span class="line"><span class="comment">// 则如果p&lt;k/l;则替换池中任意一个数，即： p*l &lt; k 则进行替换，用p*l作为随机替换的下标</span></span><br><span class="line"> <span class="keyword">val</span> replacementIndex = (rand.nextDouble() * l).toLong</span><br><span class="line"><span class="keyword">if</span> (replacementIndex &lt; k) &#123;</span><br><span class="line"><span class="comment">// 替换reservoir[随机抽取的下标]的值为input[l]的值item</span></span><br><span class="line">          reservoir(replacementIndex.toInt) = item</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="4-2-2-3-定位分区ID"><a href="#4-2-2-3-定位分区ID" class="headerlink" title="4.2.2.3. 定位分区ID"></a>4.2.2.3. <strong>定位分区ID</strong></h4><p><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/sparkcore/wpsC56C.tmp.jpg" alt="img"> </p>
<p>如果分区边界数组的大小小于或等于128的时候直接变量数组，否则采用二分查找法确定key属于某个分区。</p>
<h5 id="4-2-2-3-1-数组直接获取"><a href="#4-2-2-3-1-数组直接获取" class="headerlink" title="4.2.2.3.1. 数组直接获取"></a>4.2.2.3.1. <strong>数组直接获取</strong></h5><p>遍历数组，判断当前key值是否属于当前区间</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 根据RDD的key值返回对应的分区id。从0开始</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getPartition</span></span>(key: <span class="type">Any</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">​    <span class="comment">// 强制转换key类型为RDD中原本的数据类型</span></span><br><span class="line">​    <span class="keyword">val</span> k = key.asInstanceOf[<span class="type">K</span>]</span><br><span class="line">​    <span class="keyword">var</span> partition = <span class="number">0</span></span><br><span class="line">​    <span class="keyword">if</span> (rangeBounds.length &lt;= <span class="number">128</span>) &#123;</span><br><span class="line">​      <span class="comment">// 如果分区数据小于等于128个，那么直接本地循环寻找当前k所属的分区下标</span></span><br><span class="line">​      <span class="comment">// ordering.gt(x,y):如果x&gt;y,则返回true</span></span><br><span class="line">​      <span class="keyword">while</span> (partition &lt; rangeBounds.length &amp;&amp; ordering.gt(k, rangeBounds(partition))) &#123;</span><br><span class="line">​        partition += <span class="number">1</span></span><br><span class="line">​      &#125;</span><br></pre></td></tr></table></figure>
<h5 id="4-2-2-3-2-二分法查找"><a href="#4-2-2-3-2-二分法查找" class="headerlink" title="4.2.2.3.2. 二分法查找"></a>4.2.2.3.2. <strong>二分法查找</strong></h5><p>对于分区数大于128的情况，采样二分法查找<br> <figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"> <span class="comment">// 根据RDD的key值返回对应的分区id。从0开始</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getPartition</span></span>(key: <span class="type">Any</span>): <span class="type">Int</span> = &#123;</span><br><span class="line"> <span class="comment">// 如果分区数量大于128个，那么使用二分查找方法寻找对应k所属的下标;</span></span><br><span class="line">​      <span class="comment">// 但是如果k在rangeBounds中没有出现，实质上返回的是一个负数(范围)或者是一个超过rangeBounds大小的数(最后一个分区，比所有数据都大)</span></span><br><span class="line">​      <span class="comment">// Determine which binary search method to use only once.</span></span><br><span class="line">​      partition = binarySearch(rangeBounds, k)</span><br><span class="line">​      <span class="comment">// binarySearch either returns the match location or -[insertion point]-1</span></span><br><span class="line">​      <span class="keyword">if</span> (partition &lt; <span class="number">0</span>) &#123;</span><br><span class="line">​        partition = -partition<span class="number">-1</span></span><br><span class="line">​      &#125;</span><br><span class="line">​      <span class="keyword">if</span> (partition &gt; rangeBounds.length) &#123;</span><br><span class="line">​        partition = rangeBounds.length</span><br><span class="line">​      &#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="5-自定义分区器"><a href="#5-自定义分区器" class="headerlink" title="5. 自定义分区器"></a>5. <strong>自定义分区器</strong></h1><p>自定义：</p>
<ol>
<li>继承Partitioner方法，</li>
<li>重写getPartition、numPartitions、equals等方法。<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">public <span class="class"><span class="keyword">class</span> <span class="title">MyPartioner</span> <span class="keyword">extends</span> <span class="title">Partitioner</span> </span>&#123; </span><br><span class="line">    <span class="meta">@Override</span> </span><br><span class="line">    public int numPartitions() &#123; </span><br><span class="line">        <span class="keyword">return</span> <span class="number">1000</span>; </span><br><span class="line">    &#125; </span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span> </span><br><span class="line">    public int getPartition(<span class="type">Object</span> key) &#123; </span><br><span class="line">        <span class="type">String</span> k = (<span class="type">String</span>) key; </span><br><span class="line">        int code = k.hashCode() % <span class="number">1000</span>; </span><br><span class="line">        <span class="type">System</span>.out.println(k+<span class="string">":"</span>+code); </span><br><span class="line">        <span class="keyword">return</span>  code &lt; <span class="number">0</span>?code+<span class="number">1000</span>:code; </span><br><span class="line">    &#125; </span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span> </span><br><span class="line">    public boolean equals(<span class="type">Object</span> obj) &#123; </span><br><span class="line">        <span class="keyword">if</span>(obj instanceof <span class="type">MyPartioner</span>)&#123; </span><br><span class="line">            <span class="keyword">if</span>(<span class="keyword">this</span>.numPartitions()==((<span class="type">MyPartioner</span>) obj).numPartitions())&#123; </span><br><span class="line">                <span class="keyword">return</span> <span class="literal">true</span>; </span><br><span class="line">            &#125; </span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>; </span><br><span class="line">        &#125; </span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">super</span>.equals(obj); </span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>调用：<code>pairRdd.groupbykey(new MyPartitioner())</code></p>
<p>参考链接：<a href="https://ihainan.gitbooks.io/spark-source-code/content/section1/rddPartitions.html" target="_blank" rel="noopener">https://ihainan.gitbooks.io/spark-source-code/content/section1/rddPartitions.html</a></p>

    
  </div>

</article>


   
  <div class="text-center donation">
    <div class="inner-donation">
      <span class="btn-donation">支持一下</span>
      <div class="donation-body">
        <div class="tip text-center">扫一扫，支持sustcoder</div>
        <ul>
        
          <li class="item">
            
              <span>微信扫一扫</span>
            
            <img src="/images/qr-wechat.png" alt="">
          </li>
        
          <li class="item">
            
              <span>支付宝扫一扫</span>
            
            <img src="/images/qr-alipay.png" alt="">
          </li>
        
        </ul>
      </div>
    </div>
  </div>


   
  <div class="box-prev-next clearfix">
    <a class="show pull-left" href="/2019/01/11/2019-01-11-bloom-filter/">
        <i class="icon icon-angle-left"></i>
    </a>
    <a class="show pull-right" href="/2019/01/14/2018-12-01-sparkCore-sorceCodeAnalysis-shuffle/">
        <i class="icon icon-angle-right"></i>
    </a>
  </div>





   
      <div class="git"></div>
   
</div>


  <a id="backTop" class="back-top">
    <i class="icon-angle-up"></i>
  </a>




  <div class="modal" id="modal">
  <span id="cover" class="cover hide"></span>
  <div id="modal-dialog" class="modal-dialog hide-dialog">
    <div class="modal-header">
      <span id="close" class="btn-close">关闭</span>
    </div>
    <hr>
    <div class="modal-body">
      <ul class="list-toolbox">
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/blog/"
              rel="noopener noreferrer"
              target="_self"
              >
              博客
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/category/"
              rel="noopener noreferrer"
              target="_self"
              >
              分类
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/tag/"
              rel="noopener noreferrer"
              target="_self"
              >
              标签
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/link/"
              rel="noopener noreferrer"
              target="_self"
              >
              友链
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/about/"
              rel="noopener noreferrer"
              target="_self"
              >
              关于
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/search/"
              rel="noopener noreferrer"
              target="_self"
              >
              搜索
            </a>
          </li>
        
      </ul>

    </div>
  </div>
</div>



  
      <div class="fexo-comments comments-post">
    
  <section class="disqus-comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>
  </section>

  <script>
    var disqus_shortname = 'forsigner';
    
    var disqus_url = 'https://sustcoder.github.io/2019/01/14/2018-12-01-sparkCore-sorceCodeAnalysis-partition/';
    
    (function(){
      var dsq = document.createElement('script');
      dsq.type = 'text/javascript';
      dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>

  <script id="dsq-count-scr" src="//forsigner.disqus.com/count.js" async></script>



    

    
    

    

    
    

  </div>

  

  <script type="text/javascript">
  function loadScript(url, callback) {
    var script = document.createElement('script')
    script.type = 'text/javascript';

    if (script.readyState) { //IE
      script.onreadystatechange = function() {
        if (script.readyState == 'loaded' ||
          script.readyState == 'complete') {
          script.onreadystatechange = null;
          callback();
        }
      };
    } else { //Others
      script.onload = function() {
        callback();
      };
    }

    script.src = url;
    document.getElementsByTagName('head')[0].appendChild(script);
  }

  window.onload = function() {
    loadScript('/js/bundle.js?235683', function() {
      // load success
    });
  }
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
