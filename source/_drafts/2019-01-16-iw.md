##### 为什么RDD要设计为稳定的？

- 保证在多个线程间共享时不会被篡改
- 在lineage graph中，我们可以在需要的时刻才去计算RDD，设计成稳定的可以保证任何时间都可以进行计算
- 由于其实不变的，我们可以将中间RDD缓存起来，提高后续RDD的计算速度，如果其实不稳定的缓存的意义就不存在了

##### 对pair RDD的理解？

- pairRDD是Resilient Distributed Dataset的子集，用来存储[key,value]格式的数据
- 常见的groupByKey(),reduceByKey(),countByKey(),jion()等函数都属于pairRDD

##### 什么是RDD？

弹性分布式数据集`Resilient Distributed Dataset`,由以下五个部分组成
- `a list of partition`  由多个机器里面的partition组成的
- `a function for computing each split`  并行计算 
- `a list of dependencies on other RDDS` rdd间存在依赖关系,记录数据转换间的依赖
- `a partitioner for key-vaue` RDDS 可进行重新分区（只有key value的partition有）
- `a list of preferred locations to compute each spilt on`  用最期望的位置进行计算

##### RDD的特点？
- `immutable`：只读，任何操作都不会改变RDD本身，只会创造新的RDD
- `fault-tolerant`：容错，通过Lineage可以高效容错
- `partitioned`：分片，RDD以partition作为最小存储和计算单元，分布在cluster的不同nodes上，一个node可以有多个partitions，一个partition只能在一个node上
- `in parallel`：并行，一个Task对应一个partition，Tasks之间相互独立可以并行计算
- `persistence`：持久化，用户可以把会被重复使用的RDDs保存到storage上（内存或者磁盘）
- `partitioning`：分区，用户可以选择RDD元素被partitioned的方式来优化计算，比如两个需要被join的数据集可以用相同的方式做hash-partitioned，这样可以减少shuffle提高性能

##### 对lineage的理解？

lineage代表了RDD之间的血缘关系，可分为逻辑关系即DAG和物理关系，通过lineage可实现延迟计算和容错机制。在程序中可通过`toDebugString`查看RDD的lineage

##### RDD,DataFrame,DataSet的区别与联系？

RDD可以提供底层功能和控制，DataSet可以支持定制的视图和结构，提供高级和特定的操作，解约空间并进行快速运行,DataFrame支持行级别的视图，DataSet支持列字段基本的结构视图。

使用RDD的场景：
- 希望可以对数据进行最基本的转换、处理和控制
- 数据是非结构化的，比如媒体流或者字符流
- 想通过编程式而不是特定领域内的表达式来处理数据

使用DataSet的场景

- 需要对半结构化数据进行高级处理，例如average,sum,Sql查询等操作
- 需要在spark库之间使用一致和简化的API
- 需要丰富语义，高级抽象和特定领域API
- 需要在编译时就有高度类型安全，想要有类型的JVM对象，用上Catalyst优化，并得益于Tungsten生成的高效代码

DataSet优点：

- 静态类型和运行时安全
- 结构化的抽象和定制视图
- 简易的API
- 执行优化：
    - DataSet创立需要一个显式的Encoder，把对象序列化为二进制，可以把对象的scheme映射为Spark
    - DataSet以Catalyst逻辑执行计划表示，并且数据以编码的二进制形式被存储，不需要反序列化就可以执行sorting、shuffle等操作SQl类型，然而RDD依赖于运行时反射机制。 
- 减少数据读取：
    - Spark SQL还可以根据数据文件中附带的统计信息来进行剪枝。简单来说，在这类数据格式中，数据是分段保存的，每段数据都带有最大值、最小值、null值数量等 一些基本的统计信息。当统计信息表名某一数据段肯定不包括符合查询条件的目标数据时，该数据段就可以直接跳过（例如某整数列a某段的最大值为100，而查询条件要求a > 200）

相互转化

- DataFrame转RDD：`dataFrame.rdd`
- RDD转DataFrame: `rdd.toDS,rdd.toDF,rdd.toDS(colName1,colName2)` 
- DataFrame和DataSet: `DataSet[T] == DataFrame[Row]`

##### DataSet的比RDD快的原因？
- Encoder: 将任何类型为T的JVM对象转换为sparkSql中的internalRow,internalRow是通过Catalyst表达式生成的二进制行格式

##### 对DAG有向无循环图的理解？与lineage的区别

一种建模思想，通过有向无循环图来描述RDD之间的依赖关系，依赖关系分为逻辑依赖和物理依赖，其中物理依赖是逆向计算的。DAG代表了正向的逻辑关系,lineage代表了逆向的物理关系。

DAGScheduler负责Spark的最高级别的任务调度，调度的粒度是Stage，它为每个Job的所有Stage计算一个有向无环图，控制它们的并发，并找到一个最佳路径来执行它们。具体的执行过程是将Stage下的Task集提交给TaskScheduler对象，由它来提交到集群上去申请资源并最终完成执行。

一个Job由一个ResultStage和多个ShuffleMapStage组成

lineage记录了当前RDD的父依赖关系，通过lineage可以在需要时再去通过父RDD计算得到当前RDD，有getCompute方法获取dependencies来计算得到。从而实现了RDD的容错。

| 名词  | 解释                                                         |
| ----- | ------------------------------------------------------------ |
| Job   | 调用RDD的一个action，如count，即触发一个Job，spark中对应实现为ActiveJob，DAGScheduler中使用集合activeJobs和jobIdToActiveJob维护Job |
| Stage | 代表一个Job的DAG，会在发生shuffle处被切分，切分后每一个部分即为一个Stage，Stage实现分为ShuffleMapStage和ResultStage，一个Job切分的结果是0个或多个ShuffleMapStage加一个ResultStage |
| Task  | 最终被发送到Executor执行的任务，和stage的ShuffleMapStage和ResultStage对应，其实现分为ShuffleMapTask和ResultTask |

##### spark的缺点？

- 不支持实时计算，spark依旧是分片级别的计算
- 小文件支持差。
- 需要借助第三方文件管理系统，如HDFS
- 优于内存计算，也限制于内存
- Job需要手动进行优化处理，并且适用于特定数据集
- 相比flink有更高的延迟
- Spark不支持基于记录的窗口标准。它只有基于时间的窗口标准

##### spark的优点？

- 基于内存计算
- 快速
- 统一的计算方法：RDD和SQL的函数几乎统一
- spark-shell方便测试
- 支持多语言
- 活跃的社区

##### spark和flink区别？

 Spark is considered as 3G of Big Data, whereas Flink is as 4G of Big Data

| 特点      | Flink                                | Spark                                  |
| --------- | ------------------------------------ | -------------------------------------- |
| 计算模型  |                                      | 微批量                                 |
| 优化      | 提供优化接口                         | 需要人工优化                           |
| 延迟      | 低延迟高吞吐                         | 比flink延迟高                          |
| 迭代处理  | Iterate and DeltaIterate             | 需要借助外部系统                       |
| 性能      | 使用自身的迭代器在ML和图处理上性能好 | 社区完善但是流处理弱与flink            |
| 容错      | 基于Chandy-Lamport分布式快照         | 可以实现eaxctly-once，2.0之后的kafa... |
| 窗口函数  | record and time based                | 只支持基于时间的窗口                   |
| 内存管理  | 自动管理                             | 1.6之前需要手动配置                    |
| scheduler | 自己的job schedule                   | 使用yarn schedule或者自己的schedule    |

##### spark可以优化的点？

- 对内存的依赖，通常1G的数据需要消耗5G的内存。解决思路：
  - 使用更高效的内存管理模型，让spark直接管理二进制数据而不是java对象
- 基于代价的sql优化
- 不同spark app间的内存管理

##### spark中共享变量有哪些？

- broadcast variables：广播变量
- accumulators: 累加器

##### 如何处理积累的元数据？
- 设置`spark.cleaner.ttl`，自动清除，但会将持久化的RDD也清除掉
- 将复杂长时间的job划分成小的job。

##### 延迟加载的好处？
- 只在需要的时候计算，减少资源利用提高计算速度
- 根据算子对job进行优化，例如执行rdd.map(fun).first(),使用懒惰执行的话就没必要将RDD的数据全部加载计算。

##### spark on yarn的启动方式？
- yarn-cluster
- yarn-client

##### spark on yarn的集群管理方式？
- standalon cluster manager
- apache mesos
- hadoop yarn

##### spark推测执行？

推测任务是指对于一个Stage里面拖后腿的Task，会在其他节点的Executor上再次启动这个task，如果其中一个Task实例运行成功则将这个最先完成的Task的计算结果作为最终结果，同时会干掉其他Executor上运行的实例。spark推测式执行默认是关闭的，可通过`spark.speculation`属性来开启

**启动规则**：
当成功的Task数超过总Task数的75%(可通过参数spark.speculation.quantile设置)时，再统计所有成功的Tasks的运行时间，得到一个中位数，用这个中位数乘以1.5(可通过参数spark.speculation.multiplier控制)得到运行时间门限，如果在运行的Tasks的运行时间超过这个门限，则对它启用推测。简单来说就是对那些拖慢整体进度的Tasks启用推测，以加速整个Stage的运行。
 算法大致流程如图：
 ![推测执行](https://ask.qcloudimg.com/http-save/yehe-2935778/r6d15uywku.png?imageView2/2/w/1620)

##### 如何减少数据的传输？

 减少shuffle和IO

- broadcast variables：广播变量
- accumulators: 累加器

##### spark的计算是只能在内存中进行吗？

不是。内存cache对于Spark来说仅仅只是一个优化，即便完全关闭，效率仍然比MapReduce要来得高。去年Spark拿下Sort Benchmark的冠军也很能说明问题（sort过程全程不使用内存cache）

**在Spark内部，单个executor进程内RDD的分片数据是用Iterator流式访问的，Iterator的hasNext方法和next方法是由RDD** lineage上各个transformation携带的闭包函数复合而成的。该复合Iterator每访问一个元素，就对该元素应用相应的复合函数，得到的结果再流式地落地（对于shuffle stage是落地到本地文件系统留待后续stage访问，对于result stage是落地到HDFS或送回driver端等等，视选用的action而定）。如果用户没有要求Spark cache该RDD的结果，那么这个过程占用的内存是很小的，一个元素处理完毕后就落地或扔掉了（概念上如此，实现上有buffer），并不会长久地占用内存。只有在用户要求Spark cache该RDD，且storage level要求在内存中cache时，Iterator计算出的结果才会被保留，通过cache manager放入内存池。


按传统单机immutable FP的观点来看，上述代码运行起来好像是：把HDFS上的日志文件全部拉入内存形成一个巨大的字符串数组，Filter一遍再生成一个略小的新的字符串数组，再map一遍又生成另一个字符串数组。真这么玩儿的话Spark早就不用混了……如前所述，Spark在运行时动态构造了一个复合Iterator。就上述示例来说，构造出来的Iterator的逻辑概念上大致长这样
```
new Iterator[String] {
  private var head: String = _
  private var headDefined: Boolean = false

  def hasNext: Boolean = headDefined || {
    do {
      try head = readOneLineFromHDFS(...)     // (1) read from HDFS
      catch {
        case _: EOFException => return false
      }
    } while (!head.startsWith("ERROR"))       // (2) filter closure
    true
  }

  def next: String = if (hasNext) {
    headDefined = false
    head.split(" ")(1)                        // (3) map closure
  } else {
    throw new NoSuchElementException("...")
  }
}
```
参考：https://www.zhihu.com/question/23079001

##### 对action的简单描述？以及常见的action操作

action是excutor上执行的task来计算RDD并将计算结果返回给driver的操作。

- action返回了RDD的最终计算结果
- action触发了GAG的生成和对RDD的计算
- action将结果返回给driver或者存储到文件系统中
- count,collect,take,first,min,max,sum,reduce,fold,foreach,aggregate...

##### 从不同角度分析spark的容错？

1. task,excutor,driver失败角度
2. 数据源和结果的保存角度

**task失败**

task失败分两种情况：shufffle获取数据失败和task运行超时

Task失败由 executor 感知到，通过 statusUpdate 层层传递到 driver 端的 TaskSetManager.handleFailedTask，其基本逻辑是：

- 如果是FetchFailed，即reduce task 拿不到 shuffle 数据，那么上一个 Stage 需要重跑。
- 如果不是 FetchFailed，并且该 Task 的其他尝试（spark 可能会启动 task 的多个副本）还未成功，会重新启动该 task。
- 如果重启次数超过`spark.task.maxFailures`，taskSet 会失败，这意味着一个 stage 失败了。**stage 失败整个任务就失败了，spark 会取消该 stage 对应的 job 包含的所有 task，并返回用户任务执行失败**。

**FetchFailed**

FetchFailed 会在 ShuffleReader 取数据失败 N 次后抛出，然后由 executor 通过 statusUpdate 传到 driver 端，实际的处理会在 `DAGScheduler.handleTaskCompletion`，它会重新提交该 Stage 和该 Stage 对应的 ShuffleMapStage，重试次数超过 `spark.stage.maxConsecutiveAttempts` 时会退出。

**Speculative task**
有时候 task 不是失败了，而是太慢了，这时 spark 会多启动几个实例（spark 中一个实例叫 attempt），有任何一个实例成功了该 task 就成功了。

如何保证只有一个成功呢？
- 每个输出对象先将文件输出到一个由临时文件名的文件中，然后再将临时文件名修改成正式文件，在修改文件名之前会进行校验此文件是否存在。
- 如果一个task成功了，会取消其他task的执行。

**excutor失败**

executor 挂了，task 会在 TaskSchedulerImpl.removeExecutor 里被标记为失败

- excutor crash:Master 会重启 executor，一个 app 的 executor 重启超过 `spark.deploy.maxExecutorRetries`，app 会被终止。

- excutor网络分区：

  - 当excutor链接driver失败时会重试，超过重试次数时会自杀

  - 当Driver链接excutor失败时重试，driver 端应该忽略excutor发送的消息并通知其自杀。

**driver失败**

- driver crash:依赖持久化和excutor通信恢复driver.重建和excutor,task等的通信。重启的driver和旧的driver有相同的ID

**数据源**

- 数据源是可重新获取的
- 数据源不可重复接收则需要对接收到的数据是进行复制

[详情...](http://liyichao.github.io/posts/spark-%E5%AE%B9%E9%94%99%E6%9C%BA%E5%88%B6.html)

##### driver和worker的角色和主要功能？

1. driver

- 把DAG转换为具体的任务
- 跟踪excutor的运行状况
- 为执行节点调度任务
- 收集job运行情况并通过UI展示

2. excutor

- 运行具体的task
- 通过blockManager对RDD进行管理，如RDD在内存中的存储等

##### 累加器Accumulator？

task端对累加器质性+=操作，并将结果返回给driver端，driver端将各个excutor的值再进行一次累加。driver端通过调研accumulator.value方法获取累加器的值

注意：**使用Accumulator时，为了保证准确性，只使用一次action操作。如果需要使用多次则使用cache或persist操作切断依赖。**多次action操作的话会accumulator会记录上次的计算结果，[例如...](https://www.jianshu.com/p/1b7c9a63bc7c)

- 定义：` val emptylines = sc.accumulator(0,"myAccumulator")`
- 累加器可以实现在map,filter等函数中的数据共享
- 累加器在excutor上只质性+=操作，是不可读的
- 在任务重键时有可能导致累加器重复计算，使用cache或persist操作切断依赖

##### 广播变量的存放位置？

- broadcast 到节点(executor上)而不是 broadcast 到每个 task

- 广播变量只能在driver上定义，不能在excutor上定义

- 广播变量是只读的。一致性问题，如果允许更新的话各个excutor更新顺序，更新结果同步等问题都会出现。

##### Broadcast实现？

- 定义需要广播的变量：`val bdata = sc.broadcast(data)`

- 在执行sc.broadcast操作时，保存bddata

  - 将bddata保存到driver建立可以被httpServer访问的文件夹中

  - 将bdata写入driver自己的blockManger,获得一个bradcastBlockId。

- 当task使用到了bdata时，submit操作会将bradcastBlockId和fun一起序列化

- excutor在反序列task时先从本地blockManger获取broadcast，如果没有则去driver或者其他excutor上获取

  - HttpBroadcast:HttpBroadcast 就是每个 executor 通过的 http 协议连接 driver 并从 driver 那里 fetch data

  - TorrentBroadcast:使用BitTorrent技术，基本思想就是将 data 分块成 data blocks，然后假设有 executor fetch 到了一些 data blocks，那么这个 executor 就可以被当作 data server 了，随着 fetch 的 executor 越来越多，有更多的 data server 加入，data 就很快能传播到全部的 executor 那里去了。


[查看详情...](https://github.com/JerryLead/SparkInternals/blob/master/markdown/7-Broadcast.md)

##### 如何判断是action算子还是transformation算子？

transformation算子是RDD的转换，所以看函数的返回值如果还是一个RDD说明是transformation算子，其他就是action算子了。

##### RDD默认分区数量？

分区数量的原则：**尽可能的选择大的分区值**，如果指定了分区数量，RDD会将定义的分区数量和默认的分区数量相比去较大值。比如：`sc.textFile(…)`，`sc.newAPIHadoopRDD(…)`等

- 外部数据源

  - kafka:kafkaRDD的partition数量等于compute方法中生成OffsetRange的数量即kafka的分区数量
  - hdfs:每个partition的大小默认等于hdfs的block的大小
  - jdbc:JDBC的partition划分是指定开始行和结束行，然后将查询到的结果分为3个（默认值）partition。
  - TCP,Flume等

- tranformation：不同操作转换后分区数量略有不同

  - filter(),map(),flatMap(),distinct()：和父RDD相同
  - union： 两个RDD的和rdd.union(otherRDD)：rdd.partitions.size + otherRDD. partitions.size
  - intersection：取较大的rdd.intersection(otherRDD)：max(rdd.partitions.size, otherRDD. partitions.size)
  - rdd.subtract(otherRDD)	：rdd.partitions.size
  - cartesian：两个RDD数量的乘积rdd.cartesian(otherRDD)： rdd.partitions.size * otherRDD. partitions.size

##### 常用压缩方法有哪些？

压缩是一种时间换空间的方式，类似的还有序列化，通过压缩可以一定程度上防止OOM的发生。

压缩算法有的在速度上比较快，有的压缩比比较高，需要根据实际场景选择，默认是Snappy算法，常用的压缩方式有：

- LZF:更高压缩比，但CPU消耗大
- Snappy:更快压缩速度

##### spark默认使用java序列化的方式吗？

spark2.0之前默认使用java序列化方式。由于kryo不是所有场景都支持，所以从Spark 2.0.0版本开始，简单类型、简单类型数组、字符串类型的Shuffling RDDs 已经默认使用Kryo序列化方式了。

设置方式：`conf.set("spark.serializer", "org.apache.spark.serializer.KryoSerializer")`

主要序列化场景

- *分发给Executor上的Task*
- *需要缓存的RDD（前提是使用序列化方式缓存）*
- *广播变量*
- *Shuffle过程中的数据缓存*
- *使用receiver方式接收的流数据缓存*
- *算子函数中使用的外部变量*

##### 如何理解spark streaming中的饥饿场景Starvation scenario？

在spark streaming中需要一个线程去接收数据，另一个线程来处理数据，如果在`sparkConf.setMaster("local[2]")`中配置为1，那么接收数据和处理数据将不会同时执行。

checkpoint的原理？

为了解决大RDD重复计算耗时和driver元数据保存问题，checkpoint将metadata和RDD保存到磁盘，其中metadata包括：配置信息，未完成作业等。
在执行了checkpoint操作后，会通过lineage重新计算需要check的RDD得到一个CheckPointRdd，计算完成后单独启动一个job将CheckpointRDD保存到HDFS等文件系统中。
在读取时会判断是否已经checked，如果checked的话，就通过CheckpointRDD从文件系统中读取

##### checkpoint和WAL的区别？

checkpoint 保存着执行进度（比如已生成但未完成的 jobs），WAL 中保存着 blocks 及 blocks 元数据（比如保存着未完成的 jobs 对应的 blocks 信息及 block 文件）。

Why checkpiont?

task 中 computing chain 可能会很长，计算某些 RDD 也可能会很耗时。这时，如果 task 中途运行出错，那么 task 的整个 computing chain 需要重算，代价太高。因此，有必要将**计算代价较大的 RDD checkpoint 一下**，这样，当下游 RDD 计算出错时，可以直接从 checkpoint 过的 RDD 那里读取数据继续算。

Checkpoint写什么

**RDD和metadata**,具体来说，metadata checkpointing主要还是从driver失败中恢复，而Data Checkpoint用于对有状态的transformation操作进行checkpointing

- Metadata:将流式计算的信息保存到具备容错性的存储上比如HDFS，Metadata Checkpointing适用于当streaming应用程序Driver所在的节点出错时能够恢复，元数据包括： 
    - Configuration(配置信息) : 创建streaming应用程序的配置信息 
    - Dstream operations : 在streaming应用程序中定义的DStreaming操作 
    - Incomplete batches : 在队列中没有处理完的作业 
- RDD Data:将生成的RDD保存到外部可靠的存储当中，对于一些数据跨度为多个batch的有状态transforation操作来说，checkpoint非常有必要，因为在这些transformation操作生成的RDD对前一RDD有依赖，随着时间的增加，依赖链可能非常长，checkpoint机制能够切断依赖链，将中间的RDD周期性地checkpoint到可靠存储当中，从而在出错时可以直接从checkpoint点恢复。 

checkpoint什么时候需要

- 希望能从意外中恢复driver
- 计算代价交大的RDD。如果application中使用了updateStateByKey或者reduceByKeyAndWindow等stateful操作，必须提供checkpoint目录来允许定时的RDD checkpoint 

什么时候进行checkpoint

- 等到 job 结束后另外启动专门的 job 去完成 checkpoint

怎么checkpoint

RDD 需要经过 [ Initialized --> marked for checkpointing --> checkpointing in progress --> checkpointed ] 这几个阶段才能被 checkpoint。

- **Initialized：** 首先 driver program 需要使用 rdd.checkpoint() 去设定哪些 rdd 需要 checkpoint
- **marked for checkpointing：**初始化后，RDDCheckpointData 会将 rdd 标记为 MarkedForCheckpoint。
- **checkpointing in progress：**每个 job 运行结束后会调用 finalRdd.doCheckpoint()，finalRdd 会顺着 computing chain 回溯扫描，碰到要 checkpoint 的 RDD 就将其标记为 CheckpointingInProgress，然后将写磁盘（比如写 HDFS）需要的配置文件（如 core-site.xml 等）broadcast 到其他 worker 节点上的 blockManager。完成以后，启动一个 job 来完成 checkpoint（使用 `rdd.context.runJob(rdd, CheckpointRDD.writeToFile(path.toString, broadcastedConf))`）。**所以checkpoint会沿着调用链再次计算RDD，因此需要checkpoint的RDD建议cached防止重复计算**
- **checkpointed：**job 完成 checkpoint 后，将该 rdd 的 dependency 全部清掉，并设定该 rdd 状态为 checkpointed。然后，**为该 rdd 强加一个依赖，设置该 rdd 的 parent rdd 为 CheckpointRDD**，该 CheckpointRDD 负责以后读取在文件系统上的 checkpoint 文件，生成该 rdd 的 partition。

checkpoint读流程

- 在 runJob() 的时候会先调用 finalRDD 的 partitions() 来确定最后会有多个 task。
- rdd.partitions() 会去检查（通过 **RDDCheckpointData** 去检查，因为它负责管理被 checkpoint 过的 rdd）该 rdd 是会否被 checkpoint 过了，如果该 rdd 已经被 checkpoint 过了，直接返回该 rdd 的 partitions 也就是 Array[Partition]。
- 当调用 rdd.iterator() 去计算该 rdd 的 partition 的时候，会调用 **computeOrReadCheckpoint**(split: Partition) 去查看该 rdd 是否被 checkpoint 过了，如果是，就调用CheckpointRDD 负责读取文件系统上的文件，生成该 rdd 的 partition。

WAL

write ahead log（预写日志）,作用就是，将数据通过日志的方式写到可靠的存储，比如 HDFS、s3，在 driver 或 worker failure 时可以从在可靠存储上的日志文件恢复数据。WAL 在 driver 端和 executor 端都有应用.

Driver端：

WAL写什么：获取到的block信息以及对block的操作信息
- 新增的block及该block的具体信息，包括streamId、blockId、数据条数等
- 某个 batchTime 分配了哪些 blocks 作为该 batch RDD 的数据源
- 理了哪些 batchTime 对应的 blocks

何时写：

-  BlockAdditionEvent：当 Receiver 接收到数据后会调用 ReceiverSupervisor#pushAndReportBlock方法，该方法将 block 数据存储并写一份到日志文件中（即 WAL），之后最终将 block 信息，即 receivedBlockInfo（包括 streamId、batchId、数据条数）传递给 ReceivedBlockTracker
-  BatchAllocationEvent：JobGenerator 每隔 batch duration 就会为这个 batch 生成对应的 jobs。在生成 jobs 的时候需要为 RDD 提供数据，这个时候就会触发执行`jobScheduler.receiverTracker.allocateBlocksToBatch(time)`
-  BatchCleanupEvent:当一个 batch 的 jobSet 中的 jobs 都完成的时候和每次 checkpoint操作完成的时候会触发执行 `ReceiverTracker#cleanupOldBlocksAndBatches` 方法

Executor端：

Receiver 接收到的数据会源源不断的传递给 ReceiverSupervisor，如果开启WAL，则在StorageLevel指定的存储的基础上，写一份到 WAL 中

[查看详情...](https://www.jianshu.com/p/5e096df2618d)

##### rdd.persist(DISK_ONLY)和checkpoint区别

persist示例：`rdd.persist(StorageLevel.DISK_ONLY)`

persist的数据会随着driver运行结束而删除，checkpoint的数据存在于hdfs上，除非手动删。

- cached操作时由driver的blockManger管理，driver运行结束后整个blockManager的信息将被删除，当然包含cached的RDD信息，而 checkpoint 将 RDD 持久化到 HDFS 或本地文件夹，如果不被手动 remove 掉，也就是说可以被下一个 driver program 使用

##### Cached和Persist区别？

根据源码，cache等价于persist只持久化到内存

```scala
// cache的定义
def cache(): this.type = persist()
// persist默认实现
def persist(): this.type = persist(StorageLevel.MEMORY_ONLY)
```

cached只将数据存储在内存，但是会保存lineage,persist操作会将记录保存到磁盘和hdfs等，并记录为RDDCheckpointData，但是不会记录lineage，一般进行persist之前都需要cached防止重复计算

##### SparkSession和SparkContext区别？

- 从 **Spark** 2.0.0引入sparkSession统一了访问入口，在2.0之前，有sparkContext,SqlContext,HiveContext等,2.0之后也可以通过`sparkSession.sparkContext`得到2.0之前的入口

- 从 **Spark** 2.0.0开始 也可以通过sparkSession直接创建RDD

##### Spark并行度？

spark作业中，各个stage的task的数量，也就代表了spark作业在各个阶段stage的并行度，合理的设置并行度可减少每个task的运行时长提高执行效率。**推荐task数量，设置成spark Application 总cpu core数量的2~3倍** ，比如150个cpu core ，基本设置 task数量为 300~ 500。

##### spark和hadoop的区别及使用场景?

hadoop目前的角色更像是一个基础设施，用来存储数据，通过yarn提供更方便的数据管理中间件，spark,hive等可以基于其进行数据分析。

spark的优势是数据处理速度。

##### 如何保证宕机迅速恢复

- checkpoint+WAL
- HA
  - yarn
  - standalone

##### Spark Streaming 和 Storm 有何区别

| 特点 | spark              | storm                               |
| ---- | ------------------ | ----------------------------------- |
| 延迟 | 基于时间窗口，批量 | 亚秒级，每次只处理一条              |
| 容错 | 最多处理一次       | Storm只能保证每条记录最少被处理一次 |
| 语言 | scala              | clojure(也提供了java的API)          |

##### Spark 工作的一个流程

在申请到了作业执行所需的资源之后，Driver进程就会开始调度和执行我们编写的作业代码了。Driver进程会将我们编写的Spark作业代码分拆为多个stage，每个stage执行一部分代码片段，并为每个stage创建一批task，然后将这些task分配到各个Executor进程中执行。task是最小的计算单元，负责执行一模一样的计算逻辑（也就是我们自己编写的某个代码片段），只是每个task处理的数据不同而已。一个stage的所有task都执行完毕之后，会在各个节点本地的磁盘文件中写入计算中间结果，然后Driver就会调度运行下一个stage。下一个stage的task的输入数据就是上一个stage输出的中间结果。如此循环往复，直到将我们自己编写的代码逻辑全部执行完，并且计算完所有的数据，得到我们想要的结果为止。

Spark是根据shuffle类算子来进行stage的划分。如果我们的代码中执行了某个shuffle类算子（比如reduceByKey、join等），那么就会在该算子处，划分出一个stage界限来。可以大致理解为，shuffle算子执行之前的代码会被划分为一个stage，shuffle算子执行以及之后的代码会被划分为下一个stage。因此一个stage刚开始执行的时候，它的每个task可能都会从上一个stage的task所在的节点，去通过网络传输拉取需要自己处理的所有key，然后对拉取到的所有相同的key使用我们自己编写的算子函数执行聚合操作（比如reduceByKey()算子接收的函数）。这个过程就是shuffle。

应用程序提交后，触发action，构建sparkContext，构建DAG图，提交给DAGScheduler，构建stage，以stageSet方式提交给TaskScheduler，构建taskSet Manager，然后将task提交给executor运行。executor运行完task后，将完成信息提交给schedulerBackend，由它将任务完成的信息提交给TaskScheduler。TaskScheduler反馈信息给TaskSetManager，删除该task任务，执行下一个任务。同时TaskScheduler将完成的结果插入到成功队列里，加入之后返回加入成功的信息。TaskScheduler将任务处理成功的信息传给TaskSet Manager。全部任务完成后TaskSet Manager将结果反馈给DAGScheduler。如果属于resultTask，交给JobListener。如果不属于resultTask，保存结果。

[查看更多](https://my.oschina.net/u/2000675/blog/618788)

spark模块划分

![spark工作流程](https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/sparkArchitecture.png)

job提交

- `DAGScheduler`将Job划分为Stage，Spark根据RDD的依赖关系划分Stage，最终将其封装成taskset进行提交
- `TaskScheduler`类负责任务调度资源的分配
- `SchedulerBackend`负责与Master、Worker通信收集Worker上分配给该应用使用的资源情况

![job](https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/153231_q1BV_2000675.jpg)

job.stages.task关系

![stagetask](https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/stagetask.png)



##### 资源分配

1. 分配哪些资源？

   资源分配主要是指分配执行任务的容器executor的资源（默认是2个），每个Executor是一个独立的JVM进程，JVM之间内存是无法共享的。主要包括executor、core per executor、memory per executor、driver memory

2. 在哪里分配这些资源？

   在我们在**生产环境中，提交spark作业时，用的spark-submit shell脚本，里面调整对应的参数**

```scala
/usr/local/spark/bin/spark-submit \
--class cn.spark.sparktest.core.WordCountCluster \
--num-executors 3 \  配置executor的数量
--executor-memory 100m \  配置每个executor的内存大小
--executor-cores 3 \  配置每个executor的cpu core数量
--driver-memory 100m \  配置driver的内存（影响很大）
/usr/local/SparkTest-0.0.1-SNAPSHOT-jar-with-dependencies.jar \
```

3. 资源的动态分配

简介：当一个应用程序不需要使用资源，且后续没有资源申请的时候，它就将现有的资源交回给集群，这样集群便可以将资源分配给其他应用程序来使用。当该应用程序再次需要资源的时候就再去向集群申请。

配置参数：

```scala
spark.dynamicAllocation.enabled   true   // 开启动态资源分配
spark.shuffle.service.enabled     true   // 启用External shuffle Service服务
spark.dynamicAllocation.minExecutors 1   // 每个Application最小分配的executor数
spark.dynamicAllocation.maxExecutors 30  // 每个Application最大并发分配的executor数
spark.shuffle.service.port 7337 // Shuffle Service服务端口，必须和yarn-site中的一致
spark.dynamicAllocation.schedulerBacklogTimeout 1s // 等待1s后分配资源
spark.dynamicAllocation.sustainedSchedulerBacklogTimeout 5s// 申请资源时间间隔
```

4. 分配策略

资源动态分配模式下，如果某个Spark应用程序有某些tasks处于等待运行状态时，该应用程序就会向集群申请更多的Executors资源。对于Spark Streaming，数据按时间段到达，为了防止executor频繁出现添加移除现象，应该禁用该功能。

请求策略：

spark采用轮询的方式申请资源，默认当task等待1s后每个5s触发一次资源申请，依次申请2,4,8...个资源

Spark请求Executors采用的是 轮询的方式，当有tasks处于等待状态`spark.dynamicAllocation.schedulerBacklogTimeout`秒后会触发一次Executors请求，如果之后tasks一直处于等待状态，那么每隔`spark.dynamicAllocation.sustainedSchedulerBacklogTimeout`秒会触发一次Executors请求，每次轮询中申请的Executors个数以指数形式增长，比如第一个轮询申请1个Executor，之后会依次申请2，4，8…个Executors。

删除策略：

当某个Spark应用程序的某个Executor处于空闲状态`spark.dynamicAllocation.executorIdleTimeout`秒后就会删除该Executor

- Executor失败或者它所属的应用程序退出的情况下Executor才会结束，此时不需要保存executor的状态。
- 程序还未执行完毕的情况下回收executor，需要保存executor状态，提供给shuffleService等服务使用

Shuffle运行完毕后executor被回收，reduce阶段怎么获取shuffle结果？

通过ShuffleService去获取，shuffleService会保存executor shuffle的结果信息。

Shuffle Service是运行在集群每个节点上的服务，它与Spark应用程序及其Executors是相互独立的，如果Shuffle Service在运行，Spark的Executors就会从Shuffle Service获取Shuffle阶段保存的文件，而不是去每个节点获取。这就意味着一个Executors被删除之后，它在Shuffle阶段的状态信 息还一直运行在Shuffle Service中。

[查看详情...](http://slamke.github.io/2018/01/16/Spark%E5%8A%A8%E6%80%81%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D/)

##### 内存管理

内存划分：

spark在1.6之后采取动态内存管理机制，可以根据需求动态调整存储内存和计算内存在executor占比参数。默认情况下executor的堆内内存会预留300m内存，剩余的60%内存存储和计算各占一半。默认不使用非堆内存，当然也可以通过参数配置使用非堆内存，非堆内存的划分规则和堆内存一致。

内存调控：

对execution内存和storage的内存划分略有不同，storage在申请内存时先判断申请堆内内存还是堆外内存，然后判断storage的剩余内存是否够用，够用的话直接分配，不够则从execution借内存使用，如果execution内存不足时则放弃存储，而excution在申请不到内存时task线程会阻塞，并对sotrage内存发起缩小操作直至有足够内存时再继续执行task.

![](E:\data\oss\spark\spark-unified-heap-memory-layout.png)

[查看详情](http://shiyanjun.cn/archives/1585.html)

##### 宽依赖和窄依赖

窄依赖包括一对一依赖和范围依赖，宽依赖即shuffle依赖，即**父 RDD 中的分区可能会被多个子 RDD 分区使用**，Shuffle 依赖也意味着父 RDD 与子 RDD 之间存在着 Shuffle 过程。 shuffle 不一定产生宽依赖，但是宽依赖一定是由 shuffle 产生的（两个RDD对应的partition进行jion操作则不会产生宽依赖）。

##### spark streaming操作分类

Dstream的转换操作分为有状态和无状态操作。无状态转化是指每个批次处理都不依赖于先前批次的数据，如map() filter() reduceByKey()等均属于无状态的。有状态转化是指依赖之前的批次数据或者中间结果来计算当前批次的数据，包括**updateStatebyKey()**和**window()**

##### spark streaming中的有状态转化操作

updateStateByKey():



window()

- window(windowLength, slideInterval) // 返回一个新的Dstream来表示窗口操作的结果数据，也就是说这个新的Dstream中的每个RDD都包括了多个批次中的数据
- reduceByWindow(func, windowLength, slideInterval) //在整个窗口上执行归约操作
- reduceByKeyAndWindow(func, windowLength, slideInterval, [numTasks]) // 对key进行归约操作
- countByWindow(windowLength, slideInterval) //返回每个窗口中元素个数的Dstream
- countByValueAndWindow(windowLength, slideInterval, [numTasks])//返回每个窗口中值的个数的Dstream

##### Spark 的三种提交模式是什么

- local: local+local伪分布式

- standalone：

- yarn-cluster
- yarn-client

三种模式区别：

独立模式下资源管理有spark自己的资源管理器完成，yarn模式下由yarn进行资源管理，Yarn-Client模式中driver在客户端本地运行，这种模式可以使得Spark Application和客户端进行交互。yarn-cluster模式下sparkcontext在

ApplicationMaster中管理。

Spark Client 和 Spark Cluster的区别:

- 理解YARN-Client和YARN-Cluster深层次的区别之前先清楚一个概念：Application Master。在YARN中，每个Application实例都有一个ApplicationMaster进程，它是Application启动的第一个容器。它负责和ResourceManager打交道并请求资源，获取资源之后告诉NodeManager为其启动Container。从深层次的含义讲YARN-Cluster和YARN-Client模式的区别其实就是ApplicationMaster进程的区别
- **YARN-Cluster模式下，Driver运行在AM(Application Master)中**，它负责向YARN申请资源，并监督作业的运行状况。当用户提交了作业之后，就可以关掉Client，作业会继续在YARN上运行，因而YARN-Cluster模式不适合运行交互类型的作业
- **YARN-Client模式下，Application Master仅仅向YARN请求Executor**，Client会和请求的Container通信来调度他们工作，也就是说Client不能离开

![](E:\data\oss\spark\spark-cluster.png)

##### Spark yarn-cluster 架构

1.Spark提交作业到Yarn集群，向ResourceManager请求启动ApplicationMaster；

2.ResourceManager分配一个Container，然后在Yarn集群中的某个NodeManager中启动ApplicationMaster；

3.ApplicationMaster启动完成以后向ResourceManager请求分配一批Container资源，以运行Spark作业；

4.ResourceManager接收到来自ApplicationMaster的请求以后，开始一批Container资源用于启动executor；

5.当executor启动成功以后，将其信息向ApplicationMaster进行注册；

##### coalesce()方法和repartition()方法区别

1. coalesce()方法默认不进行序列化

2. repartition方法等价于coalesce()设置为序列化,`coalesce(numPartitions, shuffle = true)`

3. 当把父Rdd的分区数量增大时，比如Rdd的分区是100，设置成1000，如果shuffle为false，并不会起作用.

4. 一般情况下减少分区使用coalesce(合并),增加分区使用repartition，但是在减少分区的同时需要保证task的并发量就需要使用repartition，比如：

```scala
// 为了保证resultRDD计算并发量，通过再做一次shuffle将结果进行汇总
val resultRDD = ...
resultRDD.repartition(1).saveAsTextFile(output)
```


```scala
// repartition函数定义
def repartition(numPartitions: Int)(implicit ord: Ordering[T] = null): 
	RDD[T] = withScope {
    	coalesce(numPartitions, shuffle = true)
}
```

##### Direct Memory

ByteBuffer有两种:

- heap ByteBuffer -> -XX:Xmx:一种是heap ByteBuffer,该类对象分配在JVM的堆内存里面，直接由Java虚拟机负责垃圾回收，

- direct ByteBuffer -> -XX:MaxDirectMemorySize 默认64M,

**direct ByteBuffer不属于java堆内存，是通过jni在虚拟机外内存中分配的**(分配内存其实是调用操作系统的Os:malloc()函数)。这种方式是为了提高网络和文件IO的效率，避免多余的内存拷贝而出现的。**通过jmap无法查看该快内存的使用情况。只能通过top来看它的内存使用情况**。

JVM堆内存大小可以通过-Xmx来设置，同样的direct ByteBuffer可以通过-XX:MaxDirectMemorySize来设置，此参数的含义是当Direct ByteBuffer分配的堆外内存到达指定大小后，即触发Full GC。注意该值是有上限的，默认是64M，最大为sun.misc.VM.maxDirectMemory()，在程序中中可以获得-XX:MaxDirectMemorySize的设置的值。

GC仅在Java堆被填满，以至于无法为堆分配请求提供服务时发生，,或者在Java应用程序中显示调用System.gc()函数来释放内存（一些NIO框架就是用这个方法释放占用的DirectMemory）。

`java.lang.OutOfMemoryError: Direct buffer memory` 异常原因：

Direct Memory是受GC控制的，例如ByteBuffer bb = ByteBuffer.allocateDirect(1024)，这段代码的执行会在堆外占用1k的内存，Java堆内只会占用一个对象的指针引用的大小，堆外的这1k的空间只有当bb对象被回收时，才会被回收，这里会发现一个明显的不对称现象，就是堆外可能占用了很多，而堆内没占用多少，导致还没触发GC。加上-XX:MaxDirectMemorySize这个大小限制后，那么只要Direct Memory使用到达了这个大小，就会强制触发GC，这个大小如果设置的不够用，那么在日志中会看到java.lang.OutOfMemoryError: Direct buffer memory。

##### executor运行在JVM的那块区域上？

Spark 2.x 版本对 Java 堆 (heap) 的使用情况，数据处理以及类的实体对象存放在 JVM 堆 (heap) 中。

##### 如何保证sc读到的内容为空时，saveAsHadoopFile可以不生成空文件

可以判断 RDD是不是空的，isEmpty() 函数。它的实现：

```scala
def isEmpty(): Boolean = withScope {
    partitions.length == 0 || take(1).length == 0
}
```

##### spark  Shuffle机制



##### scala和java有什么区别?

语法上的不同：

- scala中没有static，但是可以用object来达到java中相同的效果，scala中的object可以实现单例对象
- scala中的unit相当于java中的void
- scala与java都有7中数值类型：int、short、long、byte、float、double、boolean这7种，但是scala中这7种值类型是类，在java中属于基本类型，java中，数据类型分成基本类型和引用类型，scala中不区分。
- scala中的变量或函数的类型总是写在变量或者函数名的后面
- 在scala中，操作符是方法，在java中操作符不是方法

宏观区别：

- scala是面向对象的，基础类型也是类的实现，scala中没有静态方法，通过object实现静态方法
- scala有丰富的语法糖，eg：getOrElse代替if else ，foreach()代替for循环等
- 语法糖过多不适合于工程化开发

##### 如何确定spark分区数、task数目、core数、worker节点个数、excutor数量

- task数目:partition数目
  - input: 如果读取hdfs，默认一个input split(block块)对应一个task
  - Map阶段：和输入的task数目保持一致
  - reduce阶段：和shuffle函数有关
- task并行度：excutor数量*每个excutor的核数
- core数量和excutor数量根据数据量和机器大小在启动时分配

##### mapPartition和map算子相比,具体优化了哪些点?

- 操作对象：mapPartition是针对每个分区进行操作，map是针对每个元素进行操作
- 创建对象：mapPaitition在遍历时是针对每个分区创建一个对象，在JDBC等连接外部数据源的情况下可以降低连接数
- mapPartition一次性处理的数据量变大容易导致OOM

##### 算子调优

- 使用mapPartitions代替map
- 使用foreachPartition代替foreach
- filter操作之后使用coalesce算子提高性能
- 使用repartition解决SparkSQL低并行度的问题(spark sql无法手动设置partition数量)
- 使用reduceByKey代替groupByKey(reduceByKey相对于普通的shuffle操作会进行map端的本地聚合，从而减少文件的输出，减少磁盘IO,网络传输，内存占比以及reduce端的聚合操作数据)

##### shuffle的有哪些方式以及使用场景？

1.2之前是HashShuffleManager，1.2之后是SortShuffleManager和bypass SortShuffleManager

在Spark 1.2以后的版本中，默认的ShuffleManager改成了SortShuffleManager。SortShuffleManager相较于HashShuffleManager来说，有了一定的改进。主要就在于，每个Task在进行shuffle操作时，虽然也会产生较多的临时磁盘文件，但是最后会将所有的临时文件合并（merge）成一个磁盘文件，因此每个Task就只有一个磁盘文件。在下一个stage的shuffle read task拉取自己的数据时，只要根据索引读取每个磁盘文件中的部分数据即可。

SortShuffleManager的原理。在该模式下，数据会先写入一个内存数据结构中，此时根据不同的shuffle算子，可能选用不同的数据结构。如果是reduceByKey这种聚合类的shuffle算子，那么会选用Map数据结构，一边通过Map进行聚合，一边写入内存；如果是join这种普通的shuffle算子，那么会选用Array数据结构，直接写入内存。接着，每写一条数据进入内存数据结构之后，就会判断一下，是否达到了某个临界阈值。如果达到临界阈值的话，那么就会尝试将内存数据结构中的数据溢写到磁盘，然后清空内存数据结构。

bypass运行机制运行原理和sortShuffle运行原理类似，只是在shufflle时没有进行排序。但是比HashShufffleManager多了对task生成的小文件合并的过程。

##### 都有哪些调优方向

![1548763120537](E:\data\oss\spark\1548763120537.png)



[调优详情](https://www.slideshare.net/ssuser42d804/spark-75554094)

##### 用java的lambda表达式实现单词统计

```java
JavaRDD<String> lines = sc.textFile(``"hdfs://log.txt"``);
JavaRDD<String> words =lines.flatMap(line -> Arrays.asList(line.split(" ")));
JavaPairRDD<String, Integer> counts =words.mapToPair(
    w -> new Tuple2<String, Integer>(w, 1)).reduceByKey((x, y) -> x + y);
counts.saveAsTextFile(``"hdfs://counts.txt"``);
```



https://github.com/qiushangwenyue/Interview_BigData

https://zhuanlan.zhihu.com/p/49185277