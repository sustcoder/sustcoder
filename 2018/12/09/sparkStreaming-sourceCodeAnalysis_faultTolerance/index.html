<!DOCTYPE html>


  <html class="light page-post">


<head>
  <meta charset="utf-8">
  
  <title>sparkStreaming源码解析之容错 | sustcoder</title>

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
    <meta name="keywords" content="spark,源码解析," />
  

  <meta name="description" content="sparkStream的数据容错思维脑图">
<meta name="keywords" content="spark,streaming,源码,容错">
<meta property="og:type" content="article">
<meta property="og:title" content="sparkStreaming源码解析之容错">
<meta property="og:url" content="https://sustcoder.github.io/2018/12/09/sparkStreaming-sourceCodeAnalysis_faultTolerance/index.html">
<meta property="og:site_name" content="sustcoder">
<meta property="og:description" content="sparkStream的数据容错思维脑图">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsA82A.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsC3C6.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wps230.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wps614F.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wps753E.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsB9D6.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsB9D7.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsB9D8.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsB9D9.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsB9DA.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsB9DB.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsB9DC.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsB9DD.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsB9DE.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsB9EF.tmp.jpg">
<meta property="og:updated_time" content="2018-12-07T03:48:27.154Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="sparkStreaming源码解析之容错">
<meta name="twitter:description" content="sparkStream的数据容错思维脑图">
<meta name="twitter:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsA82A.tmp.jpg">

  

  
    <link rel="icon" href="/favicon.ico">
  

  <link href="/css/styles.css?v=c114cben" rel="stylesheet">


  

  

  
  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?f1cc8b0edce213e23b90ab65ff3c30ff";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>


  
  <script type="text/javascript">
	(function(){
	    var bp = document.createElement('script');
	    var curProtocol = window.location.protocol.split(':')[0];
	    if (curProtocol === 'https') {
	        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
	    }
	    else {
	        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
	    }
	    var s = document.getElementsByTagName("script")[0];
	    s.parentNode.insertBefore(bp, s);
	})();
  </script>



  
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.3.0/css/font-awesome.min.css">
  

</head>

<body>


  
    <span id="toolbox-mobile" class="toolbox-mobile">盒子</span>
  

  <div class="post-header CENTER">
   
  <div class="toolbox">
    <a class="toolbox-entry" href="/">
      <span class="toolbox-entry-text">盒子</span>
      <i class="icon-angle-down"></i>
      <i class="icon-home"></i>
    </a>
    <ul class="list-toolbox">
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/blog/"
            rel="noopener noreferrer"
            target="_self"
            >
            博客
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/category/"
            rel="noopener noreferrer"
            target="_self"
            >
            分类
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/tag/"
            rel="noopener noreferrer"
            target="_self"
            >
            标签
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/link/"
            rel="noopener noreferrer"
            target="_self"
            >
            友链
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/about/"
            rel="noopener noreferrer"
            target="_self"
            >
            关于
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/search/"
            rel="noopener noreferrer"
            target="_self"
            >
            搜索
          </a>
        </li>
      
    </ul>
  </div>


</div>


  <div id="toc" class="toc-article">
    <strong class="toc-title">文章目录</strong>
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-driver端容错"><span class="toc-text">1. driver端容错</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-executor端容错"><span class="toc-text">2. executor端容错</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-热备"><span class="toc-text">2.1. 热备</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-1-备份"><span class="toc-text">2.1.1. 备份</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-2-恢复"><span class="toc-text">2.1.2. 恢复</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-冷备"><span class="toc-text">2.2. 冷备</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-1-WriteAheadLog"><span class="toc-text">2.2.1. WriteAheadLog</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-1-1-配置"><span class="toc-text">2.2.1.1. 配置</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2-2-1-1-1-存放目录配置"><span class="toc-text">2.2.1.1.1. 存放目录配置</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-2-1-1-2-rolling配置"><span class="toc-text">2.2.1.1.2. rolling配置</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-1-2-读写对象管理"><span class="toc-text">2.2.1.2. 读写对象管理</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-3-重放"><span class="toc-text">2.3. 重放</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-1-基于Receiver"><span class="toc-text">2.3.1. 基于Receiver</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-2-Direct方式"><span class="toc-text">2.3.2. Direct方式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-2-1-DirectKafkaInputDStream"><span class="toc-text">2.3.2.1. DirectKafkaInputDStream</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-2-2-KafkaRDD"><span class="toc-text">2.3.2.2. KafkaRDD</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-4-忽略"><span class="toc-text">2.4. 忽略</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-1-粗粒度忽略"><span class="toc-text">2.4.1. 粗粒度忽略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-2-细粒度忽略"><span class="toc-text">2.4.2. 细粒度忽略</span></a></li></ol></li></ol></li></ol>
  </div>



<div class="content content-post CENTER">
   <article id="post-sparkStreaming-sourceCodeAnalysis_faultTolerance" class="article article-type-post" itemprop="blogPost">
  <header class="article-header">
    <h1 class="post-title">sparkStreaming源码解析之容错</h1>

    <div class="article-meta">
      <span>
        <i class="icon-calendar"></i>
        <span>2018.12.09</span>
      </span>

      
        <span class="article-author">
          <i class="icon-user"></i>
          <span>liyz</span>
        </span>
      

      
  <span class="article-category">
    <i class="icon-list"></i>
    <a class="article-category-link" href="/categories/spark/">spark</a>
  </span>



      
        <span>
          <i class="icon-comment"></i>
          <a href="https://sustcoder.github.io//2018/12/09/sparkStreaming-sourceCodeAnalysis_faultTolerance/#disqus_thread"></a>
        </span>
      

      
      <i class="fa fa-eye"></i> 
        <span id="busuanzi_container_page_pv">
           &nbsp热度 <span id="busuanzi_value_page_pv">
           <i class="fa fa-spinner fa-spin"></i></span>℃
        </span>
      
      
    </div>
  </header>

  <div class="article-content">
    
      <p>此文是从思维导图中导出稍作调整后生成的，思维脑图对代码浏览支持不是很好，为了更好阅读体验，文中涉及到的源码都是删除掉不必要的代码后的伪代码，如需获取更好阅读体验可下载脑图配合阅读：</p>
<p> 此博文共分为四个部分：</p>
<ol>
<li><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsA82A.tmp.jpg" alt="img"><a href="https://sustcoder.github.io/2018/12/01/sparkStreaming-sourceCodeAnalysis_DAG/">DAG定义</a></li>
<li><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsC3C6.tmp.jpg" alt="img"><a href="https://sustcoder.github.io/2018/12/03/sparkStreaming-sourceCodeAnalysis_job/">Job动态生成</a></li>
<li><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wps230.tmp.jpg" alt="img"><a href="https://sustcoder.github.io/2018/12/09/sparkStreaming-sourceCodeAnalysis_dataInputOutput/">数据的产生与导入</a></li>
<li><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wps614F.tmp.jpg" alt="img"><a href="https://sustcoder.github.io/2018/12/12/sparkStreaming-sourceCodeAnalysis__faultTolerance/">容错</a></li>
</ol>
<p><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wps753E.tmp.jpg" alt="img"></p>
<p>​    策略        优点            缺点</p>
<p>(1) 热备        无 recover time        需要占用双倍资源</p>
<p>(2) 冷备        十分可靠                存在 recover time</p>
<p>(3) 重放        不占用额外资源        存在 recover time</p>
<p>(4) 忽略        无 recover time        准确性有损失</p>
<h1 id="1-driver端容错"><a href="#1-driver端容错" class="headerlink" title="1. driver端容错"></a>1. <strong>driver端容错</strong></h1><p><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsB9D6.tmp.jpg" alt="img"> </p>
<h1 id="2-executor端容错"><a href="#2-executor端容错" class="headerlink" title="2. executor端容错"></a>2. <strong>executor端容错</strong></h1><p><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsB9D7.tmp.jpg" alt="img"> </p>
<h2 id="2-1-热备"><a href="#2-1-热备" class="headerlink" title="2.1. 热备"></a>2.1. <strong>热备</strong></h2><p><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsB9D8.tmp.jpg" alt="img"> </p>
<p>Receiver 收到的数据，通过 ReceiverSupervisorImpl，将数据交给 BlockManager 存储；而 BlockManager 本身支持将数据 replicate() 到另外的 executor 上，这样就完成了 Receiver 源头数据的热备过程。</p>
<p>而在计算时，计算任务首先将获取需要的块数据，这时如果一个 executor 失效导致一份数据丢失，那么计算任务将转而向另一个 executor 上的同一份数据获取数据。因为另一份块数据是现成的、不需要像冷备那样重新读取的，所以这里不会有 recovery time。</p>
<h3 id="2-1-1-备份"><a href="#2-1-1-备份" class="headerlink" title="2.1.1. 备份"></a>2.1.1. <strong>备份</strong></h3><p><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsB9D9.tmp.jpg" alt="img"> </p>
<p>备份流程：</p>
<p>​    先保存此block块，如果保存失败则不再进行备份，如果保存成功则获取保存的block块，执行复制操作。</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BlockManager</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">doPutIterator</span></span>()&#123;</span><br><span class="line"></span><br><span class="line">		doPut(blockId,level,tellMaster)&#123;</span><br><span class="line"></span><br><span class="line">			<span class="comment">// 存储数据</span></span><br><span class="line"></span><br><span class="line">			<span class="keyword">if</span>(level)&#123;</span><br><span class="line"></span><br><span class="line">				memoryStore.putIteratorAsBytes（）</span><br><span class="line"></span><br><span class="line">			&#125;<span class="keyword">else</span> <span class="keyword">if</span>(level.useDisk)&#123;</span><br><span class="line"></span><br><span class="line">				diskStore.put()</span><br><span class="line"></span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			<span class="comment">// 当前block已经存储成功则继续：		</span></span><br><span class="line"></span><br><span class="line">			<span class="keyword">if</span>(blockWasSuccessfullyStored)&#123;</span><br><span class="line"></span><br><span class="line">				<span class="comment">// 报告结果给master</span></span><br><span class="line"></span><br><span class="line">				<span class="keyword">if</span>(tellMaster)&#123;</span><br><span class="line"></span><br><span class="line">					reportBlockStatus(blockid,status)</span><br><span class="line"></span><br><span class="line">				&#125;</span><br><span class="line"></span><br><span class="line">				<span class="comment">// 备份</span></span><br><span class="line"></span><br><span class="line">				<span class="keyword">if</span>(level.replication&gt;<span class="number">1</span>)&#123;</span><br><span class="line"></span><br><span class="line">					<span class="comment">// 从上面保存成功的位置获取block</span></span><br><span class="line"></span><br><span class="line">					 <span class="keyword">val</span> bytesToReplicate =doGetLocalBytes(blockId, info)</span><br><span class="line"></span><br><span class="line">					<span class="comment">// 正式备份</span></span><br><span class="line"></span><br><span class="line">					replicate(</span><br><span class="line"></span><br><span class="line">						blockId, </span><br><span class="line"></span><br><span class="line">						bytesToReplicate, </span><br><span class="line"></span><br><span class="line">						level</span><br><span class="line"></span><br><span class="line">					)</span><br><span class="line"></span><br><span class="line">				&#125;</span><br><span class="line"></span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="2-1-2-恢复"><a href="#2-1-2-恢复" class="headerlink" title="2.1.2. 恢复"></a>2.1.2. <strong>恢复</strong></h3><p>计算任务首先将获取需要的块数据，这时如果一个 executor 失效导致一份数据丢失，那么计算任务将转而向另一个 executor 上的同一份数据获取数据。因为另一份块数据是现成的、不需要像冷备那样重新读取的，所以这里不会有 recovery time。</p>
<h2 id="2-2-冷备"><a href="#2-2-冷备" class="headerlink" title="2.2. 冷备"></a>2.2. <strong>冷备</strong></h2><p><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsB9DA.tmp.jpg" alt="img"> </p>
<p>冷备是每次存储块数据时，除了存储到本 executor，还会把块数据作为 log 写出到 WriteAheadLog 里作为冷备。这样当 executor 失效时，就由另外的 executor 去读 WAL，再重做 log 来恢复块数据。WAL 通常写到可靠存储如 HDFS 上，所以恢复时可能需要一段 recover time</p>
<h3 id="2-2-1-WriteAheadLog"><a href="#2-2-1-WriteAheadLog" class="headerlink" title="2.2.1. WriteAheadLog"></a>2.2.1. <strong>WriteAheadLog</strong></h3><p><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsB9DB.tmp.jpg" alt="img"> </p>
<p>WriteAheadLog 的特点是顺序写入，所以在做数据备份时效率较高，但在需要恢复数据时又需要顺序读取，所以需要一定 recovery time。</p>
<p>不过对于 Spark Streaming 的块数据冷备来讲，在恢复时也非常方便。这是因为，对某个块数据的操作只有一次（即新增块数据），而没有后续对块数据的追加、修改、删除操作，这就使得在 WAL 里只会有一条此块数据的 log entry。所以，我们在恢复时只要 seek 到这条 log entry 并读取就可以了，而不需要顺序读取整个 WAL。</p>
<p><strong>也就是，Spark Streaming 基于 WAL 冷备进行恢复，需要的 recovery time 只是 seek 到并读一条 log entry 的时间，而不是读取整个 WAL 的时间</strong>，这个是个非常大的节省</p>
<h4 id="2-2-1-1-配置"><a href="#2-2-1-1-配置" class="headerlink" title="2.2.1.1. 配置"></a>2.2.1.1. <strong>配置</strong></h4><p><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsB9DC.tmp.jpg" alt="img"> </p>
<h5 id="2-2-1-1-1-存放目录配置"><a href="#2-2-1-1-1-存放目录配置" class="headerlink" title="2.2.1.1.1. 存放目录配置"></a>2.2.1.1.1. <strong>存放目录配置</strong></h5><p>WAL 存放的目录：<code>{checkpointDir}/receivedData/{receiverId}</code></p>
<p>{checkpointDir} ：在 <code>ssc.checkpoint(checkpointDir)</code>指定的​    </p>
<p>{receiverId} ：是 Receiver 的 id</p>
<p>文件名：不同的 rolling log 文件的命名规则是     <code>log-{startTime}-{stopTime}</code></p>
<h5 id="2-2-1-1-2-rolling配置"><a href="#2-2-1-1-2-rolling配置" class="headerlink" title="2.2.1.1.2. rolling配置"></a>2.2.1.1.2. <strong>rolling配置</strong></h5><p>FileBasedWriteAheadLog 的实现把 log 写到一个文件里（一般是 HDFS 等可靠存储上的文件），然后每隔一段时间就关闭已有文件，产生一些新文件继续写，也就是 rolling 写的方式</p>
<p>rolling 写的好处是单个文件不会太大，而且删除不用的旧数据特别方便</p>
<p>这里 rolling 的间隔是由参数 <strong>spark.streaming.receiver.writeAheadLog.rollingIntervalSecs</strong>（默认 = 60 秒） 控制的</p>
<h4 id="2-2-1-2-读写对象管理"><a href="#2-2-1-2-读写对象管理" class="headerlink" title="2.2.1.2. 读写对象管理"></a>2.2.1.2. <strong>读写对象管理</strong></h4><p>WAL将读写对象和读写实现分离，由FileBasedWriterAheadLog管理读写对象，LogWriter和LogReader根据不同输出源实现其读写操作</p>
<p>class FileBasedWriteAheadLog:</p>
<p>write(byteBuffer:ByteBuffer,time:Long):</p>
<p>​    1.  先调用getCurrentWriter(),获取当前currentWriter.</p>
<p>​    2. 如果log file 需要rolling成新的，则currentWriter也需要更新为新的currentWriter</p>
<p>​    3. 调用writer.write(byteBuffer)进行写操作</p>
<p>​    4. 保存成功后返回： </p>
<p>​        path:保存路径</p>
<p>​        offset:偏移量</p>
<p>​        length:长度</p>
<p>read(segment:WriteAheadRecordHandle):</p>
<p>​    ByteBuffer {}:</p>
<p>​    1. 直接调用reader.read(fileSegment)</p>
<p>read实现：</p>
<p>// 来自 FileBasedWriteAheadLogRandomReader</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read</span></span>(</span><br><span class="line"></span><br><span class="line">	segment: <span class="type">FileBasedWriteAheadLogSegment</span>): <span class="type">ByteBuffer</span> = synchronized &#123;</span><br><span class="line"></span><br><span class="line">  assertOpen()</span><br><span class="line"></span><br><span class="line">  	<span class="comment">// 【seek 到这条 log 所在的 offset】</span></span><br><span class="line"></span><br><span class="line"> 	 instream.seek(segment.offset)</span><br><span class="line"></span><br><span class="line"> 	 <span class="comment">// 【读一下 length】</span></span><br><span class="line"></span><br><span class="line"> 	 <span class="keyword">val</span> nextLength = instream.readInt()</span><br><span class="line"></span><br><span class="line">  	 <span class="keyword">val</span> buffer = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">Byte</span>](nextLength)</span><br><span class="line"></span><br><span class="line">  	 <span class="comment">// 【读一下具体的内容】</span></span><br><span class="line"></span><br><span class="line">  	 instream.readFully(buffer)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 【以 ByteBuffer 的形式，返回具体的内容】</span></span><br><span class="line"></span><br><span class="line">    <span class="type">ByteBuffer</span>.wrap(buffer)</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="2-3-重放"><a href="#2-3-重放" class="headerlink" title="2.3. 重放"></a>2.3. <strong>重放</strong></h2><p><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsB9DD.tmp.jpg" alt="img"> </p>
<p>如果上游支持重放，比如 Apache Kafka，那么就可以选择不用热备或者冷备来另外存储数据了，而是在失效时换一个 executor 进行数据重放即可。</p>
<h3 id="2-3-1-基于Receiver"><a href="#2-3-1-基于Receiver" class="headerlink" title="2.3.1. 基于Receiver"></a>2.3.1. <strong>基于Receiver</strong></h3><p><strong>偏移量又kafka负责，有可能导致重复消费</strong></p>
<p>这种是将 Kafka Consumer 的偏移管理交给 Kafka —— 将存在 ZooKeeper 里，失效后由 Kafka 去基于 offset 进行重放</p>
<p>这样可能的问题是，Kafka 将同一个 offset 的数据，重放给两个 batch 实例 —— 从而只能保证 at least once 的语义</p>
<h3 id="2-3-2-Direct方式"><a href="#2-3-2-Direct方式" class="headerlink" title="2.3.2. Direct方式"></a>2.3.2. <strong>Direct方式</strong></h3><p><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsB9DE.tmp.jpg" alt="img"> </p>
<p><strong>偏移量由spark自己管理，可以保证exactly-once</strong></p>
<p>由 Spark Streaming 直接管理 offset —— 可以给定 offset 范围，直接去 Kafka 的硬盘上读数据，使用 Spark Streaming 自身的均衡来代替 Kafka 做的均衡</p>
<p>这样可以保证，每个 offset 范围属于且只属于一个 batch，从而保证 exactly-once</p>
<p>所以看 Direct 的方式，<strong>归根结底是由 Spark Streaming 框架来负责整个 offset 的侦测、batch 分配、实际读取数据</strong>；并且这些分 batch 的信息都是 checkpoint 到可靠存储（一般是 HDFS）了。这就没有用到 Kafka 使用 ZooKeeper 来均衡 consumer 和记录 offset 的功能，而是把 Kafka 直接当成一个底层的文件系统来使用了。</p>
<h4 id="2-3-2-1-DirectKafkaInputDStream"><a href="#2-3-2-1-DirectKafkaInputDStream" class="headerlink" title="2.3.2.1. DirectKafkaInputDStream"></a>2.3.2.1. <strong>DirectKafkaInputDStream</strong></h4><p>负责侦测最新 offset，并将 offset 分配至唯一个 batch</p>
<h4 id="2-3-2-2-KafkaRDD"><a href="#2-3-2-2-KafkaRDD" class="headerlink" title="2.3.2.2. KafkaRDD"></a>2.3.2.2. <strong>KafkaRDD</strong></h4><p>负责去读指定 offset 范围内的数据，并基于此数据进行计算</p>
<h2 id="2-4-忽略"><a href="#2-4-忽略" class="headerlink" title="2.4. 忽略"></a>2.4. <strong>忽略</strong></h2><p><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsB9EF.tmp.jpg" alt="img"> </p>
<h3 id="2-4-1-粗粒度忽略"><a href="#2-4-1-粗粒度忽略" class="headerlink" title="2.4.1. 粗粒度忽略"></a>2.4.1. <strong>粗粒度忽略</strong></h3><p>在driver端捕获job抛出的异常，防止当前job失败，这样做会忽略掉整个batch里面的数据</p>
<h3 id="2-4-2-细粒度忽略"><a href="#2-4-2-细粒度忽略" class="headerlink" title="2.4.2. 细粒度忽略"></a>2.4.2. <strong>细粒度忽略</strong></h3><p>细粒度忽略是在excutor端进行的，如果接收的block失效后，将失败的Block忽略掉，只发送没有问题的block块到driver</p>
<p><strong>脑图制作参考</strong>：<a href="https://github.com/lw-lin/CoolplaySpark" target="_blank" rel="noopener">https://github.com/lw-lin/CoolplaySpark</a></p>
<p><strong>完整脑图链接地址</strong>：<a href="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/spark-streaming-all.png" target="_blank" rel="noopener">https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/spark-streaming-all.png</a></p>

    
  </div>

</article>


   
  <div class="text-center donation">
    <div class="inner-donation">
      <span class="btn-donation">支持一下</span>
      <div class="donation-body">
        <div class="tip text-center">扫一扫，支持sustcoder</div>
        <ul>
        
          <li class="item">
            
              <span>微信扫一扫</span>
            
            <img src="/images/qr-wechat.png" alt="">
          </li>
        
          <li class="item">
            
              <span>支付宝扫一扫</span>
            
            <img src="/images/qr-alipay.png" alt="">
          </li>
        
        </ul>
      </div>
    </div>
  </div>


   
  <div class="box-prev-next clearfix">
    <a class="show pull-left" href="/2018/12/03/sparkStreaming-sourceCodeAnalysis_job/">
        <i class="icon icon-angle-left"></i>
    </a>
    <a class="show pull-right" href="/2018/12/09/sparkStreaming-sourceCodeAnalysis_DataInputOutput/">
        <i class="icon icon-angle-right"></i>
    </a>
  </div>





   
      <div class="git"></div>
   
</div>


  <a id="backTop" class="back-top">
    <i class="icon-angle-up"></i>
  </a>




  <div class="modal" id="modal">
  <span id="cover" class="cover hide"></span>
  <div id="modal-dialog" class="modal-dialog hide-dialog">
    <div class="modal-header">
      <span id="close" class="btn-close">关闭</span>
    </div>
    <hr>
    <div class="modal-body">
      <ul class="list-toolbox">
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/blog/"
              rel="noopener noreferrer"
              target="_self"
              >
              博客
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/category/"
              rel="noopener noreferrer"
              target="_self"
              >
              分类
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/tag/"
              rel="noopener noreferrer"
              target="_self"
              >
              标签
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/link/"
              rel="noopener noreferrer"
              target="_self"
              >
              友链
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/about/"
              rel="noopener noreferrer"
              target="_self"
              >
              关于
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/search/"
              rel="noopener noreferrer"
              target="_self"
              >
              搜索
            </a>
          </li>
        
      </ul>

    </div>
  </div>
</div>



  
      <div class="fexo-comments comments-post">
    
  <section class="disqus-comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>
  </section>

  <script>
    var disqus_shortname = 'forsigner';
    
    var disqus_url = 'https://sustcoder.github.io/2018/12/09/sparkStreaming-sourceCodeAnalysis_faultTolerance/';
    
    (function(){
      var dsq = document.createElement('script');
      dsq.type = 'text/javascript';
      dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>

  <script id="dsq-count-scr" src="//forsigner.disqus.com/count.js" async></script>



    

    
    

    

    
    

  </div>

  

  <script type="text/javascript">
  function loadScript(url, callback) {
    var script = document.createElement('script')
    script.type = 'text/javascript';

    if (script.readyState) { //IE
      script.onreadystatechange = function() {
        if (script.readyState == 'loaded' ||
          script.readyState == 'complete') {
          script.onreadystatechange = null;
          callback();
        }
      };
    } else { //Others
      script.onload = function() {
        callback();
      };
    }

    script.src = url;
    document.getElementsByTagName('head')[0].appendChild(script);
  }

  window.onload = function() {
    loadScript('/js/bundle.js?235683', function() {
      // load success
    });
  }
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
