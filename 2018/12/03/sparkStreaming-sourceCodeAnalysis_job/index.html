<!DOCTYPE html>


  <html class="light page-post">


<head>
  <meta charset="utf-8">
  
  <title>sparkStreaming源码解析之Job动态生成 | sustcoder</title>

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
    <meta name="keywords" content="spark,源码解析," />
  

  <meta name="description" content="sparkStream的Job动态生成思维脑图">
<meta name="keywords" content="spark,streaming,源码,JOB">
<meta property="og:type" content="article">
<meta property="og:title" content="sparkStreaming源码解析之Job动态生成">
<meta property="og:url" content="https://sustcoder.github.io/2018/12/03/sparkStreaming-sourceCodeAnalysis_job/index.html">
<meta property="og:site_name" content="sustcoder">
<meta property="og:description" content="sparkStream的Job动态生成思维脑图">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsA82A.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsC3C6.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wps230.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wps614F.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wps1C70.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wps2045.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wps2046.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wps2057.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wps2058.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wps2059.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wps205A.tmp.jpg">
<meta property="og:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wps2081.tmp.jpg">
<meta property="og:updated_time" content="2018-12-07T03:47:55.207Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="sparkStreaming源码解析之Job动态生成">
<meta name="twitter:description" content="sparkStream的Job动态生成思维脑图">
<meta name="twitter:image" content="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsA82A.tmp.jpg">

  

  
    <link rel="icon" href="/favicon.ico">
  

  <link href="/css/styles.css?v=c114cben" rel="stylesheet">


  

  

  
  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?f1cc8b0edce213e23b90ab65ff3c30ff";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>


  
  <script type="text/javascript">
	(function(){
	    var bp = document.createElement('script');
	    var curProtocol = window.location.protocol.split(':')[0];
	    if (curProtocol === 'https') {
	        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
	    }
	    else {
	        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
	    }
	    var s = document.getElementsByTagName("script")[0];
	    s.parentNode.insertBefore(bp, s);
	})();
  </script>



  
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.3.0/css/font-awesome.min.css">
  

</head>

<body>


  
    <span id="toolbox-mobile" class="toolbox-mobile">盒子</span>
  

  <div class="post-header CENTER">
   
  <div class="toolbox">
    <a class="toolbox-entry" href="/">
      <span class="toolbox-entry-text">盒子</span>
      <i class="icon-angle-down"></i>
      <i class="icon-home"></i>
    </a>
    <ul class="list-toolbox">
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/blog/"
            rel="noopener noreferrer"
            target="_self"
            >
            博客
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/category/"
            rel="noopener noreferrer"
            target="_self"
            >
            分类
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/tag/"
            rel="noopener noreferrer"
            target="_self"
            >
            标签
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/link/"
            rel="noopener noreferrer"
            target="_self"
            >
            友链
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/about/"
            rel="noopener noreferrer"
            target="_self"
            >
            关于
          </a>
        </li>
      
        <li class="item-toolbox">
          <a
            class="CIRCLE"
            href="/search/"
            rel="noopener noreferrer"
            target="_self"
            >
            搜索
          </a>
        </li>
      
    </ul>
  </div>


</div>


  <div id="toc" class="toc-article">
    <strong class="toc-title">文章目录</strong>
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-启动"><span class="toc-text">1. 启动</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-JobScheduler"><span class="toc-text">1.1. JobScheduler</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-1-启动ReceiverTracker"><span class="toc-text">1.1.1. 启动ReceiverTracker</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-1-1-ReceiverSupervisor"><span class="toc-text">1.1.1.1. ReceiverSupervisor</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-1-2-拉起receivers"><span class="toc-text">1.1.1.2. 拉起receivers</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-2-启动DAG生成"><span class="toc-text">1.1.2. 启动DAG生成</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-2-1-startFirstTime"><span class="toc-text">1.1.2.1. startFirstTime</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-1-2-1-1-启动DAG"><span class="toc-text">1.1.2.1.1. 启动DAG</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1-1-2-1-2-启动timer"><span class="toc-text">1.1.2.1.2. 启动timer</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-RecurringTimer：定时器"><span class="toc-text">1.2. RecurringTimer：定时器</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-生成"><span class="toc-text">2. 生成</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-获取DAG实例"><span class="toc-text">2.2. 获取DAG实例</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-运行"><span class="toc-text">3. 运行</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-异步处理-JobScheduler"><span class="toc-text">3.1. 异步处理:JobScheduler</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-1-Job-类比Thread"><span class="toc-text">3.1.1. Job:类比Thread</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-2-JobHandler：真正执行job"><span class="toc-text">3.1.2. JobHandler：真正执行job</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-3-concurrentJobs-job并行度"><span class="toc-text">3.1.3. concurrentJobs : job并行度</span></a></li></ol></li></ol></li></ol>
  </div>



<div class="content content-post CENTER">
   <article id="post-sparkStreaming-sourceCodeAnalysis_job" class="article article-type-post" itemprop="blogPost">
  <header class="article-header">
    <h1 class="post-title">sparkStreaming源码解析之Job动态生成</h1>

    <div class="article-meta">
      <span>
        <i class="icon-calendar"></i>
        <span>2018.12.03</span>
      </span>

      
        <span class="article-author">
          <i class="icon-user"></i>
          <span>liyz</span>
        </span>
      

      
  <span class="article-category">
    <i class="icon-list"></i>
    <a class="article-category-link" href="/categories/spark/">spark</a>
  </span>



      
        <span>
          <i class="icon-comment"></i>
          <a href="https://sustcoder.github.io//2018/12/03/sparkStreaming-sourceCodeAnalysis_job/#disqus_thread"></a>
        </span>
      

      
      <i class="fa fa-eye"></i> 
        <span id="busuanzi_container_page_pv">
           &nbsp热度 <span id="busuanzi_value_site_uv">
           <i class="fa fa-spinner fa-spin"></i></span>℃
        </span>
      
      
    </div>
  </header>

  <div class="article-content">
    
      <p>此文是从思维导图中导出稍作调整后生成的，思维脑图对代码浏览支持不是很好，为了更好阅读体验，文中涉及到的源码都是删除掉不必要的代码后的伪代码，如需获取更好阅读体验可下载脑图配合阅读：</p>
<p> 此博文共分为四个部分：</p>
<ol>
<li><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsA82A.tmp.jpg" alt="img"><a href="https://sustcoder.github.io/2018/12/01/sparkStreaming-sourceCodeAnalysis_DAG/">DAG定义</a></li>
<li><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wpsC3C6.tmp.jpg" alt="img"><a href="https://sustcoder.github.io/2018/12/03/sparkStreaming-sourceCodeAnalysis_job/">Job动态生成</a></li>
<li><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wps230.tmp.jpg" alt="img"><a href="https://sustcoder.github.io/2018/12/09/sparkStreaming-sourceCodeAnalysis_dataInputOutput/">数据的产生与导入</a></li>
<li><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wps614F.tmp.jpg" alt="img"><a href="https://sustcoder.github.io/2018/12/12/sparkStreaming-sourceCodeAnalysis__faultTolerance/">容错</a></li>
</ol>
<p><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wps1C70.tmp.jpg" alt="img"></p>
<p>在 Spark Streaming 程序的入口，我们都会定义一个 batchDuration，就是需要每隔多长时间就比照静态的 DStreamGraph 来动态生成一个 RDD DAG 实例。在 Spark Streaming 里，总体负责动态作业调度的具体类是 JobScheduler。</p>
<p> JobScheduler 有两个非常重要的成员：JobGenerator 和 ReceiverTracker。JobScheduler 将每个 batch 的 RDD DAG 具体生成工作委托给 JobGenerator，而将源头输入数据的记录工作委托给 ReceiverTracker。</p>
<h1 id="1-启动"><a href="#1-启动" class="headerlink" title="1. 启动"></a>1. <strong>启动</strong></h1><p><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wps2045.tmp.jpg" alt="img"> </p>
<h2 id="1-1-JobScheduler"><a href="#1-1-JobScheduler" class="headerlink" title="1.1. JobScheduler"></a>1.1. <strong>JobScheduler</strong></h2><p><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wps2046.tmp.jpg" alt="img"> </p>
<p><strong>job运行的总指挥是JobScheduler.start()，</strong></p>
<p> JobScheduler 有两个非常重要的成员：JobGenerator 和 ReceiverTracker。JobScheduler 将每个 batch 的 RDD DAG 具体生成工作委托给 JobGenerator，而将源头输入数据的记录工作委托给 ReceiverTracker。</p>
<p><strong>在StreamingContext中启动scheduler</strong></p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StreamingContext</span>(<span class="params">sc,cp,batchDur</span>)</span>&#123;</span><br><span class="line">	<span class="keyword">val</span> scheduler = <span class="keyword">new</span> <span class="type">JobScheduler</span>(<span class="keyword">this</span>)</span><br><span class="line">	start()&#123;</span><br><span class="line">		scheduler.start()</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>在JobScheduler中启动recieverTracker和JobGenerator</strong></p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"> <span class="class"><span class="keyword">class</span> <span class="title">JobScheduler</span>(<span class="params">ssc</span>) </span>&#123;</span><br><span class="line">	<span class="keyword">var</span> receiverTracker:<span class="type">ReceiverTracker</span>=<span class="literal">null</span></span><br><span class="line">	<span class="keyword">var</span> jobGenerator=<span class="keyword">new</span> <span class="type">JobGenerator</span>(<span class="keyword">this</span>)</span><br><span class="line">	<span class="keyword">val</span> jobExecutor=<span class="type">ThreadUtils</span>.newDaemonFixedThreadPool()</span><br><span class="line">	<span class="keyword">if</span>(stared) <span class="keyword">return</span> <span class="comment">// 只启动一次</span></span><br><span class="line">	receiverTracker.start()</span><br><span class="line">    jobGenerator.start()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="1-1-1-启动ReceiverTracker"><a href="#1-1-1-启动ReceiverTracker" class="headerlink" title="1.1.1. 启动ReceiverTracker"></a>1.1.1. <strong>启动ReceiverTracker</strong></h3><p><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wps2057.tmp.jpg" alt="img"> </p>
<ol>
<li><p>在JobScheduler的start中启动ReceiverTraker:<code>receiverTracker.start()：</code></p>
</li>
<li><p>RecieverTracker 调用launchReceivers方法</p>
</li>
</ol>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span>  <span class="title">ReceiverTracker</span> </span>&#123;</span><br><span class="line">	<span class="keyword">var</span> endpoint:<span class="type">RpcEndpointRef</span>=<span class="literal">null</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">start</span></span>()=synchronized&#123;</span><br><span class="line">		endpoint=ssc.env.rpcEnv.setEndpoint(</span><br><span class="line">			<span class="string">"receiverTracker"</span>,</span><br><span class="line">			<span class="keyword">new</span> <span class="type">ReceiverTrackerEndpoint</span>() </span><br><span class="line">		)</span><br><span class="line">		launchReceivers()</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="1-1-1-1-ReceiverSupervisor"><a href="#1-1-1-1-ReceiverSupervisor" class="headerlink" title="1.1.1.1. ReceiverSupervisor"></a>1.1.1.1. <strong>ReceiverSupervisor</strong></h4><p> ReceiverTracker将RDD DAG和启动receiver的Func包装成ReceiverSupervisor发送到最优的Excutor节点上</p>
<h4 id="1-1-1-2-拉起receivers"><a href="#1-1-1-2-拉起receivers" class="headerlink" title="1.1.1.2. 拉起receivers"></a>1.1.1.2. <strong>拉起receivers</strong></h4><p> 从ReceiverInputDStreams中获取Receivers，并把他们发送到所有的worker nodes:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class  ReceiverTracker &#123;</span><br><span class="line">	var endpoint:RpcEndpointRef=</span><br><span class="line">	private def launchReceivers()&#123;</span><br><span class="line">		// DStreamGraph的属性inputStreams</span><br><span class="line">		val receivers=inputStreams.map&#123;nis=&gt;</span><br><span class="line">			val rcvr=nis.getReceiver()</span><br><span class="line">			// rcvr是对kafka,socket等接受数据的定义</span><br><span class="line">			rcvr</span><br><span class="line">		&#125;	</span><br><span class="line">		// 发送到worker</span><br><span class="line">		 endpoint.send(StartAllReceivers(receivers))</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="1-1-2-启动DAG生成"><a href="#1-1-2-启动DAG生成" class="headerlink" title="1.1.2. 启动DAG生成"></a>1.1.2. <strong>启动DAG生成</strong></h3><p><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wps2058.tmp.jpg" alt="img"> </p>
<p> 在JobScheduler的start中启动JobGenerator:<code>JobGenerator.start()</code></p>
<h4 id="1-1-2-1-startFirstTime"><a href="#1-1-2-1-startFirstTime" class="headerlink" title="1.1.2.1. startFirstTime"></a>1.1.2.1. <strong>startFirstTime</strong></h4><p><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wps2059.tmp.jpg" alt="img"> </p>
<p>  <strong>首次启动</strong></p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">startFirstTime</span></span>() &#123;</span><br><span class="line">	<span class="comment">// 定义定时器</span></span><br><span class="line">    <span class="keyword">val</span> startTime = </span><br><span class="line">	<span class="keyword">new</span> <span class="type">Time</span>(timer.getStartTime())</span><br><span class="line">	<span class="comment">// 启动DStreamGraph</span></span><br><span class="line">    graph.start(startTime - graph.batchDuration)</span><br><span class="line">    <span class="comment">//  启动定时器</span></span><br><span class="line">	 timer.start(startTime.milliseconds)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="1-1-2-1-1-启动DAG"><a href="#1-1-2-1-1-启动DAG" class="headerlink" title="1.1.2.1.1. 启动DAG"></a>1.1.2.1.1. <strong>启动DAG</strong></h5><p><strong>graph的生成是在StreamingContext中</strong>：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> graph: <span class="type">DStreamGraph</span>=&#123;</span><br><span class="line">	<span class="comment">// 重启服务时</span></span><br><span class="line">	<span class="keyword">if</span>（isCheckpointPresent）&#123;</span><br><span class="line">		checkPoint.graph.setContext(<span class="keyword">this</span>)</span><br><span class="line">		checkPoint.graph.restoreCheckPointData()</span><br><span class="line">		checkPoint.graph</span><br><span class="line">	&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">	<span class="comment">// 首次初始化时</span></span><br><span class="line">		<span class="keyword">val</span> newGraph=<span class="keyword">new</span> <span class="type">DStreamGraph</span>()</span><br><span class="line">		newGraph.setBatchDuration(_batchDur)</span><br><span class="line">		newGraph</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>在GenerateJobs中启动graph</strong>：</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">graph.start(nowTime-batchDuration)</span><br></pre></td></tr></table></figure>
<h5 id="1-1-2-1-2-启动timer"><a href="#1-1-2-1-2-启动timer" class="headerlink" title="1.1.2.1.2. 启动timer"></a>1.1.2.1.2. <strong>启动timer</strong></h5><p><strong>JobGenerator中定义了一个定时器：</strong></p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> timer=<span class="keyword">new</span> <span class="type">RecurringTimer</span>(colck,batchDuaraion,</span><br><span class="line">		longTime=&gt;eventLoop.post(</span><br><span class="line">            <span class="type">GenerateJobs</span>(</span><br><span class="line">				<span class="keyword">new</span> <span class="type">Time</span>(longTime)</span><br><span class="line">            )</span><br><span class="line">         )</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><strong>在JobGenerator启动时会开始执行这个调度器：</strong></p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">timer.start(startTime.milliseconds)</span><br></pre></td></tr></table></figure>
<h2 id="1-2-RecurringTimer：定时器"><a href="#1-2-RecurringTimer：定时器" class="headerlink" title="1.2. RecurringTimer：定时器"></a>1.2. <strong>RecurringTimer：定时器</strong></h2><p>// 来自 JobGenerator</p>
 <figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span>[streaming]</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JobGenerator</span>(<span class="params">jobScheduler: <span class="type">JobScheduler</span></span>) <span class="keyword">extends</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line">...</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> timer = <span class="keyword">new</span> <span class="type">RecurringTimer</span>(clock, ssc.graph.batchDuration.milliseconds,</span><br><span class="line">      longTime =&gt; eventLoop.post(<span class="type">GenerateJobs</span>(<span class="keyword">new</span> <span class="type">Time</span>(longTime))), <span class="string">"JobGenerator"</span>)</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过代码也可以看到，整个 timer 的调度周期就是 batchDuration，每次调度起来就是做一个非常简单的工作：往 eventLoop 里发送一个消息 —— 该为当前 batch (new Time(longTime)) GenerateJobs 了！</p>
<h1 id="2-生成"><a href="#2-生成" class="headerlink" title="2. 生成"></a>2. <strong>生成</strong></h1><p><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wps205A.tmp.jpg" alt="img"> </p>
<p><strong>JobGenerator中定义了一个定时器，在定时器中启动生成job操作</strong></p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JobGenerator</span></span>:</span><br><span class="line"><span class="comment">// 定义定时器</span></span><br><span class="line"><span class="keyword">val</span> timer=</span><br><span class="line">	<span class="keyword">new</span> <span class="type">RecurringTimer</span>(colck,batchDuaraion,</span><br><span class="line">	longTime=&gt;eventLoop.post(<span class="type">GenerateJobs</span>(</span><br><span class="line">	<span class="keyword">new</span> <span class="type">Time</span>(longTime))))</span><br><span class="line"> </span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">generateJobs</span></span>(time: <span class="type">Time</span>) &#123;</span><br><span class="line">  <span class="type">Try</span> &#123;</span><br><span class="line">      </span><br><span class="line">  <span class="comment">// 1. 将已收到的数据进行一次 allocate</span></span><br><span class="line">  receiverTracker.allocateBlocksToBatch(time)  </span><br><span class="line">      </span><br><span class="line">  <span class="comment">//   2. 复制一份新的DAG实例</span></span><br><span class="line">  graph.generateJobs(time)                                                 </span><br><span class="line">   &#125; <span class="keyword">match</span> &#123;</span><br><span class="line">     <span class="keyword">case</span> <span class="type">Success</span>(jobs) =&gt;</span><br><span class="line">      </span><br><span class="line">  <span class="comment">// 3. 获取 meta 信息</span></span><br><span class="line">  <span class="keyword">val</span> streamIdToInputInfos = jobScheduler.inputInfoTracker.getInfo(time)  </span><br><span class="line">      </span><br><span class="line">  <span class="comment">// 4. 提交job     </span></span><br><span class="line"> jobScheduler.submitJobSet(<span class="type">JobSet</span>(time, jobs, streamIdToInputInfos))   </span><br><span class="line">    <span class="keyword">case</span> <span class="type">Failure</span>(e) =&gt;</span><br><span class="line">      jobScheduler.reportError(<span class="string">"Error generating jobs for time "</span> + time, e)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 5. checkpoint</span></span><br><span class="line">  eventLoop.post(<span class="type">DoCheckpoint</span>(time, clearCheckpointDataLater = <span class="literal">false</span>))      </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="2-2-获取DAG实例"><a href="#2-2-获取DAG实例" class="headerlink" title="2.2. 获取DAG实例"></a>2.2. <strong>获取DAG实例</strong></h2><p>在生成Job并提交到excutor的第二步，</p>
<p>JobGenerator-&gt;DStreamGraph-&gt;OutputStreams-&gt;ForEachDStream-&gt;TransformationDStream-&gt;InputDStream</p>
<p>具体流程是：</p>
<p>- 1. JobGenerator调用了DStreamGraph里面的gererateJobs(time)方法</p>
<p>- 2. DStreamGraph里的generateJobs方法遍历了outputStreams</p>
<p>- 3. OutputStreams调用了其generateJob(time)方法</p>
<p>- 4. ForEachDStream实现了generateJob方法，调用了：</p>
<p>​    parent.getOrCompute(time)</p>
<p>递归的调用父类的getOrCompute方法去动态生成物理DAG图</p>
<h1 id="3-运行"><a href="#3-运行" class="headerlink" title="3. 运行"></a>3. <strong>运行</strong></h1><h2 id="3-1-异步处理-JobScheduler"><a href="#3-1-异步处理-JobScheduler" class="headerlink" title="3.1. 异步处理:JobScheduler"></a>3.1. <strong>异步处理:JobScheduler</strong></h2><p><img src="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/wps2081.tmp.jpg" alt="img"> </p>
<p><strong>JobScheduler通过线程池执行从JobGenerator提交过来的Job，jobExecutor异步的去处理提交的job</strong></p>
 <figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JobScheduler</span></span>&#123;</span><br><span class="line">  numConcurrentJobs = ssc.conf.getInt(<span class="string">"spark.streaming.concurrentJobs"</span>, <span class="number">1</span>)</span><br><span class="line">  <span class="keyword">val</span> jobExecutor =<span class="type">ThreadUtils</span>.</span><br><span class="line">	newDaemonFixedThreadPool(numConcurrentJobs, <span class="string">"streaming-job-executor"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">submitJobSet</span></span>(jobSet: <span class="type">JobSet</span>) &#123;</span><br><span class="line">		jobSet.jobs.foreach(job =&gt;</span><br><span class="line">                            jobExecutor.execute(<span class="keyword">new</span> <span class="type">JobHandler</span>(job)))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-1-1-Job-类比Thread"><a href="#3-1-1-Job-类比Thread" class="headerlink" title="3.1.1. Job:类比Thread"></a>3.1.1. <strong>Job:类比Thread</strong></h3><h3 id="3-1-2-JobHandler：真正执行job"><a href="#3-1-2-JobHandler：真正执行job" class="headerlink" title="3.1.2. JobHandler：真正执行job"></a>3.1.2. <strong>JobHandler：真正执行job</strong></h3><p> JobHandler 除了做一些状态记录外，最主要的就是调用 job.run()，</p>
<p> 在 ForEachDStream.generateJob(time) 时，是定义了 Job 的运行逻辑，即定义了 Job.func。而在 <strong>JobHandler 这里，是真正调用了 Job.run()、将触发 Job.func 的真正执行</strong>！</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 来自 JobHandler</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span></span>()</span><br><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 【发布 JobStarted 消息】</span></span><br><span class="line">  _eventLoop.post(<span class="type">JobStarted</span>(job))</span><br><span class="line">  <span class="type">PairRDDFunctions</span>.disableOutputSpecValidation.withValue(<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="comment">// 【主要逻辑，直接调用了 job.run()】</span></span><br><span class="line">    job.run()</span><br><span class="line">  &#125;</span><br><span class="line">  _eventLoop = eventLoop</span><br><span class="line">  <span class="keyword">if</span> (_eventLoop != <span class="literal">null</span>) &#123;</span><br><span class="line">  <span class="comment">// 【发布 JobCompleted 消息】</span></span><br><span class="line">    _eventLoop.post(<span class="type">JobCompleted</span>(job))</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-1-3-concurrentJobs-job并行度"><a href="#3-1-3-concurrentJobs-job并行度" class="headerlink" title="3.1.3. concurrentJobs : job并行度"></a>3.1.3. <strong>concurrentJobs : job并行度</strong></h3><p><strong>spark.streaming.concurrentJobs job并行度</strong></p>
<p>这里 jobExecutor 的线程池大小，是由 spark.streaming.concurrentJobs 参数来控制的，当没有显式设置时，其取值为 1。</p>
<p>进一步说，这里 jobExecutor 的线程池大小，就是能够并行执行的 Job 数。而回想前文讲解的 DStreamGraph.generateJobs(time) 过程，一次 batch 产生一个 Seq[Job}，里面可能包含多个 Job —— 所以，确切的，有几个 output 操作，就调用几次 ForEachDStream.generatorJob(time)，就产生出几个 Job</p>
<p><strong>脑图制作参考</strong>：<a href="https://github.com/lw-lin/CoolplaySpark" target="_blank" rel="noopener">https://github.com/lw-lin/CoolplaySpark</a></p>
<p><strong>完整脑图链接地址</strong>：<a href="https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/spark-streaming-all.png" target="_blank" rel="noopener">https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/spark/srccode/spark-streaming-all.png</a></p>

    
  </div>

</article>


   
  <div class="text-center donation">
    <div class="inner-donation">
      <span class="btn-donation">支持一下</span>
      <div class="donation-body">
        <div class="tip text-center">扫一扫，支持sustcoder</div>
        <ul>
        
          <li class="item">
            
              <span>微信扫一扫</span>
            
            <img src="/images/qr-wechat.png" alt="">
          </li>
        
          <li class="item">
            
              <span>支付宝扫一扫</span>
            
            <img src="/images/qr-alipay.png" alt="">
          </li>
        
        </ul>
      </div>
    </div>
  </div>


   
  <div class="box-prev-next clearfix">
    <a class="show pull-left" href="/2018/12/01/sparkStreaming-sourceCodeAnalysis_DAG/">
        <i class="icon icon-angle-left"></i>
    </a>
    <a class="show pull-right" href="/2018/12/09/sparkStreaming-sourceCodeAnalysis_DataInputOutput/">
        <i class="icon icon-angle-right"></i>
    </a>
  </div>





   
      <div class="git"></div>
   
</div>


  <a id="backTop" class="back-top">
    <i class="icon-angle-up"></i>
  </a>




  <div class="modal" id="modal">
  <span id="cover" class="cover hide"></span>
  <div id="modal-dialog" class="modal-dialog hide-dialog">
    <div class="modal-header">
      <span id="close" class="btn-close">关闭</span>
    </div>
    <hr>
    <div class="modal-body">
      <ul class="list-toolbox">
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/blog/"
              rel="noopener noreferrer"
              target="_self"
              >
              博客
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/category/"
              rel="noopener noreferrer"
              target="_self"
              >
              分类
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/tag/"
              rel="noopener noreferrer"
              target="_self"
              >
              标签
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/link/"
              rel="noopener noreferrer"
              target="_self"
              >
              友链
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/about/"
              rel="noopener noreferrer"
              target="_self"
              >
              关于
            </a>
          </li>
        
          <li class="item-toolbox">
            <a
              class="CIRCLE"
              href="/search/"
              rel="noopener noreferrer"
              target="_self"
              >
              搜索
            </a>
          </li>
        
      </ul>

    </div>
  </div>
</div>



  
      <div class="fexo-comments comments-post">
    
  <section class="disqus-comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>
  </section>

  <script>
    var disqus_shortname = 'forsigner';
    
    var disqus_url = 'https://sustcoder.github.io/2018/12/03/sparkStreaming-sourceCodeAnalysis_job/';
    
    (function(){
      var dsq = document.createElement('script');
      dsq.type = 'text/javascript';
      dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>

  <script id="dsq-count-scr" src="//forsigner.disqus.com/count.js" async></script>



    

    
    

    

    
    

  </div>

  

  <script type="text/javascript">
  function loadScript(url, callback) {
    var script = document.createElement('script')
    script.type = 'text/javascript';

    if (script.readyState) { //IE
      script.onreadystatechange = function() {
        if (script.readyState == 'loaded' ||
          script.readyState == 'complete') {
          script.onreadystatechange = null;
          callback();
        }
      };
    } else { //Others
      script.onload = function() {
        callback();
      };
    }

    script.src = url;
    document.getElementsByTagName('head')[0].appendChild(script);
  }

  window.onload = function() {
    loadScript('/js/bundle.js?235683', function() {
      // load success
    });
  }
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
