[{"title":"spark集群环境搭建","url":"https://sustcoder.github.io/2018/09/28/spark on yarn/","content":"<h1 id=\"spark-on-yarn\"><a href=\"#spark-on-yarn\" class=\"headerlink\" title=\"spark on yarn\"></a>spark on yarn</h1><h1 id=\"软件安装\"><a href=\"#软件安装\" class=\"headerlink\" title=\"软件安装\"></a>软件安装</h1><h2 id=\"当前环境\"><a href=\"#当前环境\" class=\"headerlink\" title=\"当前环境\"></a>当前环境</h2><p>hadoop环境搭建参考：<a href=\"https://my.oschina.net/freelili/blog/1834706\" target=\"_blank\" rel=\"noopener\">hadoop集群安装</a></p>\n<ul>\n<li>hadoop2.6</li>\n<li>spark-2.2.0-bin-hadoop2.6.tgz</li>\n<li>scala-2.11.12</li>\n</ul>\n<h2 id=\"安装scala\"><a href=\"#安装scala\" class=\"headerlink\" title=\"安装scala\"></a>安装scala</h2><blockquote>\n<p>tar -zxvf scala-2.11.12.tgz</p>\n<p>vi /etc/profile</p>\n</blockquote>\n<p>添加以下内容</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">export SCALA_HOME=/home/hadoop/app/scala</span><br><span class=\"line\">export PATH=$PATH:$SCALA_HOME/bin</span><br></pre></td></tr></table></figure>\n<p>使配置生效</p>\n<blockquote>\n<p>source /etc/profile</p>\n</blockquote>\n<p>查看scala版本号</p>\n<blockquote>\n<p>scala -version</p>\n</blockquote>\n<p>注意： <strong>用root账户修改完变量后，需要重新打开ssh链接，配置才能生效</strong></p>\n<h2 id=\"安装spark\"><a href=\"#安装spark\" class=\"headerlink\" title=\"安装spark\"></a>安装spark</h2><blockquote>\n<p>tar -zvf spark-2.2.0-bin-without-hadoop.tgz</p>\n<p>vi /etc/profile</p>\n</blockquote>\n<p>添加以下内容</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">export SPARK_HOME=/home/hadoop/app/spark2.2.0</span><br><span class=\"line\">export PATH=$PATH:$SPARK_HOME/bin</span><br></pre></td></tr></table></figure>\n<p>修改spark环境变量</p>\n<blockquote>\n<p>cp spark-env.sh.template spark-env.sh</p>\n<p>vi conf/spark-evn.sh</p>\n</blockquote>\n<p>添加以下内容</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">SPARK_DRIVER_MEMORY=512m</span><br><span class=\"line\">SPARK_DIST_CLASSPATH=$(/home/hadoop/app/hadoop-2.6.0/bin/hadoop classpath)</span><br><span class=\"line\">SPARK_LOCAL_DIRS=/home/hadoop/app/spark2.2.0</span><br><span class=\"line\">export SPARK_MASTER_IP=192.168.10.125</span><br><span class=\"line\"></span><br><span class=\"line\">export JAVA_HOME=/home/app/jdk8</span><br><span class=\"line\">export SCALA_HOME=/home/hadoop/app/scala</span><br><span class=\"line\">export HADOOP_HOME=/home/hadoop/app/hadoop</span><br><span class=\"line\">export HADOOP_CONF_DIR=/home/hadoop/app/hadoop/etc/hadoop</span><br><span class=\"line\">export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$SCALA_HOME/bin</span><br></pre></td></tr></table></figure>\n<p>使配置变量生效</p>\n<blockquote>\n<p>source /etc/profile</p>\n</blockquote>\n<p>配置slaves</p>\n<blockquote>\n<p>vi slaves</p>\n</blockquote>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">node3</span><br><span class=\"line\">node4</span><br></pre></td></tr></table></figure>\n<p>将配置文件下发到从节点</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">scp slaves hadoop@node3:/home/hadoop/app/spark2.2.0/conf</span><br><span class=\"line\">scp slaves hadoop@node4:/home/hadoop/app/spark2.2.0/conf</span><br><span class=\"line\">scp spark-env.sh hadoop@node3:/home/hadoop/app/spark2.2.0/conf</span><br><span class=\"line\">scp spark-env.sh hadoop@node4:/home/hadoop/app/spark2.2.0/conf</span><br></pre></td></tr></table></figure>\n<h2 id=\"启动\"><a href=\"#启动\" class=\"headerlink\" title=\"启动\"></a>启动</h2><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 启动zookeeper,可能存在选举延迟，可多执行几次./zkServer.sh status查看启动结果</span></span><br><span class=\"line\">./runRemoteCmd.sh \"/home/hadoop/app/zookeeper/bin/zkServer.sh start\" zookeeper</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 在node2节点上执行,启动HDFS</span></span><br><span class=\"line\">sbin/start-dfs.sh</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 在node2节点上执行,启动YARN</span></span><br><span class=\"line\">sbin/start-yarn.sh </span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 在node4节点上面执行,启动resourcemanager</span></span><br><span class=\"line\">sbin/yarn-daemon.sh start resourcemanager</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 在node2上启动spark</span></span><br><span class=\"line\">sbin/start-all.sh</span><br></pre></td></tr></table></figure>\n<h2 id=\"关闭\"><a href=\"#关闭\" class=\"headerlink\" title=\"关闭\"></a>关闭</h2><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 关闭spark</span></span><br><span class=\"line\">sbin/stop-all.sh</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 在node4上执行</span></span><br><span class=\"line\">sbin/yarn-daemon.sh stop resourcemanager</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 在node2上执行</span></span><br><span class=\"line\">sbin/stop-yarn.sh </span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 在node2上执行</span></span><br><span class=\"line\">sbin/stop-dfs.sh</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 关闭zookeeper</span></span><br><span class=\"line\">runRemoteCmd.sh \"/home/hadoop/app/zookeeper/bin/zkServer.sh stop\" zookeeper</span><br></pre></td></tr></table></figure>\n<p>查看启动情况</p>\n<blockquote>\n<p>jps</p>\n</blockquote>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> hdfs进程</span></span><br><span class=\"line\">1661 NameNode</span><br><span class=\"line\">1934 SecondaryNameNode</span><br><span class=\"line\">1750 DataNode</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> yarn进程</span></span><br><span class=\"line\">8395 ResourceManager</span><br><span class=\"line\">7725 NameNode</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> namenode HA</span></span><br><span class=\"line\">8256 DFSZKFailoverController</span><br><span class=\"line\">7985 JournalNode</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> zookeeper进程</span></span><br><span class=\"line\">1286 QuorumPeerMain</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> spark进程</span></span><br><span class=\"line\">2551 Master</span><br><span class=\"line\">2641 Worker</span><br></pre></td></tr></table></figure>\n<h2 id=\"管理界面\"><a href=\"#管理界面\" class=\"headerlink\" title=\"管理界面\"></a>管理界面</h2><figure class=\"highlight\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"attribute\">hadoop</span>:  http://node2:8088/</span><br><span class=\"line\"><span class=\"attribute\">nameNode</span>: http://node2:50070/</span><br><span class=\"line\"><span class=\"attribute\">nodeManager</span>:  http://node2:8042/</span><br><span class=\"line\">spark master:  http://node2:8080/</span><br><span class=\"line\">spark worker:  http://node2:8081/</span><br><span class=\"line\">spark jobs:  http://node2:4040/</span><br></pre></td></tr></table></figure>\n<h2 id=\"运行示例\"><a href=\"#运行示例\" class=\"headerlink\" title=\"运行示例\"></a>运行示例</h2><p><strong>Spark-shell</strong></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">vi test.text# 在文件中添加 hello spark</span><br><span class=\"line\">hdfs dfs -mkdir /test # 创建文件夹</span><br><span class=\"line\">hdfs dfs -put test.txt /test # 上传文件到hdfs</span><br><span class=\"line\">hdfs dfs -ls /test # 查看是否上传成功</span><br><span class=\"line\">./bin/spark-shell</span><br><span class=\"line\">sc.textFile(\"hdfs://node2:9000/test/test.txt\") # 从hdfs上获取文件</span><br><span class=\"line\">sc.first() # 获取文件的第一行数据</span><br></pre></td></tr></table></figure>\n<p><strong>Run application locally(Local模式)</strong></p>\n<blockquote>\n<p>./bin/spark-submit –class org.apache.spark.examples.SparkPi –master local[4] /home/hadoop/app/spark2.2.0/examples/jars/spark-examples_2.11-2.2.0.jar</p>\n</blockquote>\n<p><strong>Run on a Spark standalone cluster(Standalone模式,使用Spark自带的简单集群管理器)</strong></p>\n<blockquote>\n<p>./bin/spark-submit \\<br>–class org.apache.spark.examples.SparkPi \\<br>–master spark://node2:7077 \\<br>–executor-memory 512m \\<br>–total-executor-cores 4 \\<br>/home/hadoop/app/spark2.2.0/examples/jars/spark-examples_2.11-2.2.0.jar 10</p>\n</blockquote>\n<p><strong>Run on yarn(YARN模式，使用YARN作为集群管理器)</strong></p>\n<blockquote>\n<p>./bin/spark-submit –class org.apache.spark.examples.SparkPi –master yarn –deploy-mode client examples/jars/spark-examples*.jar 10</p>\n</blockquote>\n<h1 id=\"注意事项\"><a href=\"#注意事项\" class=\"headerlink\" title=\"注意事项\"></a>注意事项</h1><blockquote>\n<p>HADOOP_CONF_DIR=/home/hadoop/app/hadoop/etc/hadoop</p>\n</blockquote>\n<p>确保 <code>HADOOP_CONF_DIR</code> 或者 <code>YARN_CONF_DIR</code> 指向包含 Hadoop 集群的（客户端）配置文件的目录。这些配置被用于写入 HDFS 并连接到 YARN ResourceManager 。此目录中包含的配置将被分发到 YARN 集群，以便 application（应用程序）使用的所有的所有 containers（容器）都使用相同的配置。如果配置引用了 Java 系统属性或者未由 YARN 管理的环境变量，则还应在 Spark 应用程序的配置（driver（驱动程序），executors（执行器），和在客户端模式下运行时的 AM ）。</p>\n<blockquote>\n<p> SPARK_DIST_CLASSPATH=$(/home/hadoop/app/hadoop-2.6.0/bin/hadoop classpath)</p>\n</blockquote>\n<p>Pre-build with user-provided Hadoop: 属于“Hadoop free”版,不包含hadoop的jar等，这样，下载到的Spark，可应用到任意Hadoop 版本。但是需要在spark的spar-evn.sh中指定配置hadoop的安装路径。</p>\n<blockquote>\n<p>spark-submit</p>\n</blockquote>\n<p>如果用户的应用程序被打包好了，它可以使用 <code>bin/spark-submit</code> 脚本来启动。这个脚本负责设置 Spark 和它的依赖的 classpath，并且可以支持 Spark 所支持的不同的 Cluster Manager 以及 deploy mode（部署模式）:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">./bin/spark-submit \\</span><br><span class=\"line\">  --class &lt;main-class&gt; \\</span><br><span class=\"line\">  --master &lt;master-url&gt; \\</span><br><span class=\"line\">  --deploy-mode &lt;deploy-mode&gt; \\</span><br><span class=\"line\">  --conf &lt;key&gt;=&lt;value&gt; \\</span><br><span class=\"line\">  ... # other options</span><br><span class=\"line\">  &lt;application-jar&gt; \\</span><br><span class=\"line\">  [application-arguments]</span><br></pre></td></tr></table></figure>\n<p>一些常用的 options（选项）有 :</p>\n<ul>\n<li><code>--class</code>: 您的应用程序的入口点（例如。 <code>org.apache.spark.examples.SparkPi</code>)</li>\n<li><code>--master</code>: standalone模式下是集群的 master URL，on yarn模式下值是<code>yarn</code></li>\n<li><code>--deploy-mode</code>: 是在 worker 节点(<code>cluster</code>) 上还是在本地作为一个外部的客户端(<code>client</code>) 部署您的 driver(默认: <code>client</code>)</li>\n<li><code>--conf</code>: 按照 key=value 格式任意的 Spark 配置属性。对于包含空格的 value（值）使用引号包 “key=value” 起来。</li>\n<li><code>application-jar</code>: 包括您的应用以及所有依赖的一个打包的 Jar 的路径。该 URL 在您的集群上必须是全局可见的，例如，一个 <code>hdfs://</code> path 或者一个 <code>file://</code> 在所有节点是可见的。</li>\n<li><code>application-arguments</code>: 传递到您的 main class 的 main 方法的参数，如果有的话。</li>\n</ul>\n<h1 id=\"异常处理\"><a href=\"#异常处理\" class=\"headerlink\" title=\"异常处理\"></a>异常处理</h1><p><strong>执行脚本</strong></p>\n<blockquote>\n<p>./bin/spark-submit –class org.apache.spark.examples.SparkPi –master yarn –deploy-mode client /home/hadoop/app/spark2.2.0/examples/jars/spark-examples_2.11-2.2.0.jar</p>\n</blockquote>\n<p><strong>报错信息一</strong></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">Application application_1537990303043_0001 failed 2 times due to AM Container for appattempt_1537990303043_0001_000002 exited with  exitCode: -103</span><br><span class=\"line\">Diagnostics: </span><br><span class=\"line\">Container [pid=2344,containerID=container_1537990303043_0001_02_000001] is running beyond virtual memory limits. </span><br><span class=\"line\">Current usage: 74.0 MB of 1 GB physical memory used; </span><br><span class=\"line\">2.2 GB of 2.1 GB virtual memory used. Killing container.</span><br></pre></td></tr></table></figure>\n<p><strong>问题原因</strong></p>\n<p>虚拟机物理内存设置的是1G，则对应虚拟内存最大为1*2.1=2.1GB,实际使用了2.2[此处疑问：为什么就使用了2.2，单个任务默认分配1024M，加上一个任务的Container默认1024M导致吗？]，所以需要扩大虚拟内存的比例，或者限制container和task的大小，或者关闭掉对虚拟内存的检测。</p>\n<p><strong>解决方法</strong></p>\n<p>修改<code>yarn-site.xml</code>文件，新增以下内容，详情原因请参考：<a href=\"\">YARN 内存参数详解</a></p>\n<figure class=\"highlight xml\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>yarn.nodemanager.vmem-pmem-ratio<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>3<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">description</span>&gt;</span>虚拟内存和物理内存比率，默认为2.1<span class=\"tag\">&lt;/<span class=\"name\">description</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>false<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">description</span>&gt;</span>不检查虚拟内存，默认为true<span class=\"tag\">&lt;/<span class=\"name\">description</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p><strong>报错二</strong></p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\">Exception in thread <span class=\"string\">\"main\"</span> org.apache.spark.SparkException: Yarn application has already ended! It might have been killed or unable to launch application master.</span><br><span class=\"line\">\tat org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.waitForApplication(YarnClientSchedulerBackend.scala:<span class=\"number\">85</span>)</span><br><span class=\"line\">\tat org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:<span class=\"number\">62</span>)</span><br><span class=\"line\">\tat org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:<span class=\"number\">173</span>)</span><br><span class=\"line\">\tat org.apache.spark.SparkContext.&lt;init&gt;(SparkContext.scala:<span class=\"number\">509</span>)</span><br><span class=\"line\">\tat org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:<span class=\"number\">2509</span>)</span><br><span class=\"line\">\tat org.apache.spark.sql.SparkSession$Builder$$anonfun$<span class=\"number\">6</span>.apply(SparkSession.scala:<span class=\"number\">909</span>)</span><br><span class=\"line\">\tat org.apache.spark.sql.SparkSession$Builder$$anonfun$<span class=\"number\">6</span>.apply(SparkSession.scala:<span class=\"number\">901</span>)</span><br><span class=\"line\">\tat scala.Option.getOrElse(Option.scala:<span class=\"number\">121</span>)</span><br><span class=\"line\">\tat org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:<span class=\"number\">901</span>)</span><br><span class=\"line\">\tat org.apache.spark.examples.SparkPi$.main(SparkPi.scala:<span class=\"number\">31</span>)</span><br><span class=\"line\">\tat org.apache.spark.examples.SparkPi.main(SparkPi.scala)</span><br><span class=\"line\">\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class=\"line\">\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:<span class=\"number\">62</span>)</span><br><span class=\"line\">\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class=\"number\">43</span>)</span><br><span class=\"line\">\tat java.lang.reflect.Method.invoke(Method.java:<span class=\"number\">498</span>)</span><br><span class=\"line\">\tat org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:<span class=\"number\">755</span>)</span><br><span class=\"line\">\tat org.apache.spark.deploy.SparkSubmit$.doRunMain$<span class=\"number\">1</span>(SparkSubmit.scala:<span class=\"number\">180</span>)</span><br><span class=\"line\">\tat org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:<span class=\"number\">205</span>)</span><br><span class=\"line\">\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:<span class=\"number\">119</span>)</span><br><span class=\"line\">\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)</span><br><span class=\"line\"><span class=\"number\">18</span>/<span class=\"number\">09</span>/<span class=\"number\">04</span> <span class=\"number\">17</span>:<span class=\"number\">01</span>:<span class=\"number\">43</span> INFO util.ShutdownHookManager: Shutdown hook called</span><br></pre></td></tr></table></figure>\n<p><strong>问题原因</strong></p>\n<p>以上报错是在伪集群上运行时报错信息，具体报错原因未知，在切换到真正的集群环境后无此报错</p>\n<h1 id=\"配置链接\"><a href=\"#配置链接\" class=\"headerlink\" title=\"配置链接\"></a>配置链接</h1><p><strong>hadoop</strong></p>\n<ul>\n<li><p><a href=\"https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/hadoop/conf/hadoop/core-site.xml\" target=\"_blank\" rel=\"noopener\">core-site.xml</a></p>\n</li>\n<li><p><a href=\"https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/hadoop/conf/hadoop/hdfs-site.xml\" target=\"_blank\" rel=\"noopener\">hdfs-site.xml</a></p>\n</li>\n<li><p><a href=\"https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/hadoop/conf/hadoop/mapred-site.xml\" target=\"_blank\" rel=\"noopener\">mapred-site.xml</a></p>\n</li>\n<li><p><a href=\"https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/hadoop/conf/hadoop/yarn-site.xml\" target=\"_blank\" rel=\"noopener\">yarn-site.xml</a></p>\n</li>\n<li><p><a href=\"https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/hadoop/conf/hadoop/hadoop-env.sh\" target=\"_blank\" rel=\"noopener\">hadoop-env.sh</a></p>\n</li>\n<li><p><a href=\"https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/hadoop/conf/hadoop/masters\" target=\"_blank\" rel=\"noopener\">masters</a></p>\n</li>\n<li><p><a href=\"https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/hadoop/conf/hadoop/slaves\" target=\"_blank\" rel=\"noopener\">slaves</a></p>\n</li>\n</ul>\n<p><strong>zookeeper</strong></p>\n<ul>\n<li><a href=\"https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/hadoop/conf/zookeeper/zoo.cfg\" target=\"_blank\" rel=\"noopener\">zoo.cfg</a></li>\n</ul>\n<p><strong>spark</strong></p>\n<ul>\n<li><a href=\"https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/hadoop/conf/spark/spark-env.sh\" target=\"_blank\" rel=\"noopener\">spark-env.sh</a></li>\n<li><a href=\"https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018//hadoop/conf/spark/slaves\" target=\"_blank\" rel=\"noopener\">slaves</a></li>\n</ul>\n<p><strong>env</strong></p>\n<ul>\n<li><a href=\"https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/hadoop/conf/env/hosts\" target=\"_blank\" rel=\"noopener\">hosts</a></li>\n<li><a href=\"https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/hadoop/conf/env/profile\" target=\"_blank\" rel=\"noopener\">profile</a></li>\n</ul>\n<p><strong>tools</strong></p>\n<ul>\n<li><a href=\"https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/hadoop/conf/tools/deploy.conf\" target=\"_blank\" rel=\"noopener\">deploy.conf</a></li>\n<li><a href=\"https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/hadoop/conf/tools/deploy.sh\" target=\"_blank\" rel=\"noopener\">deploy.sh</a></li>\n<li><a href=\"https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/hadoop/conf/tools/runRemoteCmd.sh\" target=\"_blank\" rel=\"noopener\">runRemoteCmd.sh</a></li>\n</ul>\n","categories":["spark"],"tags":["spark","环境"]},{"title":"YARN 内存参数详解","url":"https://sustcoder.github.io/2018/09/27/YARN 内存参数详解/","content":"<h2 id=\"yarn组件依赖关系\"><a href=\"#yarn组件依赖关系\" class=\"headerlink\" title=\"yarn组件依赖关系\"></a>yarn组件依赖关系</h2><p><img src=\"https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/hadoop/structure/yarn_structure.png\" alt=\"yarn结果图\"></p>\n<p>yarn主要由两部分组成，ResourceManager和NodeManger。NodeManager里面包含多个Container，每个Container里可以运行多个task，比如MapTask和ReduceTask等。ApplicationMaster也是在Container中运行。</p>\n<p>在YARN中，资源管理由ResourceManager和NodeManager共同完成，其中，<strong>ResourceManager中的调度器负责资源的分配，而NodeManager则负责资源的供给和隔离</strong>。ResourceManager将某个NodeManager上资源分配给任务（这就是所谓的“资源调度”）后，NodeManager需按照要求为任务提供相应的资源，甚至保证这些资源应具有独占性，为任务运行提供基础的保证，这就是所谓的资源隔离。</p>\n<p>关于yarn的详细介绍可参考：<a href=\"https://my.oschina.net/freelili/blog/1853714\" target=\"_blank\" rel=\"noopener\">yarn的架构及作业调度</a></p>\n<h2 id=\"内存相关参数\"><a href=\"#内存相关参数\" class=\"headerlink\" title=\"内存相关参数\"></a>内存相关参数</h2><p><a href=\"https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-common/yarn-default.xml\" target=\"_blank\" rel=\"noopener\">yarn-site.xml官网参数表及其解释</a></p>\n<table>\n<thead>\n<tr>\n<th>配置文件</th>\n<th>配置设置</th>\n<th>默认值</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>yarn-site.xml</td>\n<td>yarn.nodemanager.resource.memory-mb</td>\n<td>-1</td>\n</tr>\n<tr>\n<td>yarn-site.xml</td>\n<td>yarn.nodemanager.vmem-pmem-ratio</td>\n<td>2.1</td>\n</tr>\n<tr>\n<td>yarn-site.xml</td>\n<td>yarn.nodemanager.vmem-check-enabled</td>\n<td>true</td>\n</tr>\n<tr>\n<td>yarn-site.xml</td>\n<td>yarn.nodemanager.pmem-check-enabled</td>\n<td>true</td>\n</tr>\n<tr>\n<td>yarn-site.xml</td>\n<td>yarn.scheduler.minimum-allocation-mb</td>\n<td>1024MB</td>\n</tr>\n<tr>\n<td>yarn-site.xml</td>\n<td>yarn.scheduler.maximum-allocation-mb</td>\n<td>8192 MB</td>\n</tr>\n<tr>\n<td>yarn-site.xml</td>\n<td>yarn.nodemanager.resource.cpu-vcores</td>\n<td>8</td>\n</tr>\n<tr>\n<td>yarn-site.xml</td>\n<td>yarn.scheduler.minimum-allocation-vcores</td>\n<td>1</td>\n</tr>\n<tr>\n<td>yarn-site.xml</td>\n<td>yarn.scheduler.maximum-allocation-vcores</td>\n<td>32</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>mapred-site.xml</td>\n<td>yarn.app.mapreduce.am.resource.mb</td>\n<td>1536 MB</td>\n</tr>\n<tr>\n<td>mapred-site.xml</td>\n<td>yarn.app.mapreduce.am.command-opts</td>\n<td>-Xmx1024m</td>\n</tr>\n<tr>\n<td>mapred-site.xml</td>\n<td>mapreduce.map.memory.mb</td>\n<td>1024 MB</td>\n</tr>\n<tr>\n<td>mapred-site.xml</td>\n<td>mapreduce.reduce.memory.mb</td>\n<td>1024 MB</td>\n</tr>\n<tr>\n<td>mapred-site.xml</td>\n<td>mapreduce.map.java.opts</td>\n<td>最新版已经去掉</td>\n</tr>\n<tr>\n<td>mapred-site.xml</td>\n<td>mapreduce.reduce.java.opts</td>\n<td>最新版已经去掉</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"参数解释\"><a href=\"#参数解释\" class=\"headerlink\" title=\"参数解释\"></a>参数解释</h2><h3 id=\"NodeManager\"><a href=\"#NodeManager\" class=\"headerlink\" title=\"NodeManager\"></a>NodeManager</h3><ul>\n<li><code>yarn.nodemanager.resource.memory-mb</code>：节点最大可用内存，如果值为-1且<code>yarn.nodemanager.resource.detect-hardware-capabilities</code>值为<code>true</code>，则根据系统内存自动计算，否则默认值为8192M</li>\n<li><code>yarn.nodemanager.vmem-pmem-ratio</code>：虚拟内存率，Container 的虚拟内存大小的限制，每使用1MB物理内存，最多可用的虚拟内存数</li>\n<li><code>yarn.nodemanager.pmem-check-enabled</code>：是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认是true;</li>\n<li><code>yarn.nodemanager.vmem-check-enabled</code>：是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认是true</li>\n</ul>\n<h3 id=\"ResourceManager\"><a href=\"#ResourceManager\" class=\"headerlink\" title=\"ResourceManager\"></a>ResourceManager</h3><ul>\n<li><code>yarn.scheduler.minimum-allocation-mb</code>：单个任务可申请的最少物理内存量，默认是1024（MB），如果一个任务申请的物理内存量少于该值，则该对应的值改为这个数</li>\n<li><code>yarn.scheduler.maximum-allocation-mb</code>：单个任务可申请的最多物理内存量，默认是8192（MB）。</li>\n</ul>\n<h3 id=\"ApplicationMaster\"><a href=\"#ApplicationMaster\" class=\"headerlink\" title=\"ApplicationMaster\"></a>ApplicationMaster</h3><ul>\n<li><code>mapreduce.map.memory.mb</code>：分配给 Map Container的内存大小，默认为1024。如果Map Task实际使用的资源量超过该值，则会被强制杀死。</li>\n<li><code>mapreduce.reduce.memory.mb</code>：分配给 Reduce Container的内存大小，默认为1024。如果Reduce Task实际使用的资源量超过该值，则会被强制杀死。</li>\n<li><code>mapreduce.map.java.opts</code>：运行 Map 任务的 jvm 参数，如 -Xmx，-Xms 等选项</li>\n<li><code>mapreduce.reduce.java.opts</code>：运行 Reduce 任务的 jvm 参数，如-Xmx，-Xms等选项</li>\n</ul>\n<h3 id=\"CPU-资源\"><a href=\"#CPU-资源\" class=\"headerlink\" title=\"CPU 资源\"></a>CPU 资源</h3><ul>\n<li><code>yarn.nodemanager.resource.cpu-vcores</code>：该节点上 YARN 可使用的虚拟 CPU 个数，如果值是-1且<code>yarn.nodemanager.resource.detect-hardware-capabilities</code>值为·true`，则其cpu数目根据系统而定，否则默认值为8</li>\n<li><code>yarn.scheduler.minimum-allocation-vcores</code>：单个任务可申请的最小虚拟CPU个数, 默认是1</li>\n<li><code>yarn.scheduler.maximum-allocation-vcores</code>：单个任务可申请的最多虚拟CPU个数，默认是4</li>\n</ul>\n<h2 id=\"Killing-Container\"><a href=\"#Killing-Container\" class=\"headerlink\" title=\"Killing Container\"></a>Killing Container</h2><p>在本地虚拟机上跑task时报错如下</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">Application application_1537990303043_0001 failed 2 times due to AM Container for appattempt_1537990303043_0001_000002 exited with  exitCode: -103</span><br><span class=\"line\">Diagnostics: </span><br><span class=\"line\">Container [pid=2344,containerID=container_1537990303043_0001_02_000001] is running beyond virtual memory limits. </span><br><span class=\"line\">Current usage: 74.0 MB of 1 GB physical memory used; </span><br><span class=\"line\">2.2 GB of 2.1 GB virtual memory used. Killing container.</span><br></pre></td></tr></table></figure>\n<p>虚拟机物理内存设置的是1G，则对应虚拟内存最大为1*2.1=2.1GB,实际使用了2.2[此处疑问：为什么就使用了2.2，单个任务默认分配1024M，加上一个任务的Container默认1024M导致吗？]，所以需要扩大虚拟内存的比例，或者限制container和task的大小，或者关闭掉对虚拟内存的检测。</p>\n<h3 id=\"yarn-site-xml\"><a href=\"#yarn-site-xml\" class=\"headerlink\" title=\"yarn-site.xml\"></a>yarn-site.xml</h3><figure class=\"highlight xml\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">&lt;!--</span></span><br><span class=\"line\"><span class=\"comment\">&lt;property&gt;</span></span><br><span class=\"line\"><span class=\"comment\">    &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;</span></span><br><span class=\"line\"><span class=\"comment\">    &lt;value&gt;256&lt;/value&gt;</span></span><br><span class=\"line\"><span class=\"comment\">    &lt;description&gt;每个container可申请最小内存&lt;/description&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;/property&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;property&gt;</span></span><br><span class=\"line\"><span class=\"comment\">    &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;</span></span><br><span class=\"line\"><span class=\"comment\">    &lt;value&gt;512&lt;/value&gt;</span></span><br><span class=\"line\"><span class=\"comment\">    &lt;description&gt;每个container可申请最大内存&lt;/description&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;/property&gt;</span></span><br><span class=\"line\"><span class=\"comment\">--&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>yarn.nodemanager.vmem-pmem-ratio<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>3<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">description</span>&gt;</span>虚拟内存和物理内存比率，默认为2.1<span class=\"tag\">&lt;/<span class=\"name\">description</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>false<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">description</span>&gt;</span>不检查虚拟内存，默认为true<span class=\"tag\">&lt;/<span class=\"name\">description</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"混淆点\"><a href=\"#混淆点\" class=\"headerlink\" title=\"混淆点\"></a>混淆点</h2><p><code>yarn.scheduler.minimum-allocation-mb</code>和<code>yarn.scheduler.maximum-allocation-mb</code>这两个参数不能限制任务的真正大小？？？</p>\n<p>这两个参数是管理员用来设置用户能够设置的每个任务可申请的最小和最大内存资源。具体每个任务到底申请多少，由各个应用程序单独设置，如果是mapreduce程序，可以map task申请的资源可通过mapreduce.map.memory.mb指定，reduce task的资源可通过mapreduce.reduce.memory.mb指定，这两个参数最大不能超过yarn.scheduler.maximum-allocation-mb</p>\n","categories":["spark"],"tags":["spark","环境"]},{"title":"spark数据倾斜调优[转]","url":"https://sustcoder.github.io/2018/09/18/Spark数据倾斜调优/","content":"<h1 id=\"一、数据倾斜发生的原理\"><a href=\"#一、数据倾斜发生的原理\" class=\"headerlink\" title=\"一、数据倾斜发生的原理\"></a>一、数据倾斜发生的原理</h1><ul>\n<li><p><strong>原理</strong>：在进行shuffle的时候，必须将各个节点上相同的key拉取到某个节点上的一个task来进行处理，比如按照key进行聚合或join等操作。此时如果某个key对应的数据量特别大的话，就会发生数据倾斜。数据倾斜只会发生在shuffle过程中。常用的并且可能会触发shuffle操作的算子：distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition等。</p>\n</li>\n<li><p><strong>表现</strong>：Spark作业看起来会运行得非常缓慢，甚至可能因为某个task处理的数据量过大导致内存溢出。</p>\n</li>\n<li><p><strong>定位</strong>：</p>\n<ul>\n<li><p>确定数据倾斜发生在第几个stage中。</p>\n<p>可以通过Spark Web UI来查看当前运行到了第几个stage。并深入看一下当前这个stage各个task分配的数据量及运行时间</p>\n</li>\n<li><p>根据stage划分原理，推算出来发生倾斜的那个stage对应代码中的哪一部分。</p>\n</li>\n<li><p>分析一下那个执行了shuffle操作并且导致了数据倾斜的RDD/Hive表，查看一下其中key的分布情况。</p>\n</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"二、数据倾斜解决方案\"><a href=\"#二、数据倾斜解决方案\" class=\"headerlink\" title=\"二、数据倾斜解决方案\"></a>二、数据倾斜解决方案</h1><h2 id=\"方案一：使用Hive-ETL预处理数据\"><a href=\"#方案一：使用Hive-ETL预处理数据\" class=\"headerlink\" title=\"方案一：使用Hive ETL预处理数据\"></a>方案一：使用Hive ETL预处理数据</h2><ul>\n<li><strong>方案适用场景</strong>：导致数据倾斜的是Hive表。如果该Hive表中的数据本身很不均匀（比如某个key对应了100万数据，其他key才对应了10条数据），而且业务场景需要频繁使用Spark对Hive表执行某个分析操作，那么比较适合使用这种技术方案。</li>\n<li><strong>方案实现思路</strong>：此时可以评估一下，是否可以通过Hive来进行数据预处理（即通过Hive ETL预先对数据按照key进行聚合，或者是预先和其他表进行join），然后在Spark作业中针对的数据源就不是原来的Hive表了，而是预处理后的Hive表。此时由于数据已经预先进行过聚合或join操作了，那么在Spark作业中也就不需要使用原先的shuffle类算子执行这类操作了。</li>\n<li><strong>方案实现原理</strong>：这种方案从根源上解决了数据倾斜，因为彻底避免了在Spark中执行shuffle类算子，那么肯定就不会有数据倾斜的问题了。但是这里也要提醒一下大家，这种方式属于治标不治本。因为毕竟数据本身就存在分布不均匀的问题，所以Hive ETL中进行group by或者join等shuffle操作时，还是会出现数据倾斜，导致Hive ETL的速度很慢。我们只是把数据倾斜的发生提前到了Hive ETL中，避免Spark程序发生数据倾斜而已。</li>\n<li><strong>方案优点</strong>：实现起来简单便捷，效果还非常好，完全规避掉了数据倾斜，Spark作业的性能会大幅度提升。</li>\n<li><strong>方案缺点</strong>：治标不治本，Hive ETL中还是会发生数据倾斜。</li>\n<li><strong>方案实践经验</strong>：在一些Java系统与Spark结合使用的项目中，会出现Java代码频繁调用Spark作业的场景，而且对Spark作业的执行性能要求很高，就比较适合使用这种方案。将数据倾斜提前到上游的Hive ETL，每天仅执行一次，只有那一次是比较慢的，而之后每次Java调用Spark作业时，执行速度都会很快，能够提供更好的用户体验。</li>\n<li><strong>项目实践经验</strong>：在美团·点评的交互式用户行为分析系统中使用了这种方案，该系统主要是允许用户通过Java Web系统提交数据分析统计任务，后端通过Java提交Spark作业进行数据分析统计。要求Spark作业速度必须要快，尽量在10分钟以内，否则速度太慢，用户体验会很差。所以我们将有些Spark作业的shuffle操作提前到了Hive ETL中，从而让Spark直接使用预处理的Hive中间表，尽可能地减少Spark的shuffle操作，大幅度提升了性能，将部分作业的性能提升了6倍以上。</li>\n</ul>\n<h2 id=\"方案二：过滤少数导致倾斜的key\"><a href=\"#方案二：过滤少数导致倾斜的key\" class=\"headerlink\" title=\"方案二：过滤少数导致倾斜的key\"></a>方案二：过滤少数导致倾斜的key</h2><ul>\n<li><strong>方案适用场景</strong>：如果发现导致倾斜的key就少数几个，而且对计算本身的影响并不大的话，那么很适合使用这种方案。比如99%的key就对应10条数据，但是只有一个key对应了100万数据，从而导致了数据倾斜。</li>\n<li><strong>方案实现思路</strong>：如果我们判断那少数几个数据量特别多的key，对作业的执行和计算结果不是特别重要的话，那么干脆就直接过滤掉那少数几个key。比如，在Spark SQL中可以使用where子句过滤掉这些key或者在Spark Core中对RDD执行filter算子过滤掉这些key。如果需要每次作业执行时，动态判定哪些key的数据量最多然后再进行过滤，那么可以使用sample算子对RDD进行采样，然后计算出每个key的数量，取数据量最多的key过滤掉即可。</li>\n<li><strong>方案实现原理</strong>：将导致数据倾斜的key给过滤掉之后，这些key就不会参与计算了，自然不可能产生数据倾斜。</li>\n<li><strong>方案优点</strong>：实现简单，而且效果也很好，可以完全规避掉数据倾斜。</li>\n<li><strong>方案缺点</strong>：适用场景不多，大多数情况下，导致倾斜的key还是很多的，并不是只有少数几个。</li>\n<li><strong>方案实践经验</strong>：在项目中我们也采用过这种方案解决数据倾斜。有一次发现某一天Spark作业在运行的时候突然OOM了，追查之后发现，是Hive表中的某一个key在那天数据异常，导致数据量暴增。因此就采取每次执行前先进行采样，计算出样本中数据量最大的几个key之后，直接在程序中将那些key给过滤掉。</li>\n</ul>\n<h2 id=\"方案三：提高shuffle操作的并行度\"><a href=\"#方案三：提高shuffle操作的并行度\" class=\"headerlink\" title=\"方案三：提高shuffle操作的并行度\"></a>方案三：提高shuffle操作的并行度</h2><ul>\n<li><strong>方案适用场景</strong>：如果我们必须要对数据倾斜迎难而上，那么建议优先使用这种方案，因为这是处理数据倾斜最简单的一种方案。</li>\n<li><strong>方案实现思路</strong>：在对RDD执行shuffle算子时，给shuffle算子传入一个参数，比如reduceByKey(1000)，该参数就设置了这个shuffle算子执行时shuffle read task的数量。对于Spark SQL中的shuffle类语句，比如group by、join等，需要设置一个参数，即spark.sql.shuffle.partitions，该参数代表了shuffle read task的并行度，该值默认是200，对于很多场景来说都有点过小。</li>\n<li><strong>方案实现原理</strong>：增加shuffle read task的数量，可以让原本分配给一个task的多个key分配给多个task，从而让每个task处理比原来更少的数据。举例来说，如果原本有5个key，每个key对应10条数据，这5个key都是分配给一个task的，那么这个task就要处理50条数据。而增加了shuffle read task以后，每个task就分配到一个key，即每个task就处理10条数据，那么自然每个task的执行时间都会变短了。具体原理如下图所示。</li>\n<li><strong>方案优点</strong>：实现起来比较简单，可以有效缓解和减轻数据倾斜的影响。</li>\n<li><strong>方案缺点</strong>：只是缓解了数据倾斜而已，没有彻底根除问题，根据实践经验来看，其效果有限。</li>\n<li><strong>方案实践经验</strong>：该方案通常无法彻底解决数据倾斜，因为如果出现一些极端情况，比如某个key对应的数据量有100万，那么无论你的task数量增加到多少，这个对应着100万数据的key肯定还是会分配到一个task中去处理，因此注定还是会发生数据倾斜的。所以这种方案只能说是在发现数据倾斜时尝试使用的第一种手段，尝试去用最简单的方法缓解数据倾斜而已，或者是和其他方案结合起来使用。</li>\n</ul>\n<h2 id=\"方案四：两阶段聚合（局部聚合-全局聚合）\"><a href=\"#方案四：两阶段聚合（局部聚合-全局聚合）\" class=\"headerlink\" title=\"方案四：两阶段聚合（局部聚合+全局聚合）\"></a>方案四：两阶段聚合（局部聚合+全局聚合）</h2><ul>\n<li><strong>方案适用场景</strong>：对RDD执行reduceByKey等聚合类shuffle算子或者在Spark SQL中使用group by语句进行分组聚合时，比较适用这种方案。</li>\n<li><strong>方案实现思路</strong>：这个方案的核心实现思路就是进行两阶段聚合。第一次是局部聚合，先给每个key都打上一个随机数，比如10以内的随机数，此时原先一样的key就变成不一样的了，比如(hello, 1) (hello, 1) (hello, 1) (hello, 1)，就会变成(1_hello, 1) (1_hello, 1) (2_hello, 1) (2_hello, 1)。接着对打上随机数后的数据，执行reduceByKey等聚合操作，进行局部聚合，那么局部聚合结果，就会变成了(1_hello, 2) (2_hello, 2)。然后将各个key的前缀给去掉，就会变成(hello,2)(hello,2)，再次进行全局聚合操作，就可以得到最终结果了，比如(hello, 4)。</li>\n<li><strong>方案实现原理</strong>：将原本相同的key通过附加随机前缀的方式，变成多个不同的key，就可以让原本被一个task处理的数据分散到多个task上去做局部聚合，进而解决单个task处理数据量过多的问题。接着去除掉随机前缀，再次进行全局聚合，就可以得到最终的结果。</li>\n<li><strong>方案优点</strong>：对于聚合类的shuffle操作导致的数据倾斜，效果是非常不错的。通常都可以解决掉数据倾斜，或者至少是大幅度缓解数据倾斜，将Spark作业的性能提升数倍以上。</li>\n<li><strong>方案缺点</strong>：仅仅适用于聚合类的shuffle操作，适用范围相对较窄。如果是join类的shuffle操作，还得用其他的解决方案。</li>\n</ul>\n<h2 id=\"方案五：将reduce-join转为map-join\"><a href=\"#方案五：将reduce-join转为map-join\" class=\"headerlink\" title=\"方案五：将reduce join转为map join\"></a>方案五：将reduce join转为map join</h2><ul>\n<li><strong>方案适用场景</strong>：在对RDD使用join类操作，或者是在Spark SQL中使用join语句时，而且join操作中的一个RDD或表的数据量比较小（比如几百M或者一两G），比较适用此方案。</li>\n<li><strong>方案实现思路</strong>：不使用join算子进行连接操作，而使用Broadcast变量与map类算子实现join操作，进而完全规避掉shuffle类的操作，彻底避免数据倾斜的发生和出现。将较小RDD中的数据直接通过collect算子拉取到Driver端的内存中来，然后对其创建一个Broadcast变量；接着对另外一个RDD执行map类算子，在算子函数内，从Broadcast变量中获取较小RDD的全量数据，与当前RDD的每一条数据按照连接key进行比对，如果连接key相同的话，那么就将两个RDD的数据用你需要的方式连接起来。</li>\n<li><strong>方案实现原理</strong>：普通的join是会走shuffle过程的，而一旦shuffle，就相当于会将相同key的数据拉取到一个shuffle read task中再进行join，此时就是reduce join。但是如果一个RDD是比较小的，则可以采用广播小RDD全量数据+map算子来实现与join同样的效果，也就是map join，此时就不会发生shuffle操作，也就不会发生数据倾斜。</li>\n<li><strong>方案优点</strong>：对join操作导致的数据倾斜，效果非常好，因为根本就不会发生shuffle，也就根本不会发生数据倾斜。</li>\n<li><strong>方案缺点</strong>：适用场景较少，因为这个方案只适用于一个大表和一个小表的情况。毕竟我们需要将小表进行广播，此时会比较消耗内存资源，driver和每个Executor内存中都会驻留一份小RDD的全量数据。如果我们广播出去的RDD数据比较大，比如10G以上，那么就可能发生内存溢出了。因此并不适合两个都是大表的情况。</li>\n</ul>\n<h2 id=\"方案六：采样倾斜key并分拆join操作\"><a href=\"#方案六：采样倾斜key并分拆join操作\" class=\"headerlink\" title=\"方案六：采样倾斜key并分拆join操作\"></a>方案六：采样倾斜key并分拆join操作</h2><ul>\n<li><strong>方案适用场景</strong>：两个RDD/Hive表进行join的时候，如果数据量都比较大，无法采用“解决方案五”，那么此时可以看一下两个RDD/Hive表中的key分布情况。如果出现数据倾斜，是因为其中某一个RDD/Hive表中的少数几个key的数据量过大，而另一个RDD/Hive表中的所有key都分布比较均匀，那么采用这个解决方案是比较合适的。</li>\n<li><p><strong>方案实现思路</strong>：</p>\n<ul>\n<li><p>对包含少数几个数据量过大的key的那个RDD，通过sample算子采样出一份样本来，然后统计一下每个key的数量，计算出来数据量最大的是哪几个key。</p>\n</li>\n<li><p>然后将这几个key对应的数据从原来的RDD中拆分出来，形成一个单独的RDD，并给每个key都打上n以内的随机数作为前缀，而不会导致倾斜的大部分key形成另外一个RDD。</p>\n</li>\n<li>接着将需要join的另一个RDD，也过滤出来那几个倾斜key对应的数据并形成一个单独的RDD，将每条数据膨胀成n条数据，这n条数据都按顺序附加一个0~n的前缀，不会导致倾斜的大部分key也形成另外一个RDD。</li>\n<li>再将附加了随机前缀的独立RDD与另一个膨胀n倍的独立RDD进行join，此时就可以将原先相同的key打散成n份，分散到多个task中去进行join了。</li>\n<li>而另外两个普通的RDD就照常join即可。</li>\n<li>最后将两次join的结果使用union算子合并起来即可，就是最终的join结果。</li>\n</ul>\n</li>\n<li><p><strong>方案实现原理</strong>：对于join导致的数据倾斜，如果只是某几个key导致了倾斜，可以将少数几个key分拆成独立RDD，并附加随机前缀打散成n份去进行join，此时这几个key对应的数据就不会集中在少数几个task上，而是分散到多个task进行join了。</p>\n</li>\n<li><strong>方案优点</strong>：对于join导致的数据倾斜，如果只是某几个key导致了倾斜，采用该方式可以用最有效的方式打散key进行join。而且只需要针对少数倾斜key对应的数据进行扩容n倍，不需要对全量数据进行扩容。避免了占用过多内存。</li>\n<li><strong>方案缺点</strong>：如果导致倾斜的key特别多的话，比如成千上万个key都导致数据倾斜，那么这种方式也不适合。</li>\n</ul>\n<h2 id=\"方案七：使用随机前缀和扩容RDD进行join\"><a href=\"#方案七：使用随机前缀和扩容RDD进行join\" class=\"headerlink\" title=\"方案七：使用随机前缀和扩容RDD进行join\"></a>方案七：使用随机前缀和扩容RDD进行join</h2><ul>\n<li><strong>方案适用场景</strong>：如果在进行join操作时，RDD中有大量的key导致数据倾斜，那么进行分拆key也没什么意义，此时就只能使用最后一种方案来解决问题了。</li>\n<li><p><strong>方案实现思路</strong>：</p>\n<ul>\n<li>该方案的实现思路基本和“解决方案六”类似，首先查看RDD/Hive表中的数据分布情况，找到那个造成数据倾斜的RDD/Hive表，比如有多个key都对应了超过1万条数据。</li>\n<li>然后将该RDD的每条数据都打上一个n以内的随机前缀。</li>\n<li>同时对另外一个正常的RDD进行扩容，将每条数据都扩容成n条数据，扩容出来的每条数据都依次打上一个0~n的前缀。</li>\n<li>最后将两个处理后的RDD进行join即可。</li>\n</ul>\n</li>\n<li><p><strong>方案实现原理</strong>：将原先一样的key通过附加随机前缀变成不一样的key，然后就可以将这些处理后的“不同key”分散到多个task中去处理，而不是让一个task处理大量的相同key。该方案与“解决方案六”的不同之处就在于，上一种方案是尽量只对少数倾斜key对应的数据进行特殊处理，由于处理过程需要扩容RDD，因此上一种方案扩容RDD后对内存的占用并不大；而这一种方案是针对有大量倾斜key的情况，没法将部分key拆分出来进行单独处理，因此只能对整个RDD进行数据扩容，对内存资源要求很高。</p>\n</li>\n<li><strong>方案优点</strong>：对join类型的数据倾斜基本都可以处理，而且效果也相对比较显著，性能提升效果非常不错。</li>\n<li><strong>方案缺点</strong>：该方案更多的是缓解数据倾斜，而不是彻底避免数据倾斜。而且需要对整个RDD进行扩容，对内存资源要求很高。</li>\n<li><strong>方案实践经验</strong>：曾经开发一个数据需求的时候，发现一个join导致了数据倾斜。优化之前，作业的执行时间大约是60分钟左右；使用该方案优化之后，执行时间缩短到10分钟左右，性能提升了6倍。</li>\n</ul>\n<h2 id=\"方案八：多种方案组合使用\"><a href=\"#方案八：多种方案组合使用\" class=\"headerlink\" title=\"方案八：多种方案组合使用\"></a>方案八：多种方案组合使用</h2><p>在实践中发现，很多情况下，如果只是处理较为简单的数据倾斜场景，那么使用上述方案中的某一种基本就可以解决。但是如果要处理一个较为复杂的数据倾斜场景，那么可能需要将多种方案组合起来使用。比如说，我们针对出现了多个数据倾斜环节的Spark作业，可以先运用解决方案一和二，预处理一部分数据，并过滤一部分数据来缓解；其次可以对某些shuffle操作提升并行度，优化其性能；最后还可以针对不同的聚合或join操作，选择一种方案来优化其性能。大家需要对这些方案的思路和原理都透彻理解之后，在实践中根据各种不同的情况，灵活运用多种方案，来解决自己的数据倾斜问题。</p>\n","categories":["spark"],"tags":["spark","调优","转载"]},{"title":"windows下JDK版本切换脚本","url":"https://sustcoder.github.io/2018/09/18/windows下JDK版本切换脚本/","content":"<h1 id=\"初衷\"><a href=\"#初衷\" class=\"headerlink\" title=\"初衷\"></a>初衷</h1><p>前几天在一个技术交流群中看到技术人应该怎样去扩展自己的知识，去发现新的技术。其中有一条就是：<strong>当你对当前的工作感到厌倦的时候就应该去思考是否可以对其进行优化</strong>，比如我在重复的打开环境变量，修改JDK版本号的时候，就为每天都要进行此操作而感到厌倦，以至于内心开始拒绝去切换JDK版本，拒绝去做需要在另一个版本上的工作。</p>\n<h1 id=\"research过程\"><a href=\"#research过程\" class=\"headerlink\" title=\"research过程\"></a>research过程</h1><p>首先我搜索的关键字是<code>jdk版本切换</code>，其搜索结果都是怎样设置多JDK版本，怎样去修改环境变量。但是这些结果并不是我想要的，不过我确实是想要切换JDK版本啊，为什么没搜到结果呢。</p>\n<p><strong>当搜索不到结果的时候，首先考虑我们的搜索关键字是否准备</strong></p>\n<p>再次思考，我其实不是想切换JDK版本，而是想更方便的切换JDK版本，怎样会更方便呢，比如只点一个按钮即可。那其实可以通过脚本去实现这个功能，所以我的搜索条件变成了<code>windos切换JDK版本脚本</code>然后就搜索到了想要的结果。</p>\n<h1 id=\"脚本\"><a href=\"#脚本\" class=\"headerlink\" title=\"脚本\"></a>脚本</h1><h2 id=\"运行截图\"><a href=\"#运行截图\" class=\"headerlink\" title=\"运行截图\"></a>运行截图</h2><p><img src=\"https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/tool/script/jdkVSwitch.png\" alt=\"运行截图\"></p>\n<h2 id=\"脚本内容\"><a href=\"#脚本内容\" class=\"headerlink\" title=\"脚本内容\"></a>脚本内容</h2><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">@<span class=\"built_in\">echo</span> off</span><br><span class=\"line\"></span><br><span class=\"line\">rem --- Base Config 配置JDK的安装目录 ---</span><br><span class=\"line\">:init </span><br><span class=\"line\"><span class=\"built_in\">set</span> JAVA_HOME_1_8=C:\\Program Files\\Java\\jdk8</span><br><span class=\"line\"><span class=\"built_in\">set</span> JRE_HOME_1_8=C:\\Program Files\\Java\\jre8</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">set</span> JAVA_HOME_1_7=C:\\Program Files\\Java\\jdk7</span><br><span class=\"line\"><span class=\"built_in\">set</span> JRE_HOME_1_7=C:\\Program Files\\Java\\jre7</span><br><span class=\"line\">:start </span><br><span class=\"line\"><span class=\"built_in\">echo</span> 当前使用的JDK 版本: </span><br><span class=\"line\">java -version </span><br><span class=\"line\"><span class=\"built_in\">echo</span>. </span><br><span class=\"line\"><span class=\"built_in\">echo</span> ============================================= </span><br><span class=\"line\"><span class=\"built_in\">echo</span> jdk版本列表: </span><br><span class=\"line\"><span class=\"built_in\">echo</span>  jdk1.8 </span><br><span class=\"line\"><span class=\"built_in\">echo</span>  jdk1.7</span><br><span class=\"line\"><span class=\"built_in\">echo</span> ============================================= </span><br><span class=\"line\"></span><br><span class=\"line\">:select</span><br><span class=\"line\"><span class=\"built_in\">set</span> /p opt=请输入JDK版本。[7代表jdk1.7],[8代表jdk1.8]： </span><br><span class=\"line\"><span class=\"keyword\">if</span> %opt%==8 (</span><br><span class=\"line\">    <span class=\"built_in\">set</span> TARGET_JAVA_HOME=%JAVA_HOME_1_8%</span><br><span class=\"line\">\t<span class=\"built_in\">set</span> TARGET_JRE_HOME=%JRE_HOME_1_8%</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"keyword\">if</span> %opt%==7 (</span><br><span class=\"line\">    <span class=\"built_in\">set</span> TARGET_JAVA_HOME=%JAVA_HOME_1_7%</span><br><span class=\"line\">\t<span class=\"built_in\">set</span> TARGET_JRE_HOME=%JRE_HOME_1_7%</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">echo</span> 当前选择的Java路径:</span><br><span class=\"line\"><span class=\"built_in\">echo</span> JAVE_HOME:%TARGET_JAVA_HOME%</span><br><span class=\"line\"><span class=\"built_in\">echo</span> JRE_HOME:%TARGET_JRE_HOME%</span><br><span class=\"line\"></span><br><span class=\"line\">wmic ENVIRONMENT <span class=\"built_in\">where</span> <span class=\"string\">\"name='JAVA_HOME'\"</span> delete</span><br><span class=\"line\">wmic ENVIRONMENT create name=<span class=\"string\">\"JAVA_HOME\"</span>,username=<span class=\"string\">\"&lt;system&gt;\"</span>,VariableValue=<span class=\"string\">\"%TARGET_JAVA_HOME%\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">wmic ENVIRONMENT <span class=\"built_in\">where</span> <span class=\"string\">\"name='JRE_HOME'\"</span> delete</span><br><span class=\"line\">wmic ENVIRONMENT create name=<span class=\"string\">\"JRE_HOME\"</span>,username=<span class=\"string\">\"&lt;system&gt;\"</span>,VariableValue=<span class=\"string\">\"%TARGET_JRE_HOME%\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">rem -- refresh env ---</span><br><span class=\"line\">call RefreshEnv</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">echo</span> 请按任意键退出!   </span><br><span class=\"line\">pause&gt;nul</span><br><span class=\"line\"></span><br><span class=\"line\">@<span class=\"built_in\">echo</span> on</span><br></pre></td></tr></table></figure>\n<h2 id=\"脚本下载\"><a href=\"#脚本下载\" class=\"headerlink\" title=\"脚本下载\"></a>脚本下载</h2><ul>\n<li><a href=\"https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/tool/script/RefreshEnv.exe\" target=\"_blank\" rel=\"noopener\">RefreshEnv.exe</a></li>\n<li><a href=\"https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/tool/script/switchVersion.bat\" target=\"_blank\" rel=\"noopener\">switchVersion.bat</a></li>\n</ul>\n<h1 id=\"注意事项\"><a href=\"#注意事项\" class=\"headerlink\" title=\"注意事项\"></a>注意事项</h1><ul>\n<li>是否需要配置<code>JRE_HOME</code>和安装JDK的路径有关系，下图是我的安装路径</li>\n</ul>\n<p><img src=\"https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/tool/script/jdkPath.png\" alt=\"jdk安装路径\"> </p>\n<ul>\n<li>需要修改<code>JAVA_HOME</code>的值为你对应的JDK安装路径</li>\n<li>需要以管理员权限运行脚本</li>\n</ul>\n","categories":["tool"],"tags":["tool","jdk","思考"]},{"title":"sbt安装与仓库设置","url":"https://sustcoder.github.io/2018/09/13/sbt入门/","content":"<h1 id=\"sbt安装\"><a href=\"#sbt安装\" class=\"headerlink\" title=\"sbt安装\"></a>sbt安装</h1><h2 id=\"环境\"><a href=\"#环境\" class=\"headerlink\" title=\"环境\"></a>环境</h2><ul>\n<li><code>java 1.8</code></li>\n<li><code>scala 2.12.6</code></li>\n<li><code>sbt 1.2.1</code></li>\n<li><code>idea2.18.3</code><h2 id=\"软件\"><a href=\"#软件\" class=\"headerlink\" title=\"软件\"></a>软件</h2></li>\n<li><code>idea sbt</code>插件</li>\n<li><code>idea scala</code>插件</li>\n<li>sbt安装包 <code>https://sbt-downloads.cdnedge.bluemix.net/releases/v1.2.1/sbt-1.2.1.msi</code>,非必须，可直接使用idea的sbt插件做对应配置<h2 id=\"安装sbt\"><a href=\"#安装sbt\" class=\"headerlink\" title=\"安装sbt\"></a>安装sbt</h2></li>\n</ul>\n<ol>\n<li>新建sbt安装路径，注意：<strong>sbt安装路径中不能含有空格和中文</strong>，将<code>sbt-1.2.1.msi</code>安装到此路径。</li>\n<li>配置环境变量</li>\n</ol>\n<ul>\n<li>新建变量sbt<blockquote>\n<p>SBT_HOME  D:\\ProgramFile\\sbt</p>\n</blockquote>\n</li>\n<li>添加变量到path中<blockquote>\n<p> %SBT_HOME%bin;</p>\n</blockquote>\n</li>\n</ul>\n<h2 id=\"配置文件\"><a href=\"#配置文件\" class=\"headerlink\" title=\"配置文件\"></a>配置文件</h2><p>修改文件<code>onf/sbtconfig.txt</code>，添加以下内容</p>\n<blockquote>\n<p>-Dfile.encoding=UTF8</p>\n</blockquote>\n<h2 id=\"sbt仓库设置\"><a href=\"#sbt仓库设置\" class=\"headerlink\" title=\"sbt仓库设置\"></a>sbt仓库设置</h2><h3 id=\"方案一\"><a href=\"#方案一\" class=\"headerlink\" title=\"方案一\"></a>方案一</h3><p>直接修改sbt的jar里面的配置文件。<code>windows</code>下可通过360压缩替换掉<code>jar</code>包里面的文件。</p>\n<ol>\n<li>找到sbt安装目录<code>D:\\ProgramFile\\sbt\\bin</code></li>\n<li>备份<code>sbt-launch.jar</code>为<code>sbt-launch.jar.bak</code></li>\n<li>解压<code>sbt-launch.jar.bak</code>,打开个<code>sbt.boot.properties</code>文件</li>\n<li><p>在<code>[repositories]</code>里面的<code>local</code>下面添加以下数据源</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">alirepo1:https://maven.aliyun.com/repository/central</span><br><span class=\"line\">alirepo2:https://maven.aliyun.com/repository/jcenter</span><br><span class=\"line\">alirepo3:https://maven.aliyun.com/repository/public</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>使用360压缩打开<code>sbt-launch.jar</code>,找到<code>sbt.boot.properties</code>文件并替换</p>\n</li>\n</ol>\n<h3 id=\"方案二\"><a href=\"#方案二\" class=\"headerlink\" title=\"方案二\"></a>方案二</h3><p>配置sbt的数据源，让其优先加载我们配置的数据源</p>\n<ol>\n<li>在<code>D:\\ProgramFile\\sbt\\conf</code>目录下，新建文件<code>repository.properties</code></li>\n<li><p>在<code>repository.properties</code>中添加以下内容</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[repositories]</span><br><span class=\"line\">local</span><br><span class=\"line\">alirepo1:https://maven.aliyun.com/repository/central</span><br><span class=\"line\">alirepo2:https://maven.aliyun.com/repository/jcenter</span><br><span class=\"line\">alirepo3:https://maven.aliyun.com/repository/public</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>在<code>conf/sbtconfig.txt</code>中添加<code>repository.properties</code>文件路径</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">-Dsbt.repository.config=D:/ProgramFile/sbt/conf/repository.properties</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<h2 id=\"添加依赖build-sbt\"><a href=\"#添加依赖build-sbt\" class=\"headerlink\" title=\"添加依赖build.sbt\"></a>添加依赖build.sbt</h2><p>在项目中找到<code>build.sbt</code>文件，此类似于<code>maven</code>中的<code>pom</code>文件<br>添加<code>spark-core</code>和<code>spark-sql</code>等的依赖<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">name := &quot;sbt-test&quot; // 项目名称</span><br><span class=\"line\"></span><br><span class=\"line\">version := &quot;0.1&quot; // 项目版本号</span><br><span class=\"line\"></span><br><span class=\"line\">scalaVersion := &quot;2.11.12&quot; // scala版本号</span><br><span class=\"line\"></span><br><span class=\"line\">// 依赖</span><br><span class=\"line\">libraryDependencies ++= Seq(</span><br><span class=\"line\">  &quot;org.apache.spark&quot;  %%  &quot;spark-core&quot;    % &quot;2.2.0&quot;,</span><br><span class=\"line\">  &quot;org.apache.spark&quot;  %%  &quot;spark-sql&quot;     % &quot;2.2.0&quot;,</span><br><span class=\"line\">  &quot;com.typesafe.scala-logging&quot; % &quot;scala-logging-slf4j_2.11&quot; % &quot;latest.integration&quot;</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"下载依赖\"><a href=\"#下载依赖\" class=\"headerlink\" title=\"下载依赖\"></a>下载依赖</h2><p>通过以下方式打开执行命令窗口</p>\n<ul>\n<li>在<code>build.sbt</code>同级目录下打开<code>cmd</code>窗口</li>\n<li>在<code>idea</code>中打开<code>Termail</code>窗口</li>\n</ul>\n<p>下载或更新jar</p>\n<blockquote>\n<p>sbt update</p>\n</blockquote>\n<p>编译文件</p>\n<blockquote>\n<p>sbt compile</p>\n</blockquote>\n<p>打包</p>\n<blockquote>\n<p>sbt package</p>\n</blockquote>\n<h1 id=\"问题处理\"><a href=\"#问题处理\" class=\"headerlink\" title=\"问题处理\"></a>问题处理</h1><h2 id=\"版本不兼容\"><a href=\"#版本不兼容\" class=\"headerlink\" title=\"版本不兼容\"></a>版本不兼容</h2><h3 id=\"jdk不兼容\"><a href=\"#jdk不兼容\" class=\"headerlink\" title=\"jdk不兼容\"></a>jdk不兼容</h3><ul>\n<li><code>idea2018</code>需要<code>jdk8</code>以上</li>\n<li><code>spark2.0</code>需要<code>jdk8</code>以上<h2 id=\"文件下载缓慢\"><a href=\"#文件下载缓慢\" class=\"headerlink\" title=\"文件下载缓慢\"></a>文件下载缓慢</h2><code>idea</code>控制台<code>build</code>界面一直在转圈,并提示<code>dump project structure from sbt</code></li>\n</ul>\n<p>这里需要注意，在<code>Intellij Idea</code>启动时，会执行<code>dump project structure from sbt</code>的操作，也就是把sbt所需要的项目结构从远程服务器拉取到本地，在本地会生成sbt所需要的项目结构。由于是从国外的远程服务器下载，所以，这个过程很慢，笔者电脑上运行了15分钟。这个过程没有结束之前，上图中的<code>File-&gt;New</code>弹出的子菜单是找不到<code>Scala Class</code>这个选项的。所以，一定要等<code>dump project structure from sbt</code>的操作全部执行结束以后，再去按照上图操作来新建<code>Scala Class</code>文件。</p>\n<h2 id=\"修改sbt数据源\"><a href=\"#修改sbt数据源\" class=\"headerlink\" title=\"修改sbt数据源\"></a>修改sbt数据源</h2><h3 id=\"不靠谱方案\"><a href=\"#不靠谱方案\" class=\"headerlink\" title=\"不靠谱方案\"></a>不靠谱方案</h3><ol>\n<li>将数据源改为<code>maven.oschina.com</code>。此数据源已经失效</li>\n<li>将<code>sbt.boot.properties</code>中的<code>https</code>改为<code>http</code>。未生效</li>\n<li>在<code>sbt</code>的<code>vm</code>中配置<code>-Dsbt.override.build.repos=true</code>。此方法效果和<code>-Dsbt.repository.config=D:/ProgramFile/sbt/conf/repository.properties</code>一致，前提是需要配置数据源</li>\n<li>最笨方案，下载jar包，放到本地仓库<code>C:\\Users\\suning\\.ivy2\\cache</code></li>\n</ol>\n<h3 id=\"修改成阿里云数据源后依旧下载失败\"><a href=\"#修改成阿里云数据源后依旧下载失败\" class=\"headerlink\" title=\"修改成阿里云数据源后依旧下载失败\"></a>修改成阿里云数据源后依旧下载失败</h3><ul>\n<li>配置的<code>sbt</code>版本在阿里云的仓库中没有。排查办法：可以去<code>maven.aliyun.com</code>去查看对应版本pom文件是否存在</li>\n<li>在阿里云上找到了对应版本但依旧保持。注意查看日志信息中下载的jar包路径含有<code>_2.10</code>类似的字样，比如在<code>build.sbt</code>中配置的是<code>&quot;org.apache.spark&quot;  %%  &quot;spark-sql&quot;     % &quot;2.2.0&quot;</code>,但是日志里面是<code>[warn]  :: com.typesafe.scala-logging#scala-sql_2.10;2.1.2: not found</code>,这个是因为sbt里面的<code>%%</code>代表sbt默认会拼接上scala的版本号在pom文件上，下载最适合的jar包，可以将<code>%%</code>改为<code>%</code>，即改为<code>&quot;org.apache.spark&quot;  %  &quot;spark-sql&quot;     % &quot;2.2.0&quot;</code>,注意区别：仅仅是少了一个百分号。</li>\n<li>执行<code>sbt-shell</code>会走默认的仓库配置，需要在sbt的vm参数中配置<code>-Dsbt.override.build.repos=true</code> ????<h2 id=\"查看配置参数是否生效\"><a href=\"#查看配置参数是否生效\" class=\"headerlink\" title=\"查看配置参数是否生效\"></a>查看配置参数是否生效</h2>可在日志控制台查看第一行日志，查看配置参数是否生效，走的是自己安装的sbt还是idea的插件,如下日志，在<code>sbtconfig.txt</code>中配置信息会进行加载<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&quot;C:\\Program Files\\Java\\jdk8\\bin\\java.exe&quot; -agentlib:jdwp=transport=dt_socket,address=localhost:58502,suspend=n,server=y -Xdebug -server -Xmx1536M </span><br><span class=\"line\">-Dsbt.repository.config=D:/develop/sbt/conf/repository.properties -Didea.managed=true -Dfile.encoding=UTF-8 </span><br><span class=\"line\">-Didea.runid=2018.2 -jar D:\\ProgramFile\\sbt\\bin\\sbt-launch.jar idea-shell</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p><strong>参考链接</strong></p>\n<p><a href=\"https://www.scala-sbt.org/0.13/docs/Proxy-Repositories.html\" target=\"_blank\" rel=\"noopener\">https://www.scala-sbt.org/0.13/docs/Proxy-Repositories.html</a></p>\n<p><a href=\"https://segmentfault.com/a/1190000002484978\" target=\"_blank\" rel=\"noopener\">https://segmentfault.com/a/1190000002484978</a></p>\n","categories":["spark"],"tags":["spark","sbt"]},{"title":"Hello World","url":"https://sustcoder.github.io/2018/09/10/hello-world/","content":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"noopener\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"noopener\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"noopener\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"noopener\">Deployment</a></p>\n","categories":[],"tags":[]},{"title":"about","url":"https://sustcoder.github.io/about/index.html","content":"","categories":[],"tags":[]},{"title":"category","url":"https://sustcoder.github.io/category/index.html","content":"","categories":[],"tags":[]},{"title":"","url":"https://sustcoder.github.io/life/index.html","content":"<html>\n\t<head>\n\t\t<title>胖斯世界</title>\n\t\t<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\">\n\t\t<style type=\"text/css\">\n\t\t\t\nbody {\n\tmargin: 0px 0px;\n\tpadding: 0px 0px;\n\toverflow: hidden;\n}\n\ndiv {\n\tcolor: #fff;\n}\n\n.space {\n\tbackground : #000;\n\twidth : 100%;\n\theight : 100%;\n}\n\n.space  div{\n\ttop:50%;\n\tleft:50%;\n\tposition:absolute;\n}\n\n.container {\n\n\tbackground : #888;\n\t\n    animation-play-state: running;\n    -webkit-animation-play-state: running;    \n}\n\n.container:hover {\n\n\tbackground : #eee;\n\t\n    animation-play-state: paused;\n    -webkit-animation-play-state: paused;\n\t\n\ttransition: 3s;\n}\n\n#all-container {\n\n\tbackground : #0f0f0f;\n\n    -moz-border-radius: 400px;\n    -webkit-border-radius: 400px;\n    border-radius: 400px;\n\t\n\twidth : 800px;\n\theight : 800px;\n\tmargin-left:-400px;\n\tmargin-top:-400px;\n\t\n\n    animation: spin 80s linear infinite;\n    -webkit-animation: spin 80s linear infinite;\n\t\n}\n\n#all-container:hover,\n#family-container:hover,\n#me-container:hover,\n#wife-container:hover,\n#child-container:hover {\n\n    animation-play-state: paused;\n    -webkit-animation-play-state: paused;\n\t\n}\n\n#family-container {\n\n    -moz-border-radius: 120px;\n    -webkit-border-radius: 120px;\n    border-radius: 120px;\n\t\n\twidth : 240px;\n\theight : 240px;\n\tmargin-left:-120px;\n\tmargin-top:-120px;\n\t\n    animation: spin 40s linear infinite;\n    -webkit-animation: spin 40s linear infinite;\n\t\n\tbackground-image:url(https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/life/myworld/wife.jpg);\n}\n\n#family {\n\n\twidth : 180px;\n\theight : 180px;\n\tmargin-left:-90px;\n\tmargin-top:-90px;\n\tfont-size: 50;\n\tfont-weight:300;\n\t\n}\n\n#family .words {\n\tdisplay:none;\n\tmargin-left:-90px;\n\tmargin-top:90px;\n}\n\n#family:hover .words {\n\tdisplay:block;\n}\n\n#wife-container {\n\n    -moz-border-radius: 40px;\n    -webkit-border-radius: 40px;\n    border-radius: 40px;\n\t\n\twidth : 70px;\n\theight : 70px;\n\tmargin-left:-330px;\n\tmargin-top:-30px;\n\t\n    animation: spin 10s linear infinite;\n    -webkit-animation: spin 15s linear infinite;\n\t\n\tbackground-image:url(https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/life/myworld/me.jpg);\n}\n\n#wife {\n\n\twidth : 40px;\n\theight : 40px;\n\tmargin-left:-30px;\n\tmargin-top:-30px;\n\tfont-size:20;\n\tfont-weight:300;\n}\n\n#wife .words {\n\tdisplay:none;\n\tmargin-left:-50px;\n\tmargin-top:50px;\n}\n\n#wife:hover .words {\n\tdisplay:block;\n}\n\n#child-container {\n\n    -moz-border-radius: 20px;\n    -webkit-border-radius: 20px;\n    border-radius: 20px;\n\t\n\twidth : 40px;\n\theight : 40px;\n\tmargin-left:-330px;\n\tmargin-top:15px;\n\t\n    animation: spin 5s linear infinite;\n    -webkit-animation: spin 5s linear infinite;\n\t\n\tbackground-image:url(https://sustblog.oss-cn-beijing.aliyuncs.com/blog/2018/life/myworld/child.jpg);\n}\n\n#child {\n\n\twidth : 30px;\n\theight : 30px;\n\tmargin-left:-15px;\n\tmargin-top:-15px;\n\tfont-size:15;\n\tfont-weight:300;\n}\n\n#child .words {\n\tdisplay:none;\n\tmargin-left:-30px;\n\tmargin-top:30px;\n}\n\n#child:hover .words {\n\tdisplay:block;\n}\n\n@keyframes spin {\n\tto {\n\t\t-webkit-transform: rotate(1turn);\n\t\t-ms-transform: rotate(1turn);\n\t}\n}\n\n@-webkit-keyframes spin {\n\tto {\n\t\t-webkit-transform: rotate(1turn);\n\t\t-ms-transform: rotate(1turn);\n\t}\n}\n\n\n\n\t  </style>\n\t</head>\n\t<body>\n\t\t<div class=\"space\">\n\t\t\t<div class=\"container\" id=\"all-container\">\n\t\t\t\t<div class=\"container\" id=\"family-container\">\n\t\t\t\t\t<div id=\"family\" alt=\"菲菲\">\n\t\t\t\t\t\t<div class=\"words\">菲菲</div>\n\t\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"container\" id=\"wife-container\">\n\t\t\t\t\t<div id=\"wife\" alt=\"胖斯\">\n\t\t\t\t\t\t<div class=\"words\">胖斯</div>\n\t\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"container\" id=\"child-container\">\n\t\t\t\t\t<div id=\"child\" alt=\"小可爱\">\n\t\t\t\t\t\t<div class=\"words\">小可爱</div>\n\t\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t</div>\n\t\t</div>\n\t</body>\n</html>\n\n","categories":[],"tags":[]},{"title":"link","url":"https://sustcoder.github.io/link/index.html","content":"","categories":[],"tags":[]},{"title":"project","url":"https://sustcoder.github.io/project/index.html","content":"","categories":[],"tags":[]},{"title":"search","url":"https://sustcoder.github.io/search/index.html","content":"","categories":[],"tags":[]},{"title":"tag","url":"https://sustcoder.github.io/tag/index.html","content":"","categories":[],"tags":[]}]